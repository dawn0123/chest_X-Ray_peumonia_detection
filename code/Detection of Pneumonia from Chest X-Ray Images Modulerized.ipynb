{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "<pre>\n",
    "Author           : Anjana Tiha\n",
    "Project Name     : Detection of Pneumonia from Chest X-Ray Images using Convolutional Neural Network, \n",
    "                   and Transfer Learning.\n",
    "Description      : 1. Detected Pneumonia from Chest X-Ray images by retraining pretrained model “InceptionV3” \n",
    "                      with 5856 images of X-ray (1.15GB).\n",
    "                   2. For retraining removed output layers, freezed first few layers and Fine-tuned model for \n",
    "                      two new label classes (Pneumonia and Normal).\n",
    "                   3. Attained testing accuracy 83.44% and loss 0.42.\n",
    "Method           : \n",
    "Tools/Library    : Python, Keras, PyTorch, TensorFlow\n",
    "Version History  : 1.0.0.0\n",
    "Current Version  : 1.0.0.0\n",
    "Last Update      : 11.30.2018\n",
    "Comments         : Please use Anaconda editor for convenience of visualization.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "<pre>\n",
    "GitHub Link      : <a href=https://github.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitHub)</a>\n",
    "GitLab Link      : <a href=https://gitlab.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitLab)</a>\n",
    "Portfolio        : <a href=https://anjanatiha.wixsite.com/website>Anjana Tiha's Portfolio</a>\n",
    "</pre>\n",
    "\n",
    "#### Dataset\n",
    "<pre>\n",
    "Dataset Name     : Chest X-Ray Images (Pneumonia)\n",
    "Dataset Link     : <a href=https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia>Chest X-Ray Images (Pneumonia) Dataset (Kaggle)</a>\n",
    "                 : <a href=https://data.mendeley.com/datasets/rscbjbr9sj/2>Chest X-Ray Images (Pneumonia) Dataset (Original Dataset)</a>\n",
    "Original Paper   : <a href=https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5>Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning</a>\n",
    "                   (Daniel S. Kermany, Michael Goldbaum, Wenjia Cai, M. Anthony Lewis, Huimin Xia, Kang Zhang)\n",
    "                   https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library/Tools Version\n",
    "- Python - v3.6.7\n",
    "- argparse\n",
    "- random\n",
    "- numpy\n",
    "- shutil\n",
    "- gc\n",
    "- re\n",
    "- Keras - 2.2.4\n",
    "- Keras-preprocessing - v1.0.5\n",
    "- TensorFlow - 1.12\n",
    "- PIL/Pillow - 5.1.0\n",
    "- Matplotlib - 2.2.2\n",
    "- scikit-learn - 0.19.1\n",
    "- mlxtend - 0.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands / Running Instruction\n",
    "<pre>\n",
    "tensorboard --logdir=logs\n",
    "%config IPCompleter.greedy=True\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>Dataset Details</b>\n",
    "Dataset Name            : Chest X-Ray Images (Pneumonia)\n",
    "Number of Class         : 2\n",
    "Number/Size of Images   : Total      : 5856 (1.15 Gigabyte (GB))\n",
    "                          Training   : 5216 (1.07 Gigabyte (GB))\n",
    "                          Validation : 320  (42.8 Megabyte (MB))\n",
    "                          Testing    : 320  (35.4 Megabyte (MB))\n",
    "\n",
    "<b>Model Parameters</b>\n",
    "Machine Learning Library: Keras\n",
    "Base Model              : InceptionV3\n",
    "Optimizers              : Adam\n",
    "Loss Function           : categorical_crossentropy\n",
    "\n",
    "<b>Training Parameters</b>\n",
    "Batch Size              : 64\n",
    "Number of Epochs        : 50\n",
    "Training Time           : 3 Hours\n",
    "\n",
    "<b>Output (Prediction/ Recognition / Classification Metrics)</b>\n",
    "<!--<b>Validation</b>-->\n",
    "<b>Testing</b>\n",
    "Accuracy                : 83.44%\n",
    "Loss                    : 0.42\n",
    "<!--Precision               : -->\n",
    "Recall                  : 94% (highest)\n",
    "<!--Specificity             : -->\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import inspect\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes directory, if directory exists removes if remove parameter is set to True \n",
    "def mk_reset_dir(directory, remove=False):\n",
    "    if remove and os.path.exists(directory):\n",
    "        try:\n",
    "            shutil.rmtree(directory)\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory)\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print time with date, month, year and hour, minute, second in format given by parameter\n",
    "def date_time(x):\n",
    "    if x==1:\n",
    "        print('Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==2:    \n",
    "        print('Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==3:  \n",
    "        print('Date now: %s' % datetime.datetime.now())\n",
    "    if x==4:  \n",
    "        print('Date today: %s' % datetime.date.today())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints a integer for degugging\n",
    "def debug(x):\n",
    "    print(\"-\"*40, x, \"-\"*40)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of files in each subdirectory of a directory\n",
    "def count_bar(master_directory):\n",
    "    dir_list = os.listdir(master_directory)\n",
    "    num_class = len(dir_list)\n",
    "\n",
    "    dir_name = []\n",
    "    dir_file_count = []\n",
    "\n",
    "    for directory in dir_list:\n",
    "        cur_dir = os.path.join(master_directory, directory)\n",
    "        count_sample = len(os.listdir(cur_dir))\n",
    "        dir_name.append(directory)\n",
    "        dir_file_count.append(count_sample)\n",
    "    \n",
    "    return dir_name, dir_file_count\n",
    "               \n",
    "\n",
    "# show barplot\n",
    "def bar_plot(x, y, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    sns.barplot(x=x, y=y)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    \n",
    "\n",
    "# show bar plot for count of labels in subdirectory of a directory\n",
    "def count_bar_plot(master_directory, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    dir_name, dir_file_count = count_bar(master_directory)\n",
    "    x=dir_name\n",
    "    y=dir_file_count\n",
    "    bar_plot(x, y, title, xlabel, ylabel, figsize=fig_size, title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=subplot_no)\n",
    "    \n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a training, validation, testing directory    \n",
    "def show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    count_bar_plot(training_dir, title +\" (Training)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=131)\n",
    "    count_bar_plot(validation_dir, title +\" (Validation)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=132)\n",
    "    count_bar_plot(testing_dir, title +\" (Testing)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=133)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches)\n",
    "def get_transformed_image_batch(directory, target_size, classes, class_mode='categorical', batch_size=1, shuffle=True, rescale=None, shear_range=0.0, zoom_range=0.0, horizontal_flip=False, validation_split=0.0):       \n",
    "    datagen = ImageDataGenerator(\n",
    "            rescale=rescale,\n",
    "            shear_range=shear_range,\n",
    "            zoom_range=zoom_range,\n",
    "            horizontal_flip=horizontal_flip,\n",
    "            validation_split=validation_split)     \n",
    "    \n",
    "    image_generator = datagen.flow_from_directory(\n",
    "            directory,\n",
    "            target_size=target_size,\n",
    "            classes = classes,\n",
    "            class_mode=class_mode,\n",
    "            batch_size=batch_size)\n",
    "    return image_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Label Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust class weights for imbalanced dataset of classes of images\n",
    "def get_class_weight(y):\n",
    "    counter = Counter(y)                          \n",
    "    max_val = float(max(counter.values()))     \n",
    "    class_weight = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Graph Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tensorflow graph tp free up memory and resource allocation \n",
    "def reset_graph(model=None):\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        return False\n",
    "    tf.reset_default_graph()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    return True\n",
    "\n",
    "\n",
    "# reset callbacks \n",
    "def reset_callbacks(checkpoint=None, reduce_lr=None, early_stopping=None, tensorboard=None):\n",
    "    checkpoint=None\n",
    "    reduce_lr = None\n",
    "    early_stopping = None\n",
    "    tensorboard = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish_activation(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "def basic_model(optimizer, loss, metrics, input_shape=(3,150,150), activation='relu', activation2='sigmoid', padding=\"same\", padding2=\"valid\", pool_size=(2, 2), dilation_rate=(2, 2)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(64, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(96, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(96, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(128, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation=swish_activation))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2 , activation=activation2))\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=metrics)\n",
    "\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "    \n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization Function\n",
    "#### Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "<p>1. Imports Pretrained model InceptionV3 <br>\n",
    "   2. Disabled training on first few layers <br>\n",
    "   3. Enabled training on top and output layers<br>\n",
    "   4. Adjust output Dense Layer to number of Image Classes <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and configure model InceptionV3 for fine-tuning with new class labels\n",
    "def get_inception_model(train_generator, validation_generator, epochs, verbose, optimizer, loss, metrics, tensorboard, callbacks, num_class, include_top=False, non_trainable_index=249, print_layers = False):    \n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=include_top)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    # Setting model layers specially output layer with class number\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 2 classes\n",
    "\n",
    "    # softmax for multi-class\n",
    "    predictions = Dense(num_class, activation='softmax')(x) \n",
    "    \n",
    "    # sigmoid for 2 class or binary class\n",
    "    # predictions = Dense(num_class, activation='sigmoid')(x) \n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "     \n",
    "    # compile model with loss, optimizer and metrics \n",
    "    model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    \n",
    "    if callbacks:\n",
    "        tensorboard.set_model(model) \n",
    "    \n",
    "    # train the model on the new data for a few epochs\n",
    "    model.fit_generator(train_generator,\n",
    "                        steps_per_epoch = len(train_generator),\n",
    "                        epochs=epochs,\n",
    "                        # verbose=verbose, \n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=len(validation_generator),\n",
    "                        class_weight = class_weight)\n",
    "\n",
    "    # at this point, the top layers are well trained and we can start fine-tuning\n",
    "    # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "    # and train the remaining top layers.\n",
    "\n",
    "    # let's visualize layer names and layer indices to see how many layers\n",
    "    # we should freeze:\n",
    "    if print_layers:\n",
    "        for i, layer in enumerate(base_model.layers):\n",
    "            print(i, layer.name)\n",
    "\n",
    "    # Freeze or set first few layers as untrainable\n",
    "    # Unfreeze or set rest of the layers as trainable\n",
    "    for layer in model.layers[:non_trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[non_trainable_index:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Performance Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation performance\n",
    "def plot_history(history, plot_val, title, xlabel, ylabel, legend=[['Train', 'Val'], ['Train', 'Val']], fig_size=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history[plot_val[0][0]])\n",
    "    plt.plot(history.history[plot_val[0][1]])\n",
    "    plt.title(title[0], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[0], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[0], fontsize=label_fontsize)\n",
    "    plt.legend(legend[0], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history[plot_val[1][0]])\n",
    "    plt.plot(history.history[plot_val[1][1]])\n",
    "    plt.title(title[1], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[1], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[1], fontsize=label_fontsize)\n",
    "    plt.legend(legend[1], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Performance Report Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_report(model, test_generator, classes, print_report=False):\n",
    "    y_preds = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "    y_classes = y_preds.argmax(axis=-1)\n",
    "\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    CM_report = classification_report(test_generator.classes, y_classes, target_names=classes)\n",
    "    \n",
    "    if print_report: \n",
    "        print(CM_report)\n",
    "    return y_preds, y_classes, CM, CM_report\n",
    "\n",
    "def model_evaluate(model, test_generator, print_report=False):\n",
    "    result = model.evaluate_generator(generator=test_generator, steps=len(test_generator))\n",
    "    \n",
    "    accuracy = result[1]*100\n",
    "    loss = result[0]\n",
    "    \n",
    "    if print_report:\n",
    "        print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "    \n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse classification report for reporting negetive classes (0)\n",
    "def reverse_pos_neg(CM, print_bool):\n",
    "    tp=CM[0][0]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    tn=CM[1][1]\n",
    "    if print_bool:\n",
    "        print(tp, fp, tn, fn, tn)\n",
    "    return [tp, fp, tn, fn, tn]\n",
    "\n",
    "# reverse and report classification report for reporting negetive classes (0)\n",
    "def report(CM, reverse):\n",
    "    if not reverse:\n",
    "        tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "    else:\n",
    "        tp=CM[0][0]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        tn=CM[1][1]\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "    print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_models(model_dir, details, report_type, classes):\n",
    "    results = {}\n",
    "    \n",
    "    model_files = os.listdir(model_dir)\n",
    "    \n",
    "    i=0\n",
    "    model = None\n",
    "    \n",
    "    for model_file in model_files:\n",
    "        \n",
    "        model_path = model_dir+\"\\\\\"+model_file\n",
    "        \n",
    "        if not os.path.isdir(model_path):\n",
    "            reset_graph(model)\n",
    "\n",
    "            model = keras.models.load_model(model_path)\n",
    "\n",
    "            if report_type==\"Complete\":\n",
    "                y_preds, y_classes, CM, CM_report = predict_report(model, test_generator, classes)\n",
    "                results[model_file] = [CM, CM_report]\n",
    "\n",
    "            else:\n",
    "                accuracy, loss =  model_evaluate(model, test_generator, print_report=False)\n",
    "\n",
    "                results[model_file] = [accuracy, loss]\n",
    "\n",
    "\n",
    "            if details:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_file))\n",
    "                print(\"*\"*80)\n",
    "                if report_type==\"Complete\":\n",
    "                    show_confusion_matrix(test_generator, y_classes, classes)\n",
    "                    print(CM_report)\n",
    "                else:\n",
    "                    print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "                    print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            elif not details and i%10==0:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_file))\n",
    "                print(\"*\"*80)\n",
    "                if report_type==\"Complete\":\n",
    "                    show_confusion_matrix(test_generator, y_classes, classes)\n",
    "                    print(CM_report)\n",
    "                else:\n",
    "                    print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "                    print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            i+=1\n",
    "    print(\"Test complete\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_over_epochs(array, title, xlabel=\"Epoch\", ylabel=\"Value\", title_fontsize=14, label_fontsize=12, subplot_no=0):\n",
    "    x_axis_arr = np.arange(len(array))\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.plot(x_axis_arr, array)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    \n",
    "def line_plot_over_epochs_loss_acc(array, title, fig_size=(10, 8), xlabel=[\"Epoch\", \"Epoch\"], ylabel=[\"Value\",\"Value\"], title_fontsize=14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    line_plot_over_epochs(array[0], title[0], xlabel=xlabel[0], ylabel=ylabel[0], title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=121)\n",
    "    line_plot_over_epochs(array[1], title[1], xlabel=xlabel[1], ylabel=ylabel[1], title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=122)\n",
    "    plt.show()\n",
    "    \n",
    "def show_confusion_matrix(test_generator, y_classes, classes, figsize=(10,8), stick_fontsize=12):\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=figsize, hide_ticks=True,cmap=plt.cm.Blues)\n",
    "    plt.xticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.yticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.show()\n",
    "    return CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-455a2dc4cf83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreset_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Train, Validation and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input/ output directory\n",
    "# Configure training, validation, testing directory\n",
    "\n",
    "input_directory = r\"data/input/\"\n",
    "output_directory = r\"data/output/\"\n",
    "\n",
    "training_dir = input_directory+ r\"train\"\n",
    "testing_dir = input_directory+ r\"test\"\n",
    "validation_dir = input_directory+ r\"val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xlabel=\"Count\"\n",
    "ylabel=\"CaseType\"\n",
    "fig_size = (14,4)\n",
    "# fig_size = (4,2)\n",
    "# title_fontsize=14\n",
    "title_fontsize=13\n",
    "# label_fontsize=12\n",
    "label_fontsize=13\n",
    "title=\"Number of Cases\"\n",
    "\n",
    "\n",
    "show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=fig_size, title_fontsize = title_fontsize, label_fontsize=label_fontsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (Image Preprocessing)\n",
    "#### Configuring Image Transformation Parameters for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get number of label/ class / category\n",
    "num_class = len(os.listdir(training_dir))\n",
    "print(num_class)\n",
    "\n",
    "\n",
    "#Image Augmentation/ Preprocessing before training\n",
    "norm=255.0\n",
    "rescale=1./norm\n",
    "# shear_range=0.2\n",
    "shear_range=0.1\n",
    "# zoom_range=0.2\n",
    "zoom_range=0.1\n",
    "horizontal_flip=True\n",
    "\n",
    "\n",
    "# flow from directory function\n",
    "# Target Image dimention\n",
    "target_size=(224, 224)\n",
    "\n",
    "# Batch size\n",
    "# train\n",
    "# batch_size=32\n",
    "batch_size=64\n",
    "# batch_size=128\n",
    "\n",
    "# validation\n",
    "validation_batch_size=1\n",
    "# test\n",
    "test_batch_size=1\n",
    "\n",
    "# shuffle\n",
    "# test\n",
    "test_shuffle=False\n",
    "\n",
    "# validation split for train\n",
    "validation_split=0.0\n",
    "\n",
    "# class mode\n",
    "# class_mode='binary'\n",
    "class_mode='categorical'\n",
    "# class_mode='sparse'\n",
    "\n",
    "\n",
    "classes = ['Normal', 'PNEUMONIA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_transformed_image_batch(training_dir, target_size, classes, class_mode=class_mode, batch_size=batch_size, rescale=rescale, shear_range=shear_range, zoom_range=zoom_range, horizontal_flip=horizontal_flip)       \n",
    "\n",
    "validation_generator = get_transformed_image_batch(validation_dir, target_size, classes, class_mode=class_mode, batch_size=validation_batch_size, rescale=rescale)       \n",
    "\n",
    "test_generator = get_transformed_image_batch(validation_dir, target_size, classes, class_mode=class_mode, batch_size=test_batch_size, shuffle = test_shuffle, rescale=rescale) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Adjustmanet for Class Label Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_generator.classes\n",
    "class_weight=get_class_weight(y)\n",
    "# class_weight=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model and Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model and log output directory\n",
    "model_dir=output_directory + r\"models/\"+time.strftime('%Y%m%d%H%M%S')+\"/\"\n",
    "log_dir=output_directory + r\"logs\"+time.strftime('%Y%m%d%H%M%S')+\"/\"\n",
    "\n",
    "mk_reset_dir(model_dir, remove=True)\n",
    "mk_reset_dir(log_dir, remove=True)\n",
    "\n",
    "\n",
    "\n",
    "# make or reset directory\n",
    "# mk_reset_dir(model_dir, False)\n",
    "# mk_reset_dir(log_dir, False)\n",
    "\n",
    "init_model_file=model_dir+\"base-\"+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "model_file=model_dir+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "retrain_model_file=model_dir+\"retrain-{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(3,150,150)\n",
    "activation='relu'\n",
    "activation2='sigmoid'\n",
    "padding=\"same\"\n",
    "padding2=\"valid\"\n",
    "pool_size=(2, 2)\n",
    "dilation_rate=(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Base Model and Training Configuration for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Base Model - InceptionV3 (pretrained) initial training settings\n",
    "\n",
    "# inception base top layer discarded\n",
    "include_top=False\n",
    "\n",
    "# number of layers freezed\n",
    "non_trainable_index = 249\n",
    "\n",
    "# init_optimizer=optimizers.Adam()\n",
    "init_optimizer=optimizers.Adam(0.000001)\n",
    "\n",
    "print_layers=False\n",
    "\n",
    "# initial epochs on only output layers\n",
    "# init_epochs=1\n",
    "# initial_epochs=3\n",
    "init_epochs=15\n",
    "\n",
    "# verbose\n",
    "init_verbose=0\n",
    "\n",
    "# callbacks\n",
    "init_callbacks=None\n",
    "\n",
    "# model report\n",
    "print_layers=True\n",
    "\n",
    "\n",
    "### Full model training parameter configuration for Loss, Optimizer and Performance Metrics\n",
    "\n",
    "# optimizer\n",
    "# adam lr=0.01/0.001/0.0001/0.00001/0.000001, decay = decay=1e-5/ 1e-6\n",
    "# optimizer=optimizers.Adam()\n",
    "# optimizer=Adam(lr=0.0001, decay=1e-5)\n",
    "# optimizer=optimizers.Adam(0.000001, decay=1e-7)\n",
    "optimizer=optimizers.Adam(0.1)\n",
    "optimizer=optimizers.Adam(0.00001, decay=1e-7)\n",
    "\n",
    "\n",
    "\n",
    "# loss function\n",
    "# loss='binary_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "# performance metrics ('accuracy', 'binary_accuracy', precision, recall)\n",
    "# metrics=['accuracy']\n",
    "metrics=['mae', 'acc']\n",
    "\n",
    "\n",
    "### Main model training parameter configuration\n",
    "\n",
    "# epochs = 20/30/50\n",
    "epochs = 30\n",
    "\n",
    "# steps\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "# verbose 0=nothing 1=each line\n",
    "verbose=0\n",
    "\n",
    "\n",
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard\n",
    "\n",
    "# checkpoint\n",
    "ck_monitor='val_acc'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "red_lr_patience=10\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "red_lr_min_lr=0.0\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "# es_patience=0\n",
    "es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "update_freq='epoch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks - checkpoint, reduce_lr, early_stopping, tensorboard\n",
    "init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/82 [==============================] - 158s 2s/step - loss: 1.0477 - mean_absolute_error: 0.5084 - acc: 0.4630 - val_loss: 0.9789 - val_mean_absolute_error: 0.5759 - val_acc: 0.3438\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 136s 2s/step - loss: 1.0020 - mean_absolute_error: 0.4828 - acc: 0.5722 - val_loss: 0.9412 - val_mean_absolute_error: 0.5676 - val_acc: 0.3406\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.9652 - mean_absolute_error: 0.4707 - acc: 0.6170 - val_loss: 0.9077 - val_mean_absolute_error: 0.5589 - val_acc: 0.3531\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 119s 1s/step - loss: 0.9361 - mean_absolute_error: 0.4580 - acc: 0.6650 - val_loss: 0.8859 - val_mean_absolute_error: 0.5520 - val_acc: 0.3469\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 120s 1s/step - loss: 0.8929 - mean_absolute_error: 0.4434 - acc: 0.7090 - val_loss: 0.8642 - val_mean_absolute_error: 0.5448 - val_acc: 0.3594\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 118s 1s/step - loss: 0.8626 - mean_absolute_error: 0.4296 - acc: 0.7378 - val_loss: 0.8532 - val_mean_absolute_error: 0.5399 - val_acc: 0.3750\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.8386 - mean_absolute_error: 0.4195 - acc: 0.7569 - val_loss: 0.8163 - val_mean_absolute_error: 0.5276 - val_acc: 0.4062\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.8162 - mean_absolute_error: 0.4087 - acc: 0.7742 - val_loss: 0.8074 - val_mean_absolute_error: 0.5228 - val_acc: 0.4094\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.7894 - mean_absolute_error: 0.3990 - acc: 0.7887 - val_loss: 0.7811 - val_mean_absolute_error: 0.5125 - val_acc: 0.4500\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.7698 - mean_absolute_error: 0.3881 - acc: 0.8030 - val_loss: 0.7711 - val_mean_absolute_error: 0.5072 - val_acc: 0.4719\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.7489 - mean_absolute_error: 0.3792 - acc: 0.8125 - val_loss: 0.7535 - val_mean_absolute_error: 0.4989 - val_acc: 0.5188\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.7302 - mean_absolute_error: 0.3694 - acc: 0.8258 - val_loss: 0.7514 - val_mean_absolute_error: 0.4964 - val_acc: 0.5125\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.7145 - mean_absolute_error: 0.3621 - acc: 0.8287 - val_loss: 0.7326 - val_mean_absolute_error: 0.4872 - val_acc: 0.5406\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.7037 - mean_absolute_error: 0.3551 - acc: 0.8289 - val_loss: 0.7341 - val_mean_absolute_error: 0.4862 - val_acc: 0.5406\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.6821 - mean_absolute_error: 0.3463 - acc: 0.8363 - val_loss: 0.7178 - val_mean_absolute_error: 0.4775 - val_acc: 0.5437\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.6753 - mean_absolute_error: 0.3450 - acc: 0.8352 - val_loss: 0.7008 - val_mean_absolute_error: 0.4680 - val_acc: 0.5625\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.6618 - mean_absolute_error: 0.3309 - acc: 0.8462 - val_loss: 0.7123 - val_mean_absolute_error: 0.4724 - val_acc: 0.5437\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.6497 - mean_absolute_error: 0.3308 - acc: 0.8430 - val_loss: 0.6981 - val_mean_absolute_error: 0.4646 - val_acc: 0.5531\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.6394 - mean_absolute_error: 0.3254 - acc: 0.8460 - val_loss: 0.6835 - val_mean_absolute_error: 0.4556 - val_acc: 0.5844\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.6286 - mean_absolute_error: 0.3179 - acc: 0.8525 - val_loss: 0.6862 - val_mean_absolute_error: 0.4560 - val_acc: 0.5656\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.6177 - mean_absolute_error: 0.3138 - acc: 0.8527 - val_loss: 0.6780 - val_mean_absolute_error: 0.4503 - val_acc: 0.5844\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.6057 - mean_absolute_error: 0.3040 - acc: 0.8628 - val_loss: 0.6747 - val_mean_absolute_error: 0.4475 - val_acc: 0.5875\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.6007 - mean_absolute_error: 0.3033 - acc: 0.8540 - val_loss: 0.6720 - val_mean_absolute_error: 0.4454 - val_acc: 0.5875\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.6007 - mean_absolute_error: 0.3001 - acc: 0.8592 - val_loss: 0.6684 - val_mean_absolute_error: 0.4429 - val_acc: 0.5875\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.5816 - mean_absolute_error: 0.2913 - acc: 0.8672 - val_loss: 0.6680 - val_mean_absolute_error: 0.4418 - val_acc: 0.5813\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.5748 - mean_absolute_error: 0.2898 - acc: 0.8619 - val_loss: 0.6597 - val_mean_absolute_error: 0.4362 - val_acc: 0.6094\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.5790 - mean_absolute_error: 0.2897 - acc: 0.8619 - val_loss: 0.6602 - val_mean_absolute_error: 0.4361 - val_acc: 0.6062\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.5712 - mean_absolute_error: 0.2872 - acc: 0.8637 - val_loss: 0.6487 - val_mean_absolute_error: 0.4282 - val_acc: 0.6219\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.5631 - mean_absolute_error: 0.2795 - acc: 0.8678 - val_loss: 0.6474 - val_mean_absolute_error: 0.4271 - val_acc: 0.6219\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.5556 - mean_absolute_error: 0.2764 - acc: 0.8725 - val_loss: 0.6455 - val_mean_absolute_error: 0.4254 - val_acc: 0.6250\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 117s 1s/step - loss: 0.5477 - mean_absolute_error: 0.2747 - acc: 0.8744 - val_loss: 0.6390 - val_mean_absolute_error: 0.4203 - val_acc: 0.6344\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 140s 2s/step - loss: 0.5496 - mean_absolute_error: 0.2722 - acc: 0.8721 - val_loss: 0.6338 - val_mean_absolute_error: 0.4162 - val_acc: 0.6406\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 165s 2s/step - loss: 0.5407 - mean_absolute_error: 0.2676 - acc: 0.8674 - val_loss: 0.6369 - val_mean_absolute_error: 0.4184 - val_acc: 0.6312\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 176s 2s/step - loss: 0.5329 - mean_absolute_error: 0.2669 - acc: 0.8716 - val_loss: 0.6341 - val_mean_absolute_error: 0.4164 - val_acc: 0.6375\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 167s 2s/step - loss: 0.5303 - mean_absolute_error: 0.2666 - acc: 0.8731 - val_loss: 0.6328 - val_mean_absolute_error: 0.4154 - val_acc: 0.6406\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 127s 2s/step - loss: 0.5267 - mean_absolute_error: 0.2653 - acc: 0.8750 - val_loss: 0.6304 - val_mean_absolute_error: 0.4135 - val_acc: 0.6500\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 144s 2s/step - loss: 0.5194 - mean_absolute_error: 0.2621 - acc: 0.8775 - val_loss: 0.6296 - val_mean_absolute_error: 0.4128 - val_acc: 0.6469\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 156s 2s/step - loss: 0.5248 - mean_absolute_error: 0.2622 - acc: 0.8729 - val_loss: 0.6290 - val_mean_absolute_error: 0.4122 - val_acc: 0.6469\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 154s 2s/step - loss: 0.5187 - mean_absolute_error: 0.2592 - acc: 0.8750 - val_loss: 0.6281 - val_mean_absolute_error: 0.4115 - val_acc: 0.6469\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 156s 2s/step - loss: 0.5318 - mean_absolute_error: 0.2627 - acc: 0.8678 - val_loss: 0.6277 - val_mean_absolute_error: 0.4112 - val_acc: 0.6469\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 153s 2s/step - loss: 0.5276 - mean_absolute_error: 0.2629 - acc: 0.8756 - val_loss: 0.6277 - val_mean_absolute_error: 0.4112 - val_acc: 0.6469\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 153s 2s/step - loss: 0.5223 - mean_absolute_error: 0.2623 - acc: 0.8758 - val_loss: 0.6272 - val_mean_absolute_error: 0.4108 - val_acc: 0.6469\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 153s 2s/step - loss: 0.5211 - mean_absolute_error: 0.2615 - acc: 0.8739 - val_loss: 0.6263 - val_mean_absolute_error: 0.4100 - val_acc: 0.6469\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 152s 2s/step - loss: 0.5309 - mean_absolute_error: 0.2636 - acc: 0.8727 - val_loss: 0.6255 - val_mean_absolute_error: 0.4092 - val_acc: 0.6469\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 153s 2s/step - loss: 0.5230 - mean_absolute_error: 0.2590 - acc: 0.8748 - val_loss: 0.6250 - val_mean_absolute_error: 0.4088 - val_acc: 0.6500\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 155s 2s/step - loss: 0.5177 - mean_absolute_error: 0.2584 - acc: 0.8733 - val_loss: 0.6247 - val_mean_absolute_error: 0.4086 - val_acc: 0.6500\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 152s 2s/step - loss: 0.5140 - mean_absolute_error: 0.2575 - acc: 0.8758 - val_loss: 0.6238 - val_mean_absolute_error: 0.4077 - val_acc: 0.6500\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 152s 2s/step - loss: 0.5288 - mean_absolute_error: 0.2593 - acc: 0.8788 - val_loss: 0.6244 - val_mean_absolute_error: 0.4083 - val_acc: 0.6500\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 152s 2s/step - loss: 0.5249 - mean_absolute_error: 0.2592 - acc: 0.8798 - val_loss: 0.6244 - val_mean_absolute_error: 0.4084 - val_acc: 0.6469\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 152s 2s/step - loss: 0.5213 - mean_absolute_error: 0.2587 - acc: 0.8746 - val_loss: 0.6244 - val_mean_absolute_error: 0.4084 - val_acc: 0.6469\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 153s 2s/step - loss: 0.5119 - mean_absolute_error: 0.2564 - acc: 0.8767 - val_loss: 0.6243 - val_mean_absolute_error: 0.4083 - val_acc: 0.6469\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 156s 2s/step - loss: 0.5322 - mean_absolute_error: 0.2619 - acc: 0.8721 - val_loss: 0.6243 - val_mean_absolute_error: 0.4083 - val_acc: 0.6469\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, None, 2 0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2050        dense_1[0][0]                    \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 12,788,130\n",
      "Trainable params: 2,100,226\n",
      "Non-trainable params: 10,687,904\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "# # get inception model\n",
    "# init_epochs = 100\n",
    "# print_layers=False\n",
    "# model = get_inception_model(train_generator, validation_generator, init_epochs, init_verbose, init_optimizer, loss, metrics, tensorboard, init_callbacks, num_class, include_top, non_trainable_index, print_layers)\n",
    "# main_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model Performance with Minimum Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.34      0.33      0.34       121\n",
      "  PNEUMONIA       0.60      0.62      0.61       199\n",
      "\n",
      "avg / total       0.51      0.51      0.51       320\n",
      "\n",
      "Accuracy: 41.13%\n",
      "Loss: 0.63\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 40,  81],\n",
       "       [ 76, 123]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_report=True\n",
    "\n",
    "y_preds, y_classes, CM, CM_report = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "accuracy, loss =  model_evaluate(model, test_generator, print_report)\n",
    "\n",
    "show_confusion_matrix(test_generator, y_classes, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/82 [==============================] - 157s 2s/step - loss: 0.5078 - mean_absolute_error: 0.2512 - acc: 0.8779 - val_loss: 0.9997 - val_mean_absolute_error: 0.3590 - val_acc: 0.6375\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 128s 2s/step - loss: 0.4718 - mean_absolute_error: 0.2345 - acc: 0.8857 - val_loss: 1.0292 - val_mean_absolute_error: 0.3546 - val_acc: 0.6469\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4399 - mean_absolute_error: 0.2202 - acc: 0.8933 - val_loss: 1.1758 - val_mean_absolute_error: 0.3716 - val_acc: 0.6125\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.4295 - mean_absolute_error: 0.2100 - acc: 0.8944 - val_loss: 1.0839 - val_mean_absolute_error: 0.3469 - val_acc: 0.6406\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 127s 2s/step - loss: 0.4231 - mean_absolute_error: 0.2102 - acc: 0.9011 - val_loss: 1.1311 - val_mean_absolute_error: 0.3642 - val_acc: 0.6219\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 134s 2s/step - loss: 0.4372 - mean_absolute_error: 0.2115 - acc: 0.8929 - val_loss: 1.1186 - val_mean_absolute_error: 0.3537 - val_acc: 0.6344\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 140s 2s/step - loss: 0.4078 - mean_absolute_error: 0.2032 - acc: 0.9026 - val_loss: 1.1470 - val_mean_absolute_error: 0.3666 - val_acc: 0.6188\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 134s 2s/step - loss: 0.4170 - mean_absolute_error: 0.2073 - acc: 0.8982 - val_loss: 1.0664 - val_mean_absolute_error: 0.3435 - val_acc: 0.6438\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 140s 2s/step - loss: 0.4409 - mean_absolute_error: 0.2111 - acc: 0.8960 - val_loss: 1.1345 - val_mean_absolute_error: 0.3693 - val_acc: 0.6156\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 141s 2s/step - loss: 0.4284 - mean_absolute_error: 0.2078 - acc: 0.8981 - val_loss: 1.0998 - val_mean_absolute_error: 0.3529 - val_acc: 0.6344\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 134s 2s/step - loss: 0.4256 - mean_absolute_error: 0.2087 - acc: 0.8977 - val_loss: 1.0864 - val_mean_absolute_error: 0.3505 - val_acc: 0.6375\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 138s 2s/step - loss: 0.4156 - mean_absolute_error: 0.2063 - acc: 0.8988 - val_loss: 1.1425 - val_mean_absolute_error: 0.3669 - val_acc: 0.6188\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 138s 2s/step - loss: 0.4148 - mean_absolute_error: 0.2039 - acc: 0.9040 - val_loss: 1.1136 - val_mean_absolute_error: 0.3552 - val_acc: 0.6312\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 137s 2s/step - loss: 0.4284 - mean_absolute_error: 0.2099 - acc: 0.8965 - val_loss: 1.1023 - val_mean_absolute_error: 0.3564 - val_acc: 0.6281\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 135s 2s/step - loss: 0.4222 - mean_absolute_error: 0.2074 - acc: 0.9011 - val_loss: 1.1770 - val_mean_absolute_error: 0.3668 - val_acc: 0.6219\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 134s 2s/step - loss: 0.4198 - mean_absolute_error: 0.2099 - acc: 0.8992 - val_loss: 1.0820 - val_mean_absolute_error: 0.3544 - val_acc: 0.6312\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 139s 2s/step - loss: 0.4321 - mean_absolute_error: 0.2089 - acc: 0.8975 - val_loss: 1.1385 - val_mean_absolute_error: 0.3617 - val_acc: 0.6250\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999146890344e-15.\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 139s 2s/step - loss: 0.4189 - mean_absolute_error: 0.2080 - acc: 0.8986 - val_loss: 1.1123 - val_mean_absolute_error: 0.3574 - val_acc: 0.6281\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 141s 2s/step - loss: 0.4192 - mean_absolute_error: 0.2058 - acc: 0.9013 - val_loss: 1.1097 - val_mean_absolute_error: 0.3547 - val_acc: 0.6312\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999998977483753e-16.\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 141s 2s/step - loss: 0.4180 - mean_absolute_error: 0.2075 - acc: 0.9013 - val_loss: 1.1041 - val_mean_absolute_error: 0.3590 - val_acc: 0.6250\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 146s 2s/step - loss: 0.4063 - mean_absolute_error: 0.2030 - acc: 0.9019 - val_loss: 1.0973 - val_mean_absolute_error: 0.3523 - val_acc: 0.6375\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999998977483754e-17.\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 140s 2s/step - loss: 0.4220 - mean_absolute_error: 0.2082 - acc: 0.8946 - val_loss: 1.1414 - val_mean_absolute_error: 0.3658 - val_acc: 0.6188\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 139s 2s/step - loss: 0.4265 - mean_absolute_error: 0.2084 - acc: 0.8994 - val_loss: 1.0873 - val_mean_absolute_error: 0.3497 - val_acc: 0.6375\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999998845134856e-18.\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 143s 2s/step - loss: 0.4156 - mean_absolute_error: 0.2063 - acc: 0.8969 - val_loss: 1.1364 - val_mean_absolute_error: 0.3586 - val_acc: 0.6281\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 145s 2s/step - loss: 0.4288 - mean_absolute_error: 0.2097 - acc: 0.8960 - val_loss: 1.1175 - val_mean_absolute_error: 0.3602 - val_acc: 0.6250\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999010570977e-19.\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 146s 2s/step - loss: 0.4154 - mean_absolute_error: 0.2052 - acc: 0.9043 - val_loss: 1.1186 - val_mean_absolute_error: 0.3605 - val_acc: 0.6250\n",
      "Epoch 27/100\n",
      "36/82 [============>.................] - ETA: 1:09 - loss: 0.4327 - mean_absolute_error: 0.2117 - acc: 0.8928"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-dc30efb20607>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     class_weight=class_weight)\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "\n",
    "epochs=100\n",
    "optimizer=optimizers.adam(lr=0.000001, decay=1e-6)\n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-a3d2b0e188e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mlabel_fontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mplot_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfig_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfig_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle_fontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle_fontsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_fontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_fontsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_val=[['acc', 'val_acc'], ['loss', 'val_loss']]\n",
    "\n",
    "title = ['Model accuracy', 'Model loss']\n",
    "\n",
    "xlabel = ['Epoch', 'Epoch']\n",
    "ylabel = ['Accuracy', 'Loss']\n",
    "\n",
    "legend = ['Train', 'Val']\n",
    "\n",
    "fig_size=(14, 5)\n",
    "\n",
    "\n",
    "title_fontsize=17\n",
    "label_fontsize=15\n",
    "\n",
    "plot_history(history, plot_val, title, xlabel, ylabel, fig_size=fig_size, title_fontsize=title_fontsize, label_fontsize=label_fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance of All Models on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model No: 1\n",
      "Model File: base-42-val_acc-0.65-val_loss-0.63.hdf5\n",
      "********************************************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAHmCAYAAABOJeUVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAH45JREFUeJzt3XmYZVV97+HvD1pABpmRQRnECBJuVHAg4IAGcQIFEQGJ4JyocQggaOIVEIE4YC6IiYIJoIADDqAMDiCY2ICAIyoooojMkzSz0N3r/nFOYVFWNwXd1Yuuet/nqafOXmfvfdbBp9pP7b3r7GqtBQCghyV6TwAAmL6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuZvSeAH9ptdVWa+utt37vacCUdds99/WeAkxp119zVW774801kXWFyCPQeuutn5k/uKj3NGDK+s4l1/eeAkxpe+267YTXdWoGAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0M2M3hOYLqrqgCRPbK39fe+5sGDmzJmTrZ719Ky9zjr56imn5uzvnpV/2e89mTt3bpZbfvkc/V/HZsMnPrH3NGGxtNxSS2bzdVe8f3nZpZbMr66/M0vNqKy5wtJpSe6dPTc/vuq2/Gn23H4TZaGZUkdEquqKqrq+qpYbNfamqjqn47SYYo484vBs9OQn37/8zn96a4757An5wQ9/kl12fU3+7ZAPdZwdLN7uvHdO/uc3t9z/NWduy3W33ZPLb7wr3xuOXX/7n/KkNZZ78J2xWJhSITI0I8m7FmQHNTAV/9uwgK666qp884zT8vo3vOn+sarKbbfdliS57bZZWWvttXtND6aU1ZdfKnfdOyd33zc3s+e2+8eXXKI6zoqFbSr+n+1Hk+xTVSuNfaKqtqyqC6tq1vD7lqOeO6eqDq6qmUnuSvKE4diHqurcqrqjqr5RVatW1QlVddtwH+uP2sfhVfWH4XM/rKrnLIL3yyL0nr3fnYMP/UiWWOLPPzr/8enPZMeXvzQbrv+4nHjC57LPvu/tOEOYOtZecZlcPeue+5c3fuxy2Waj1bLOSo/Or66/o+PMWJimYohclOScJPuMHqyqVZKcluSIJKsm+XiS06pq1VGrvTbJW5KskOT3w7Fdh+PrJNkwyXlJjkmySpJLkuw/avsLkzx1+NyJSU6qqmUW3lujp9NPOzVrrL5GNtt88weMf+Lwf8/Xvn56Lr/iqrx2z9dnv3326jRDmDqqkjUfs3SumfWn+8cuvf7OnPmrm3L1rXdn/VWX7Tg7FqapGCJJ8oEk76iq1UeNvSzJZa21z7XWZrfWPp/k0iTbj1rn2NbaL4bP3zccO6a1dnlrbVaSM5Jc3lo7s7U2O8lJSZ42snFr7fjW2s3D7Q9LsnSSjSYy4ap6S1VdVFUX3XjTjQ/7jTN5zjt3Zk499evZ6InrZ4/dd805Z383O778Zbn4Zz/NM5/1rCTJq3beJeeff27nmcLib43ll86su+/LveNckHr1rfdkrRX9jjdVTMkQaa39PMmpSUYfI187fz7KMeL3GRzpGPGHcXZ3/ajHd4+zvPzIQlXtXVWXDE/93JpkxSSrTXDOR7XWnt5ae/rqq63+4BuwyB108KG5/Iqr8qvfXJHPnvCFbP38F+Skr56S22bNymW//nWS5LtnficbbfzkB9kT8GDWWemBp2WWW2rJ+x8/9jFL544/ze4xLSbBVP7z3f2T/CjJYcPla5KsN2addZN8c9Ryy8M0vB5kvyR/l+QXrbW5VfXHJK6qmsJmzJiRT37q6Oz26p2yxBJLZKWVV86nj/7v3tOCxdqSNbhQ9WdX33b/2JPXXD7LLT0jaS133Tc3F496jsXblA2R1tpvquqLSd6Z5OIkpyf5RFW9JsmXkuyUZJMMjpwsDCskmZ3kxiQzquq9SR6zkPbNI8xzn7d1nvu8rZMkr9hhx7xihx37TgimkDkt+dYlDzxFfdGVszrNhsk2JU/NjPLBJMslSWvt5iTbJdk7yc1J9k2yXWvtpoX0Wt/K4BqSX2dwyueejH+qBwAYqtYe9tkIJsnmmz+9zfzBRb2nAVPWdy65/sFXAh62vXbdNpf94qcTujRhqh8RAQAewYQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG5mzOuJqro9SRtZHH5vw8ettfaYSZ4bADDFzTNEWmsrLMqJAADTz4ROzVTVs6vq9cPHq1XVBpM7LQBgOnjQEKmq/ZPsl+R9w6Glkhw/mZMCAKaHiRwR2THJy5PcmSSttWuSOG0DACywiYTIva21luGFq1W13OROCQCYLiYSIl+qqk8nWamq3pzkzCRHT+60AIDpYJ5/NTOitfaxqnphktuSPCnJB1pr35n0mQEAU96DhsjQxUkencHpmYsnbzoAwHQykb+aeVOSC5K8MsmrkpxfVW+Y7IkBAFPfRI6IvCfJ01prNydJVa2a5Nwk/z2ZEwMApr6JXKx6VZLbRy3fnuQPkzMdAGA6md+9ZvYaPrw6yQ+q6pQMrhF5RQanagAAFsj8Ts2MfGjZ5cOvEadM3nQAgOlkfje9O3BRTgQAmH4e9GLVqlo9yb5J/jrJMiPjrbUXTOK8AIBpYCIXq56Q5NIkGyQ5MMkVSS6cxDkBANPEREJk1dbafyW5r7X2vdbaG5JsMcnzAgCmgYl8jsh9w+/XVtXLklyT5HGTNyUAYLqYSIh8qKpWTLJ3kk8keUySf57UWQEA08JEbnp36vDhrCTPn9zpAADTyfw+0OwTGXyA2bhaa++clBmRO/40O+dffnPvacCU9eo9Duo9BZjS/vS7aye87vyOiFy04FMBAJi3+X2g2XGLciIAwPQzkT/fBQCYFEIEAOhGiAAA3TxoiFTVk6rqrKr6+XD5b6rq/ZM/NQBgqpvIEZGjk7wvw09Yba39LMmukzkpAGB6mEiILNtau2DM2OzJmAwAML1MJERuqqoNM/xws6p6VZKJf1IJAMA8TOReM29PclSSjavq6iS/S/L3kzorAGBamMi9Zn6bZJuqWi7JEq212yd/WgDAdPCgIVJVHxiznCRprX1wkuYEAEwTEzk1c+eox8sk2S7JJZMzHQBgOpnIqZnDRi9X1ceSfH3SZgQATBsP55NVl03yhIU9EQBg+pnINSIXZ/inu0mWTLJ6EteHAAALbCLXiGw36vHsJNe31nygGQCwwOYbIlW1RJLTWmubLqL5AADTyHyvEWmtzU3y06padxHNBwCYRiZyamatJL+oqgsy6k95W2svn7RZAQDTwkRC5MBJnwUAMC1NJERe2lrbb/RAVX04yfcmZ0oAwHQxkc8ReeE4Yy9Z2BMBAKafeR4Rqaq3JnlbkidU1c9GPbVCkpmTPTEAYOqb36mZE5OckeTQJO8dNX57a+2WSZ0VADAtzDNEWmuzksxKstuimw4AMJ08nHvNAAAsFEIEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuZvSeACxOrvztZfngXm++f/naP1yR17/zvdn2Fbvkg3u9KdddfWXWXGfd7P/v/5UVVlyp40xh8fGp/XfPS567aW685fY8fedDkiSHvHuHvPS5m+be++bkd1fdlLfsf3xm3XF3HjVjyRz5/t2y2SbrZm6bm30+8pX87w8v6/wOWBCTdkSkqq6oqrur6o6qur6qjqmq5avqnKq6p6oeP2rdbarqinlsO/J15PC5A6rq+HFer1XVE4ePzxkuP2XMOicPx7ceNbZJVX29qmZV1e1VdXZVbTnq+fWH25w2Zl/HV9UBw8dbV9VV48zp2KqaXVVrP+T/gDwirfuEv8pnTj4nnzn5nHz6K2dl6Ucvm2dv87KcePTh2WyL5+b4b12YzbZ4bk48+vDeU4XFxue+cX5e8fZPPmDsrPMvzeY7H5Jn7nJoLvv9DXnPG7ZNkrzhlVslSZ7x6kOy3T8emX/ba8dU1SKfMwvPZJ+a2b61tnySzZI8I8n7h+N3Jvm/E9l21Nc/PcTX/nWSPUYWqmrVJFskuXHU2IZJZia5OMkGSdZO8rUk366qvx2zvy2qaquJvnhVLZdkpySzkuz+EOfOYuBH5/1P1n78+llzncfn3LPOyIt22CVJ8qIddsnMM0/vPDtYfMz80eW5ZdZdDxg76/xLM2fO3CTJBRf/Lus8dnCEceMnrJmzL/hVkuTGP96RWbffnc03WXfRTpiFapFcI9JauzrJGUk2HQ4dkWS3kSMYk+SEJLtU1ZLD5d0yiIx7R61zQJLzWmv/2lq7pbV2e2vtiCSfS/LhMfv7SJIPPYTX3ynJrUk+mGTPhzF/HuG+e/rX8ncve2WS5Jabb8yqa6yZJFl1jTXzx1tu6jk1mFL2eMXf5lszf5kkufjXV2f7rf9Pllxyiay39qp52iaPz+PWXLnzDFkQiyREhqdhXprkx8Ohq5McnUEITJZrkvwyybbD5T2SfHbMOi9MctI4234pyVZVteyosU8meVJVbTPB198zyeeTfCHJxlW12fxWrqq3VNVFVXXRrD/ePMGXoJf77r035373m3nei1/eeyowpe37xhdlzpy5+cLpFyZJjjvlvFx9/a2ZecK++eh7dsr5P/1dZs+Z03mWLIjJvlj15KqancHpidOSHJLBkZEkOTTJb6rqrx9k2xHvaa0d/RBf/7NJ9qiq3yZZqbV23phziasluXac7a7NINJGZ/Y9SQ7O4KjImfN70apaN8nzk+zdWru+qs7KIEx+NK9tWmtHJTkqSTba9KntQd4Xnf3gf8/Mkzb5m6yy2hpJklVWXT0333BdVl1jzdx8w3VZeZXVOs8QFn+7b/+svPS5m+Yl/3DE/WNz5szNvod99f7ls4/dK7+58sbxNmcxMdlHRHZora3UWluvtfa21trdI0+01m5McmQGpy7mt+3I10iEzE7yqNErVtXI8n1j9vHVJC9I8o4MTreMdVOStcYZXyvJ3CR/HDN+dJLHVtX285jziNcmuaS19pPh8glJXjNqnizmvnvaV/OC4WmZJNnyBS/Ot07+YpLkWyd/MVv+3Ut6TQ2mhBdu+eTs/bpt8qp3fzp33/Pnf9ofvcyjsuwySyVJXvCsjTN7ztxc+tvrek2ThaD3n+9+NMlvk1zwELa5MsnYENggyZwMTvncr7V2V1WdkeStSTYcZ19nJtk5yTFjxl+dwbUjd40+gtJau6+qDkxyUJJfzGeOeyRZt6pGfjpmJFk1yUuSfH0+27EYuOfuu/LDmd/LXgd+/P6x3d78rhz4z2/M6V85Pmus9bgc8P/+u+MMYfFy3KGvy3M2/6usttLy+c03D8pBnzo973n9tll6qRk59T8Hf6dwwcVX5J0HfyGrr7xCvvEfb8/cuS3X3Hhr3vj+4zrPngXVNURaa7dW1WFJ9k1y+wQ3+2aSI6rqtRlcf7FCBqd8vtxamz3O+v+S5DOttSvGee7AJBdW1cFJDsvgiMrrMgiJbcdZPxkcWdkvyYuT/MUfrw//2mbDJE/LqL/QGe5/zwiRxd4yj142p/zggf/Tr7jyKvn4sV/rNCNYvO35vmP/Yuy4k88bd90rr70lT9nxoEmeEYvSI+GTVQ/P4GjGWN8Y8zkiX0uS1toNGVz4+g9Jbkjy8wyuQXnreDtvrV3TWvv+PJ67LMmzkzwlyRUZXBuyU5IXtdZmzmObOUn2T7LKPN7PnklOaa1d3Fq7buRr+D63q6p5bQcA00615rrIR5qNNn1q+/RXzuo9DZiyXrLr/r2nAFPan371pcy964YJfdLcI+GICAAwTQkRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6ESIAQDdCBADoRogAAN0IEQCgGyECAHQjRACAboQIANCNEAEAuhEiAEA3QgQA6EaIAADdCBEAoBshAgB0I0QAgG6ECADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIAdCNEAIBuhAgA0I0QAQC6qdZa7zkwRlXdmOT3vefBhK2W5Kbek4Apzs/Z4mW91trqE1lRiMACqqqLWmtP7z0PmMr8nE1dTs0AAN0IEQCgGyECC+6o3hOAacDP2RTlGhEAoBtHRACAboQIANCNEIFHkKo6oKqO7z0PgEVFiDDtVNUVVXV9VS03auxNVXVOx2nBI87wZ+Xuqrpj+DNzTFUtX1XnVNU9VfX4UetuU1VXzGPbka8jh8+NG9xV1arqicPH5wyXnzJmnZOH41uPGtukqr5eVbOq6vaqOruqthz1/PrDbU4bs6/jq+qA4eOtq+qqceZ0bFXNrqq1H/J/QCZEiDBdzUjyrgXZQQ34GWKq2761tnySzZI8I8n7h+N3Jvm/E9l21Nc/PcTX/nWSPUYWqmrVJFskuXHU2IZJZia5OMkGSdZO8rUk366qvx2zvy2qaquJvvjwl5WdksxKsvtDnDsT5B9RpquPJtmnqlYa+0RVbVlVFw5/u7pwzG9W51TVwVU1M8ldSZ4wHPtQVZ07/K3vG1W1alWdUFW3Dfex/qh9HF5Vfxg+98Oqes4ieL+wQFprVyc5I8mmw6Ejkuw2cgRjkpyQZJeqWnK4vFsGkXHvqHUOSHJea+1fW2u3tNZub60dkeRzST48Zn8fSfKhh/D6OyW5NckHk+z5MObPBAgRpquLkpyTZJ/Rg1W1SpLTMvhHdtUkH09y2vA3sRGvTfKWJCvkz/cE2nU4vk6SDZOcl+SYJKskuSTJ/qO2vzDJU4fPnZjkpKpaZuG9NVj4hqdhXprkx8Ohq5McnUEITJZrkvwyybbD5T2SfHbMOi9MctI4234pyVZVteyosU8meVJVbTPB198zyeeTfCHJxlW12UQnzsQJEaazDyR5R1WNvjHTy5Jc1lr7XGttdmvt80kuTbL9qHWOba39Yvj8fcOxY1prl7fWZmXwW+PlrbUzW2uzM/hH8mkjG7fWjm+t3Tzc/rAkSyfZaBLfJyyIk6vq1iTfT/K9JIeMeu7QJNtX1V/Pb9tRX29+GK//2SR7VNVGSVZqrZ035vnVklw7znbXZvD/cSuPGrsnycGZwFGRqlo3yfOTnNhauz7JWXFUZFIIEaat1trPk5ya5L2jhtfOX975+PcZHOkY8Ydxdnf9qMd3j7O8/MhCVe1dVZcMT/3cmmTFDP4xhUeiHVprK7XW1mutva21dvfIE621G5McmcGpi/ltO/J19HB8dpJHjV6xqkaW78sDfTXJC5K8I4PTLWPdlGStccbXSjI3yR/HjB+d5LFVtf1fbvIAr01ySWvtJ8PlE5K8ZtQ8WUiECNPd/knenD+HxjVJ1huzzroZHIYe8bA/jnh4Pch+SV6dZOXW2koZXAhXD3ef0NlHMzhysPlD2ObKJOuPGdsgyZw88GctrbW7MjjK+NaMHyJnJtl5nPFXZ3DtyF1j9ndfkgOTHJT5/9ztkcE1YNdV1XUZnKZdLclL5rMND4MQYVprrf0myReTvHM4dHoG55BfU1UzqmqXJJtkcORkYVghg98Gb0wyo6o+kOQxC2nfsMi11m5NcliSfR/CZt9MslFVvbaqHjW8NuuQJF8ens4c61+SPK+1dsU4zx2YZMvhReSrVNUKVfWODEJiv3m8/ucyOCX64vGeHP61zYZJnpnB9VxPzeAi3RPj9MxCJ0RgcFh5uSRprd2cZLskeye5OYN/XLdrrd20kF7rWxn8dvfrDE753JPxT/XA4uTwDI5mjPWNMZ8j8rUkaa3dkMGFr/+Q5IYkP8/gyOBbx9t5a+2a1tr35/HcZUmeneQpSa7I4NqQnZK8qLU2cx7bzMngaOgq83g/eyY5pbV2cWvtupGv4fvcbhhOLCRuegcAdOOICADQjRABALoRIgBAN0IEAOhGiAAA3QgRAKAbIQIsdqrqjuH3tavqyw+y7rvH3PhsIvvfuqr+4kPs5jU+Zp3XVdWRD/H1rqgqH/PPtCREgEeEUbd6n7DhB1296kFWe3eShxQiwKIjRIBJVVXrV9WlVXVcVf2sqr48coRieCTgA1X1/SQ7V9WGVfXNqvphVf1vVW08XG+Dqjqvqi6sqoPG7Pvnw8dLVtXHquri4eu8o6remcGNDM+uqrOH62073NePquqkqlp+OP7i4Ty/n+SVE3hfz6yqc6vqx8Pvo++g/Pjh+/hVVe0/apu/r6oLquonVfXphxNfMNUIEWBR2CjJUa21v0lyW5K3jXruntbas1trX0hyVJJ3tNY2T7JPkv8YrnN4kv9srT0jyXXzeI23ZHDjtKcNX+eE1toRGdzI8PmttecPT3+8P8k2rbXNklyUZK+qWiaDu7Jun+Q5SdacwHu6NMlzW2tPS/KBDO6VMuKZSXbP4B4lO1fV06vqyUl2SbJVa+2pGXwk+u4TeB2Y0mb0ngAwLfxh1H0/js/gJoMfGy5/MUmGRya2THJS1f03RV16+H2rDO4fkgxuWPbhcV5jmySfGrlpWmvtlnHW2SKDmxjOHL7GUknOS7Jxkt8N71uSqjo+g7CZnxWTHFdVf5XBHZlH3x7+O8P7FqWqvprBvVBmZ3CH2guHr/3oDO6zAtOaEAEWhbE3tRq9fOfw+xJJbh0eLZjIPsaqCa7zndbabg8YrHrqBLYd66AkZ7fWdqyq9ZOcM+q58d5vJTmutfa+h/g6MKU5NQMsCusOb62eJLsl+Ys7qbbWbkvyu6raOUlq4CnDp2cm2XX4eF6nM76d5B+rasZw+5E7pN6eZIXh4/OTbFVVTxyus2xVPSmD0ywbVNWGo+b4YFZMcvXw8evGPPfC4S3pH51kh+H8z0ryqqpaY2R+VbXeBF4HpjQhAiwKlyTZs6p+lsGt1/9zHuvtnuSNVfXTJL9I8orh+LuSvL2qLswgAMbzmSRXJvnZcPvXDMePSnJGVZ3dWrsxg2j4/HAu5yfZuLV2TwanYk4bXqz6+wm8p48kObSqZiYZe9Hp9zM4hfSTJF9prV3UWvtlBtenfHv42t9JstYEXgemtGrtoR6NBJi44WmLU1trm3aeCvAI5IgIANCNIyIAQDeOiAAA3QgRAKAbIQIAdCNEAIBuhAgA0M3/B3zsDreUhxaRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.41      0.40      0.40       121\n",
      "  PNEUMONIA       0.64      0.65      0.64       199\n",
      "\n",
      "avg / total       0.55      0.55      0.55       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "details = True\n",
    "# report_type = \"Acc_Loss\"\n",
    "report_type = \"Complete\"\n",
    "\n",
    "results=test_all_models(model_dir, details, report_type, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of  Performance Over All Epochs/Models based on Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "array=[[1,2,3],[2,3,4]]\n",
    "\n",
    "fig_size = (10, 8)\n",
    "title=[\"Test Dataset Performance (Accuracy)\", \"Test Dataset Performance (Loss)\"]\n",
    "xlabel=[\"Epoch\", \"Epoch\"]\n",
    "ylabel=[\"Accuracy (100%)\", \"Loss\"]\n",
    "\n",
    "line_plot_over_epochs_loss_acc(array, title, fig_size=fig_size, xlabel=xlabel, ylabel=ylabel, title_fontsize=title_fontsize, label_fontsize=label_fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_callbacks(checkpoint, reduce_lr, early_stopping, tensorboard)\n",
    "# reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration for Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file=model_dir+\"retrain-{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "### Full model training parameter configuration for Loss, Optimizer and Performance Metrics\n",
    "\n",
    "# optimizer\n",
    "# adam lr=0.01/0.001/0.0001/0.00001/0.000001, decay = decay=1e-5/ 1e-6\n",
    "optimizer=optimizers.Adam()\n",
    "\n",
    "\n",
    "# loss function\n",
    "# loss='binary_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "# performance metrics ('accuracy', 'binary_accuracy', precision, recall)\n",
    "metrics=['accuracy']\n",
    "\n",
    "\n",
    "### Main model training parameter configuration\n",
    "\n",
    "# epochs = 20/30/50\n",
    "epochs=30\n",
    "\n",
    "# steps\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "# verbose 0=nothing 1=each line\n",
    "verbose=0\n",
    "\n",
    "\n",
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard\n",
    "\n",
    "# checkpoint\n",
    "ck_monitor='val_acc'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "# red_lr_patience=5\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "# red_lr_min_lr=0.0001 # default\n",
    "red_lr_min_lr=0.000001\n",
    "\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "# es_patience=0\n",
    "es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "\n",
    "################################################ Retrain #########################################################\n",
    "epochs=epochs+1\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard for Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Best Model\n",
    "### Selecting best model file based on validation accuracy mentioned in file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best model file / checkpoint for retraining\n",
    "# model_path = model_dir+r\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "# model_path = model_dir+r\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "# best accuracy/ F-1 score\n",
    "# model_path = \"data/output/models/\"+\"17-val_acc-0.82-val_loss-0.42.hdf5\"\n",
    "\n",
    "# Lowest validation Loss\n",
    "# model_path = \"data/output/models/\"+\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "\n",
    "# Best Recall\n",
    "# model_path = \"data/output/models/\"+\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "model_path = model_dir+r\"20-val_acc-0.71-val_loss-1.26.hdf5\"\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "# retrain by loading last good model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    # verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight,\n",
    "    initial_epoch=initial_epoch)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    extracted_id = b[0]\n",
    "    \n",
    "    return extracted_id\n",
    "\n",
    "\n",
    "\n",
    "test_filenames = test_generator.filenames\n",
    "df_preds = pd.DataFrame(predictions, columns=classes)\n",
    "df_preds['file_names'] = test_filenames\n",
    "df_preds['id'] = df_preds['file_names'].apply(extract_id)\n",
    "df_preds.head()\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['Cancer']\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "roc_auc_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':image_id, \n",
    "                           'label':y_pred, \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('patch_preds.csv', columns=['label']) \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retriving actual labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (test_generator.class_indices)\n",
    "label_map_rev = {v: name_correct(k) for k,v in label_map.items()}\n",
    "num_batch_t = len(test_generator)\n",
    "print(label_map)\n",
    "print(label_map_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing accuracy for Model over Single Batch of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0, num_batch_t-1)\n",
    "y_img_batch, y_class_batch = test_generator[num] \n",
    "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
    "y_true = np.argmax(y_class_batch,-1)\n",
    "print(\"Selected Batch No: %d\\nBatch Size: %d\"%(num, len(y_pred)))\n",
    "print(\"Accuracy : \", sum(y_pred==y_true)/batch_size*100, \"%\")\n",
    "\n",
    "y_true_labels = [label_map_rev[c] for c in y_true]\n",
    "y_pred_labels = [label_map_rev[c] for c in y_pred]\n",
    "batch_size_t = len(y_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n",
    "Visualization of performance of a random test dataset batch and few random images from a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/result\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "\n",
    "cols = 8\n",
    "rows= batch_size_t/cols\n",
    "if batch_size_t%cols==0:\n",
    "    rows = int(batch_size_t/cols)\n",
    "else:\n",
    "    rows = int(batch_size_t/cols)+1\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org : \"\n",
    "pred_label_title_prefix = \"pred: \"\n",
    "\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "for i in range(0, batch_size_t): # how many imgs will show from the mxn grid\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[i])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[i]==y_pred_labels[i]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i], color=false_prediction_label_color)\n",
    "        \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)\n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/sample\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "cols = 4\n",
    "rows= 2\n",
    "\n",
    "count = rows*cols\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "# titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org:  \"\n",
    "pred_label_title_prefix = \"pred: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "\n",
    "batch_size_tmp = batch_size_t\n",
    "\n",
    "m = {}\n",
    "\n",
    "for i in range(0, count): \n",
    "    num = random.randint(0, batch_size_tmp-1)\n",
    "    while num in m:\n",
    "        num = random.randint(0, batch_size_tmp-1)\n",
    "    \n",
    "    m[num]=1\n",
    "    \n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[num])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[num]==y_pred_labels[num]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num], color=false_prediction_label_color)\n",
    "    \n",
    "   \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)   \n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
