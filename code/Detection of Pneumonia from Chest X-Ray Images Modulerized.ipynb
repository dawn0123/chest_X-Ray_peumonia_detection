{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "<pre>\n",
    "Author           : Anjana Tiha\n",
    "Project Name     : Detection of Pneumonia from Chest X-Ray Images using Convolutional Neural Network, \n",
    "                   and Transfer Learning.\n",
    "Description      : 1. Detected Pneumonia from Chest X-Ray images by retraining pretrained model “InceptionV3” \n",
    "                      with 5856 images of X-ray (1.15GB).\n",
    "                   2. For retraining removed output layers, freezed first few layers and Fine-tuned model for \n",
    "                      two new label classes (Pneumonia and Normal).\n",
    "                   3. Attained testing accuracy 83.44% and loss 0.42.\n",
    "Method           : \n",
    "Tools/Library    : Python, Keras, PyTorch, TensorFlow\n",
    "Version History  : 1.0.0.0\n",
    "Current Version  : 1.0.0.0\n",
    "Last Update      : 11.30.2018\n",
    "Comments         : Please use Anaconda editor for convenience of visualization.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "<pre>\n",
    "GitHub Link      : <a href=https://github.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitHub)</a>\n",
    "GitLab Link      : <a href=https://gitlab.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitLab)</a>\n",
    "Portfolio        : <a href=https://anjanatiha.wixsite.com/website>Anjana Tiha's Portfolio</a>\n",
    "</pre>\n",
    "\n",
    "#### Dataset\n",
    "<pre>\n",
    "Dataset Name     : Chest X-Ray Images (Pneumonia)\n",
    "Dataset Link     : <a href=https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia>Chest X-Ray Images (Pneumonia) Dataset (Kaggle)</a>\n",
    "                 : <a href=https://data.mendeley.com/datasets/rscbjbr9sj/2>Chest X-Ray Images (Pneumonia) Dataset (Original Dataset)</a>\n",
    "Original Paper   : <a href=https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5>Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning</a>\n",
    "                   (Daniel S. Kermany, Michael Goldbaum, Wenjia Cai, M. Anthony Lewis, Huimin Xia, Kang Zhang)\n",
    "                   https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library/Tools Version\n",
    "- Python - v3.6.7\n",
    "- argparse\n",
    "- random\n",
    "- numpy\n",
    "- shutil\n",
    "- gc\n",
    "- re\n",
    "- Keras - 2.2.4\n",
    "- Keras-preprocessing - v1.0.5\n",
    "- TensorFlow - 1.12\n",
    "- PIL/Pillow - 5.1.0\n",
    "- Matplotlib - 2.2.2\n",
    "- scikit-learn - 0.19.1\n",
    "- mlxtend - 0.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands / Running Instruction\n",
    "<pre>\n",
    "tensorboard --logdir=logs\n",
    "%config IPCompleter.greedy=True\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>Dataset Details</b>\n",
    "Dataset Name            : Chest X-Ray Images (Pneumonia)\n",
    "Number of Class         : 2\n",
    "Number/Size of Images   : Total      : 5856 (1.15 Gigabyte (GB))\n",
    "                          Training   : 5216 (1.07 Gigabyte (GB))\n",
    "                          Validation : 320  (42.8 Megabyte (MB))\n",
    "                          Testing    : 320  (35.4 Megabyte (MB))\n",
    "\n",
    "<b>Model Parameters</b>\n",
    "Machine Learning Library: Keras\n",
    "Base Model              : InceptionV3\n",
    "Optimizers              : Adam\n",
    "Loss Function           : categorical_crossentropy\n",
    "\n",
    "<b>Training Parameters</b>\n",
    "Batch Size              : 64\n",
    "Number of Epochs        : 50\n",
    "Training Time           : 3 Hours\n",
    "\n",
    "<b>Output (Prediction/ Recognition / Classification Metrics)</b>\n",
    "<!--<b>Validation</b>-->\n",
    "<b>Testing</b>\n",
    "Accuracy                : 83.44%\n",
    "Loss                    : 0.42\n",
    "<!--Precision               : -->\n",
    "Recall                  : 94% (highest)\n",
    "<!--Specificity             : -->\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import inspect\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directory, if directory exists removes if remove parameter is set to True \n",
    "def create_directory(directory_name, remove=False):\n",
    "    if remove and os.path.exists(directory_name):\n",
    "        try:\n",
    "            shutil.rmtree(directory_name)\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_name)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory_name)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Removes directory, if directory exists \n",
    "def remove_directory(directory_name):\n",
    "    if os.path.exists(directory_name):\n",
    "        try:\n",
    "            shutil.rmtree(directory_name)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_name)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Deletes file, if file exists \n",
    "def remove_file(filename):\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            os.remove(filename)\n",
    "        except:\n",
    "            print(\"Could not remove file : \", filename)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print date and time for given type of representation\n",
    "def date_time(x):\n",
    "    if x==1:\n",
    "        print('Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==2:    \n",
    "        print('Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==3:  \n",
    "        print('Date now: %s' % datetime.datetime.now())\n",
    "    if x==4:  \n",
    "        print('Date today: %s' % datetime.date.today())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints a integer for degugging\n",
    "def debug(x):\n",
    "    print(\"-\"*40, x, \"-\"*40)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of files in each subdirectory of a directory\n",
    "def subdirectory_file_count(master_directory):\n",
    "    subdirectories = os.listdir(master_directory)\n",
    "    subdirectory_count = len(subdirectories)\n",
    "\n",
    "    subdirectory_names = []\n",
    "    subdirectory_file_counts = []\n",
    "\n",
    "    for subdirectory in subdirectories:\n",
    "        current_directory = os.path.join(master_directory, subdirectory)\n",
    "        file_count = len(os.listdir(current_directory))\n",
    "        subdirectory_names.append(subdirectory)\n",
    "        subdirectory_file_counts.append(file_count)\n",
    "    \n",
    "    return subdirectory_names, subdirectory_file_counts\n",
    "               \n",
    "\n",
    "# show barplot\n",
    "def bar_plot(x, y, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    sns.barplot(x=x, y=y)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    \n",
    "\n",
    "# show bar plot for count of labels in subdirectory of a directory\n",
    "def count_bar_plot(master_directory, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    dir_name, dir_file_count = subdirectory_file_count(master_directory)\n",
    "    x=dir_name\n",
    "    y=dir_file_count\n",
    "    bar_plot(x, y, title, xlabel, ylabel, figsize=fig_size, title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=subplot_no)\n",
    "    \n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a training, validation, testing directory    \n",
    "def show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    count_bar_plot(training_dir, title +\" (Training)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=131)\n",
    "    count_bar_plot(validation_dir, title +\" (Validation)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=132)\n",
    "    count_bar_plot(testing_dir, title +\" (Testing)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=133)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches)\n",
    "def get_transformed_image_batch(directory, target_size, classes, class_mode='categorical', batch_size=1, shuffle=True, rescale=None, shear_range=0.0, zoom_range=0.0, horizontal_flip=False, validation_split=0.0):       \n",
    "    datagen = ImageDataGenerator(\n",
    "            rescale=rescale,\n",
    "            shear_range=shear_range,\n",
    "            zoom_range=zoom_range,\n",
    "            horizontal_flip=horizontal_flip,\n",
    "            validation_split=validation_split)     \n",
    "    \n",
    "    image_generator = datagen.flow_from_directory(\n",
    "            directory,\n",
    "            target_size=target_size,\n",
    "            classes = classes,\n",
    "            class_mode=class_mode,\n",
    "            batch_size=batch_size)\n",
    "    return image_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Label Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust class weights for imbalanced dataset of classes of images\n",
    "def get_class_weight(y):\n",
    "    counter = Counter(y)                          \n",
    "    max_val = float(max(counter.values()))     \n",
    "    class_weight = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Graph Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tensorflow graph tp free up memory and resource allocation \n",
    "def reset_graph(model=None):\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        return False\n",
    "    tf.reset_default_graph()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    return True\n",
    "\n",
    "\n",
    "# reset callbacks \n",
    "def reset_callbacks(checkpoint=None, reduce_lr=None, early_stopping=None, tensorboard=None):\n",
    "    checkpoint=None\n",
    "    reduce_lr = None\n",
    "    early_stopping = None\n",
    "    tensorboard = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish_activation(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "def basic_model(optimizer, loss, metrics, input_shape=(3,150,150), activation='relu', activation2='sigmoid', padding=\"same\", padding2=\"valid\", pool_size=(2, 2), dilation_rate=(2, 2)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(64, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(96, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(96, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(128, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation=swish_activation))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2 , activation=activation2))\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=metrics)\n",
    "\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "    \n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization Function\n",
    "#### Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "<p>1. Imports Pretrained model InceptionV3 <br>\n",
    "   2. Disabled training on first few layers <br>\n",
    "   3. Enabled training on top and output layers<br>\n",
    "   4. Adjust output Dense Layer to number of Image Classes <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and configure model InceptionV3 for fine-tuning with new class labels\n",
    "def get_inception_model(train_generator, validation_generator, epochs, verbose, optimizer, loss, metrics, tensorboard, callbacks, num_class, include_top=False, non_trainable_index=249, print_layers = False):    \n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=include_top)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    # Setting model layers specially output layer with class number\n",
    "    x = base_model.output\n",
    "    \n",
    "#     x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 2 classes\n",
    "\n",
    "    # softmax for multi-class\n",
    "    predictions = Dense(num_class, activation='softmax')(x) \n",
    "    \n",
    "    # sigmoid for 2 class or binary class\n",
    "    # predictions = Dense(num_class, activation='sigmoid')(x) \n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "     \n",
    "\n",
    "\n",
    "    \n",
    "    if callbacks:\n",
    "        # compile model with loss, optimizer and metrics \n",
    "        model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        tensorboard.set_model(model) \n",
    "    \n",
    "        # train the model on the new data for a few epochs\n",
    "        model.fit_generator(train_generator,\n",
    "                            steps_per_epoch = len(train_generator),\n",
    "                            epochs=epochs,\n",
    "                            # verbose=verbose, \n",
    "                            callbacks=callbacks,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=len(validation_generator),\n",
    "                            class_weight = class_weight)\n",
    "\n",
    "    # at this point, the top layers are well trained and we can start fine-tuning\n",
    "    # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "    # and train the remaining top layers.\n",
    "\n",
    "    # let's visualize layer names and layer indices to see how many layers\n",
    "    # we should freeze:\n",
    "    if print_layers:\n",
    "        for i, layer in enumerate(base_model.layers):\n",
    "            print(i, layer.name)\n",
    "\n",
    "    # Freeze or set first few layers as untrainable\n",
    "    # Unfreeze or set rest of the layers as trainable\n",
    "    for layer in model.layers[:non_trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[non_trainable_index:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Performance Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation performance\n",
    "def plot_history(history, plot_val, title, xlabel, ylabel, legend=[['Train', 'Val'], ['Train', 'Val']], fig_size=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history[plot_val[0][0]])\n",
    "    plt.plot(history.history[plot_val[0][1]])\n",
    "    plt.title(title[0], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[0], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[0], fontsize=label_fontsize)\n",
    "    plt.legend(legend[0], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history[plot_val[1][0]])\n",
    "    plt.plot(history.history[plot_val[1][1]])\n",
    "    plt.title(title[1], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[1], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[1], fontsize=label_fontsize)\n",
    "    plt.legend(legend[1], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Performance Report Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, test_generator, print_report=False):\n",
    "    result = model.evaluate_generator(generator=test_generator, steps=len(test_generator))\n",
    "    \n",
    "    accuracy = result[1]*100\n",
    "    loss = result[0]\n",
    "    \n",
    "    if print_report:\n",
    "        print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "    \n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "def predict_report(model, test_generator, classes, print_report=False):\n",
    "    y_preds = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "    y_classes = y_preds.argmax(axis=-1)\n",
    "\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    cls_report_print = classification_report(test_generator.classes, y_classes, target_names=classes)\n",
    "    cls_report = classification_report(test_generator.classes, y_classes, target_names=classes, output_dict=True)\n",
    "    \n",
    "    if print_report: \n",
    "        print(cls_report_print)\n",
    "    return y_preds, y_classes, CM, cls_report, cls_report_print\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse classification report for reporting negetive classes (0)\n",
    "def reverse_pos_neg(CM, print_bool):\n",
    "    tp=CM[0][0]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    tn=CM[1][1]\n",
    "    if print_bool:\n",
    "        print(tp, fp, tn, fn, tn)\n",
    "    return [tp, fp, tn, fn, tn]\n",
    "\n",
    "# reverse and report classification report for reporting negetive classes (0)\n",
    "def report(CM, reverse):\n",
    "    if not reverse:\n",
    "        tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "    else:\n",
    "        tp=CM[0][0]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        tn=CM[1][1]\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "    print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_models(model_dir, details, report_type, classes, class_name):\n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "    \n",
    "    filenames=[]\n",
    "    \n",
    "    accuracy_list=[]\n",
    "    loss_list=[]\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    f1_score_list=[]\n",
    "    \n",
    "    \n",
    "    best_accuracy=0\n",
    "    best_accuracy_file=\"\"\n",
    "    \n",
    "    best_loss=1000\n",
    "    best_loss_file=\"\"\n",
    "    \n",
    "    \n",
    "    best_precision=0\n",
    "    best_precision_file=\"\"\n",
    "    \n",
    "    best_recall=0\n",
    "    best_recall_file=\"\"\n",
    "    \n",
    "    best_f1_score=0\n",
    "    best_f1_score_file=\"\"\n",
    "    \n",
    "\n",
    "    model_files = os.listdir(model_dir)\n",
    "    \n",
    "    model = None\n",
    "    reset_graph(model)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for model_filename in model_files:\n",
    "        \n",
    "        model_path = model_dir+\"\\\\\"+model_filename\n",
    "        \n",
    "        if not os.path.isdir(model_path):\n",
    "            reset_graph(model)\n",
    "\n",
    "            model = keras.models.load_model(model_path)\n",
    "            \n",
    "            current_accuracy, current_loss =  model_evaluate(model, test_generator, print_report=False)\n",
    "            y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes)\n",
    "\n",
    "            \n",
    "            current_precision = cls_report[class_name]['precision'] \n",
    "            current_recall =  cls_report[class_name]['recall'] \n",
    "            current_f1_score =  cls_report[class_name]['f1-score'] \n",
    "            \n",
    "            filenames.append(model_file)\n",
    "            \n",
    "            accuracy_list.append(current_accuracy)\n",
    "            loss_list.append(current_loss)\n",
    "            \n",
    "            precision_list.append(current_precision)\n",
    "            recall_list.append(current_recall)\n",
    "            f1_score_list.append(current_f1_score)\n",
    "            \n",
    "            \n",
    "            results1[model_filename] = [current_accuracy, current_loss]\n",
    "            results2[model_filename] = [CM, cls_report, cls_report_print]\n",
    "\n",
    "                \n",
    "            if current_accuracy>=best_accuracy:\n",
    "                best_accuracy=current_accuracy\n",
    "                best_accuracy_file=model_file\n",
    "\n",
    "            if current_loss<=best_loss:\n",
    "                best_loss=current_loss\n",
    "                best_loss_file=model_file\n",
    "                \n",
    "            \n",
    "            if current_precision>=best_precision:\n",
    "                best_precision=current_precision\n",
    "                best_precision_file=model_file\n",
    "\n",
    "            if current_recall>=best_recall:\n",
    "                best_recall=current_recall\n",
    "                best_recall_file=model_file\n",
    "                \n",
    "            if current_f1_score>=best_f1_score:\n",
    "                best_f1_score=current_f1_score\n",
    "                best_f1_score_file=model_file\n",
    "                    \n",
    "\n",
    "            if details or i%5==0:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_file))\n",
    "                print(\"*\"*80)\n",
    "                show_confusion_matrix(test_generator, y_classes, classes)\n",
    "                print(cls_report_print)\n",
    "                print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "                print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            i+=1\n",
    "    print(\"Testing dataset evaluation and prediction report generation complete\")\n",
    "    \n",
    "    report = {\"Best Accuracy\" : [best_accuracy, best_accuracy_file], \n",
    "                   \"Best Loss\" : [best_loss, best_loss_file],\n",
    "                   \"Best Precision\" : [best_precision, best_precision_file],\n",
    "                   \"Best Recall\": [best_recall, best_recall_file],\n",
    "                   \"Best F1-Score\":[best_f1_score, best_f1_score_file]}\n",
    "    \n",
    "    \n",
    "    return results1, results2, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_over_epochs(array, title, xlabel=\"Epoch\", ylabel=\"Value\", title_fontsize=14, label_fontsize=12, subplot_no=0):\n",
    "    x_axis_arr = np.arange(len(array))\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.plot(x_axis_arr, array)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    \n",
    "def line_plot_over_epochs_loss_acc(array, title, fig_size=(10, 8), xlabel=[\"Epoch\", \"Epoch\"], ylabel=[\"Value\",\"Value\"], title_fontsize=14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    line_plot_over_epochs(array[0], title[0], xlabel=xlabel[0], ylabel=ylabel[0], title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=121)\n",
    "    line_plot_over_epochs(array[1], title[1], xlabel=xlabel[1], ylabel=ylabel[1], title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=122)\n",
    "    plt.show()\n",
    "    \n",
    "def show_confusion_matrix(test_generator, y_classes, classes, figsize=(10,8), stick_fontsize=12):\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=figsize, hide_ticks=True,cmap=plt.cm.Blues)\n",
    "    plt.xticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.yticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.show()\n",
    "    return CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Train, Validation and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input/ output directory\n",
    "# Configure training, validation, testing directory\n",
    "\n",
    "input_directory = r\"data/input/\"\n",
    "output_directory = r\"data/output/\"\n",
    "\n",
    "training_dir = input_directory+ r\"train\"\n",
    "testing_dir = input_directory+ r\"test\"\n",
    "validation_dir = input_directory+ r\"val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xlabel=\"Count\"\n",
    "ylabel=\"CaseType\"\n",
    "fig_size = (14,4)\n",
    "# fig_size = (4,2)\n",
    "# title_fontsize=14\n",
    "title_fontsize=13\n",
    "# label_fontsize=12\n",
    "label_fontsize=13\n",
    "title=\"Number of Cases\"\n",
    "\n",
    "\n",
    "show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=fig_size, title_fontsize = title_fontsize, label_fontsize=label_fontsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (Image Preprocessing)\n",
    "#### Configuring Image Transformation Parameters for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get number of label/ class / category\n",
    "num_class = len(os.listdir(training_dir))\n",
    "print(num_class)\n",
    "\n",
    "\n",
    "#Image Augmentation/ Preprocessing before training\n",
    "norm=255.0\n",
    "rescale=1./norm\n",
    "shear_range=0.2\n",
    "# shear_range=0.1\n",
    "zoom_range=0.2\n",
    "# zoom_range=0.1\n",
    "horizontal_flip=True\n",
    "\n",
    "\n",
    "# flow from directory function\n",
    "# Target Image dimention\n",
    "target_size=(224, 224)\n",
    "\n",
    "# Batch size\n",
    "# train\n",
    "# batch_size=32\n",
    "batch_size=64\n",
    "# batch_size=128\n",
    "\n",
    "# validation\n",
    "validation_batch_size=1\n",
    "# test\n",
    "test_batch_size=1\n",
    "\n",
    "# shuffle\n",
    "# test\n",
    "test_shuffle=False\n",
    "\n",
    "# validation split for train\n",
    "validation_split=0.0\n",
    "\n",
    "# class mode\n",
    "# class_mode='binary'\n",
    "class_mode='categorical'\n",
    "# class_mode='sparse'\n",
    "\n",
    "\n",
    "classes = ['Normal', 'PNEUMONIA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_transformed_image_batch(training_dir, target_size, classes, class_mode=class_mode, batch_size=batch_size, rescale=rescale, shear_range=shear_range, zoom_range=zoom_range, horizontal_flip=horizontal_flip)       \n",
    "\n",
    "validation_generator = get_transformed_image_batch(validation_dir, target_size, classes, class_mode=class_mode, batch_size=validation_batch_size, rescale=rescale)       \n",
    "\n",
    "test_generator = get_transformed_image_batch(validation_dir, target_size, classes, class_mode=class_mode, batch_size=test_batch_size, shuffle = test_shuffle, rescale=rescale) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Adjustmanet for Class Label Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_generator.classes\n",
    "class_weight=get_class_weight(y)\n",
    "class_weight=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not create directory:  data/output/models/20181201163224/\n",
      "Could not create directory:  data/output/logs/20181201163224\n"
     ]
    }
   ],
   "source": [
    "# setting model and log output directory\n",
    "model_dir=output_directory + r\"models/\"+time.strftime('%Y%m%d%H%M%S')+\"/\"\n",
    "log_dir=output_directory + r\"logs/\"+time.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "create_directory(model_dir, remove=True)\n",
    "create_directory(log_dir, remove=True)\n",
    "\n",
    "\n",
    "init_model_file=model_dir+\"base-\"+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "model_file=model_dir+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "retrain_model_file=model_dir+\"retrain-{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(3,150,150)\n",
    "activation='relu'\n",
    "activation2='sigmoid'\n",
    "padding=\"same\"\n",
    "padding2=\"valid\"\n",
    "pool_size=(2, 2)\n",
    "dilation_rate=(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Base Model - InceptionV3 (pretrained) initial training settings\n",
    "\n",
    "# inception base top layer discarded\n",
    "include_top=False\n",
    "\n",
    "# number of layers freezed\n",
    "non_trainable_index = 249\n",
    "\n",
    "init_optimizer=optimizers.Adam()\n",
    "# init_optimizer=optimizers.Adam(0.000001)\n",
    "\n",
    "print_layers=False\n",
    "\n",
    "# initial epochs on only output layers\n",
    "# init_epochs=1\n",
    "init_epochs=15\n",
    "\n",
    "# verbose\n",
    "init_verbose=0\n",
    "\n",
    "# callbacks\n",
    "init_callbacks=None\n",
    "\n",
    "# model report\n",
    "print_layers=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full model training parameter configuration for Loss, Optimizer and Performance Metrics\n",
    "\n",
    "# optimizer\n",
    "# adam lr=0.01/0.001/0.0001/0.00001/0.000001, decay = decay=1e-5/ 1e-6\n",
    "optimizer=optimizers.Adam()\n",
    "# optimizer=optimizers.Adam(0.1)\n",
    "# optimizer=optimizers.Adam(0.01)\n",
    "# optimizer=optimizers.Adam(0.001)\n",
    "# optimizer=optimizers.Adam(0.00001)\n",
    "# optimizer=optimizers.Adam(0.00001, decay=1e-7)\n",
    "\n",
    "\n",
    "\n",
    "# loss function\n",
    "# loss='binary_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "# performance metrics ('accuracy', 'binary_accuracy', precision, recall)\n",
    "metrics=['accuracy']\n",
    "# metrics=['mae', 'acc']\n",
    "# metrics=['mse', 'acc']\n",
    "# metrics=None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main model training parameter configuration\n",
    "\n",
    "# epochs = 20/30/50\n",
    "epochs = 30\n",
    "\n",
    "# steps\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "# verbose 0=nothing 1=each line\n",
    "verbose=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard\n",
    "\n",
    "# base_logger\n",
    "base_logger_stateful_metrics=None\n",
    "\n",
    "# TerminateOnNaN\n",
    "\n",
    "# ProgbarLogger\n",
    "progbar_logger_count_mode='samples'\n",
    "progbar_logger_stateful_metrics=None\n",
    "\n",
    "# History\n",
    "\n",
    "# LearningRateScheduler\n",
    "lr_schedule = None\n",
    "lr_scheduler_verbose=0\n",
    "\n",
    "# CSVLogger\n",
    "CSV_logger_filename = log_dir+ \"\\\\csv_logger.csv\"\n",
    "CSV_logger_separator=','\n",
    "CSV_logger_append=False\n",
    "\n",
    "\n",
    "# checkpoint\n",
    "# ck_monitor='val_acc'\n",
    "ck_monitor='val_loss'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "red_lr_patience=10\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "red_lr_min_lr=0.0\n",
    "\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "# es_patience=0\n",
    "es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "update_freq='epoch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_logger = keras.callbacks.BaseLogger(stateful_metrics=base_logger_stateful_metrics)\n",
    "terminate_on_NaN = keras.callbacks.TerminateOnNaN()\n",
    "progbar_logger = keras.callbacks.ProgbarLogger(count_mode=progbar_logger_count_mode, stateful_metrics=progbar_logger_stateful_metrics)\n",
    "history = keras.callbacks.History()\n",
    "# learning_rate_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, lr_scheduler_verbose=0)\n",
    "CSV_logger = keras.callbacks.CSVLogger(CSV_logger_filename, separator=CSV_logger_separator, append=CSV_logger_append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Callbacks\n",
    "#### ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard, \n",
    "#### BaseLogger, TerminateOnNaN , ProgbarLogger,  History, LearningRateScheduler, CSVLogger, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_logger, terminate_on_NaN , progbar_logger,  history, learning_rate_scheduler, CSV_logger, checkpoint, reduce_lr, early_stopping, tensorboard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN , progbar_logger,  history, learning_rate_scheduler, CSV_logger]init_callbacks = None\n",
    "init_callbacks = None\n",
    "# init_callbacks = [checkpoint, tensorboard]\n",
    "# init_callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history, CSV_logger]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, learning_rate_scheduler, CSV_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = None\n",
    "# callbacks = [checkpoint, tensorboard]\n",
    "callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history, CSV_logger]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, learning_rate_scheduler, CSV_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Retrain Main Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain_callbacks = None\n",
    "# retrain_callbacks = [checkpoint, tensorboard]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, CSV_logger]\n",
    "# retrain_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, base_logger, terminate_on_NaN, progbar_logger, history, learning_rate_scheduler, CSV_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2050        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 13,215,106\n",
      "Non-trainable params: 10,687,904\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # get inception model\n",
    "# init_epochs = 100\n",
    "# print_layers=False\n",
    "# model = get_inception_model(train_generator, validation_generator, init_epochs, init_verbose, init_optimizer, loss, metrics, tensorboard, init_callbacks, num_class, include_top, non_trainable_index, print_layers)\n",
    "# main_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model Performance with Minimum Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_report=True\n",
    "\n",
    "# y_preds, y_classes, CM, CM_report, cls_report_print = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "# accuracy, loss =  model_evaluate(model, test_generator, print_report)\n",
    "\n",
    "# res=show_confusion_matrix(test_generator, y_classes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "82/82 [==============================] - 225s 3s/step - loss: 0.2287 - acc: 0.9234 - val_loss: 1.6530 - val_acc: 0.6375\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 175s 2s/step - loss: 0.0975 - acc: 0.9621 - val_loss: 1.1992 - val_acc: 0.6500\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 182s 2s/step - loss: 0.0873 - acc: 0.9682 - val_loss: 0.6189 - val_acc: 0.7375\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 142s 2s/step - loss: 0.0738 - acc: 0.9735 - val_loss: 0.4384 - val_acc: 0.7844\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 144s 2s/step - loss: 0.0667 - acc: 0.9775 - val_loss: 1.4076 - val_acc: 0.6406\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 130s 2s/step - loss: 0.0635 - acc: 0.9766 - val_loss: 0.5333 - val_acc: 0.8156\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.0495 - acc: 0.9829 - val_loss: 1.4577 - val_acc: 0.6750\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.0563 - acc: 0.9789 - val_loss: 0.2641 - val_acc: 0.8812\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.0502 - acc: 0.9819 - val_loss: 1.3885 - val_acc: 0.7156\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.0467 - acc: 0.9815 - val_loss: 0.5687 - val_acc: 0.8031\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.0501 - acc: 0.9813 - val_loss: 0.5906 - val_acc: 0.7937\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 117s 1s/step - loss: 0.0490 - acc: 0.9830 - val_loss: 0.3882 - val_acc: 0.8469\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.0418 - acc: 0.9834 - val_loss: 1.0402 - val_acc: 0.7031\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.0392 - acc: 0.9863 - val_loss: 0.9157 - val_acc: 0.7562\n",
      "Epoch 15/30\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.0441 - acc: 0.9821 - val_loss: 0.8536 - val_acc: 0.8344\n",
      "Epoch 16/30\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.0398 - acc: 0.9855 - val_loss: 1.5797 - val_acc: 0.7219\n",
      "Epoch 17/30\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.0414 - acc: 0.9846 - val_loss: 0.5500 - val_acc: 0.8313\n",
      "Epoch 18/30\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.0412 - acc: 0.9865 - val_loss: 0.9501 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 19/30\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.0284 - acc: 0.9884 - val_loss: 0.9775 - val_acc: 0.7812\n",
      "Epoch 20/30\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.0258 - acc: 0.9895 - val_loss: 0.9960 - val_acc: 0.7844\n",
      "Epoch 21/30\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.0241 - acc: 0.9918 - val_loss: 0.8664 - val_acc: 0.7969\n",
      "Epoch 22/30\n",
      "82/82 [==============================] - 117s 1s/step - loss: 0.0218 - acc: 0.9928 - val_loss: 0.7521 - val_acc: 0.8125\n",
      "Epoch 23/30\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.0240 - acc: 0.9907 - val_loss: 0.7707 - val_acc: 0.8156\n",
      "Epoch 24/30\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.0224 - acc: 0.9916 - val_loss: 0.7019 - val_acc: 0.8313\n",
      "Epoch 25/30\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.0198 - acc: 0.9937 - val_loss: 0.7933 - val_acc: 0.8219\n",
      "Epoch 26/30\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.0255 - acc: 0.9912 - val_loss: 0.9904 - val_acc: 0.7969\n",
      "Epoch 27/30\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.0172 - acc: 0.9945 - val_loss: 0.6763 - val_acc: 0.8438\n",
      "Epoch 28/30\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.0218 - acc: 0.9920 - val_loss: 0.6030 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 29/30\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.0178 - acc: 0.9933 - val_loss: 0.6549 - val_acc: 0.8500\n",
      "Epoch 30/30\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.0208 - acc: 0.9928 - val_loss: 0.6643 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "\n",
    "# epochs=100\n",
    "# optimizer=optimizers.adam(lr=0.0001)\n",
    "# model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "# tensorboard.set_model(model) \n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val=[['acc', 'val_acc'], ['loss', 'val_loss']]\n",
    "\n",
    "title = ['Model accuracy', 'Model loss']\n",
    "\n",
    "xlabel = ['Epoch', 'Epoch']\n",
    "ylabel = ['Accuracy', 'Loss']\n",
    "\n",
    "legend = ['Train', 'Val']\n",
    "\n",
    "fig_size=(15, 5)\n",
    "\n",
    "\n",
    "title_fontsize=17\n",
    "label_fontsize=15\n",
    "\n",
    "plot_history(history, plot_val, title, xlabel, ylabel, fig_size=fig_size, title_fontsize=title_fontsize, label_fontsize=label_fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance of All Models on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir=\"data\\\\output\\\\models\\\\20181201035451\\\\\"\n",
    "log_dir=\"data\\\\output\\\\logs\\\\20181201035451\\\\\"\n",
    "model=keras.models.load_model(model_dir+\"30-val_acc-0.85-val_loss-0.66.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# log_data = pd.read_csv('data\\\\output\\\\logs\\\\20181201035451events.out.tfevents.1543654624.DESKTOP-BU5QMIC', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes, print_report=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.30      0.20      0.24       121\n",
      "   PNEUMONIA       0.60      0.72      0.65       199\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       320\n",
      "   macro avg       0.45      0.46      0.45       320\n",
      "weighted avg       0.49      0.53      0.50       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cls_report_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_models(model_dir, details, report_type, classes, class_name):\n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "    \n",
    "    filenames=[]\n",
    "    \n",
    "    accuracy_list=[]\n",
    "    loss_list=[]\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    f1_score_list=[]\n",
    "    \n",
    "    \n",
    "    best_accuracy=0\n",
    "    best_accuracy_file=\"\"\n",
    "    \n",
    "    best_loss=1000\n",
    "    best_loss_file=\"\"\n",
    "    \n",
    "    \n",
    "    best_precision=0\n",
    "    best_precision_file=\"\"\n",
    "    \n",
    "    best_recall=0\n",
    "    best_recall_file=\"\"\n",
    "    \n",
    "    best_f1_score=0\n",
    "    best_f1_score_file=\"\"\n",
    "    \n",
    "\n",
    "    model_files = os.listdir(model_dir)\n",
    "    \n",
    "    model = None\n",
    "    reset_graph(model)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for model_filename in model_files:\n",
    "        \n",
    "        model_path = model_dir+\"\\\\\"+model_filename\n",
    "        \n",
    "        if not os.path.isdir(model_path):\n",
    "            reset_graph(model)\n",
    "\n",
    "            model = keras.models.load_model(model_path)\n",
    "            \n",
    "            current_accuracy, current_loss =  model_evaluate(model, test_generator, print_report=False)\n",
    "            y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes)\n",
    "\n",
    "            \n",
    "            current_precision = cls_report[class_name]['precision'] *100\n",
    "            current_recall =  cls_report[class_name]['recall'] *100\n",
    "            current_f1_score =  cls_report['weighted avg']['f1-score'] *100\n",
    "            \n",
    "            filenames.append(model_file)\n",
    "            \n",
    "            accuracy_list.append(current_accuracy)\n",
    "            loss_list.append(current_loss)\n",
    "            \n",
    "            precision_list.append(current_precision)\n",
    "            recall_list.append(current_recall)\n",
    "            f1_score_list.append(current_f1_score)\n",
    "            \n",
    "            \n",
    "            results1[model_filename] = [current_accuracy, current_loss]\n",
    "            results2[model_filename] = [CM, cls_report, cls_report_print]\n",
    "\n",
    "                \n",
    "            if current_accuracy>=best_accuracy:\n",
    "                best_accuracy=current_accuracy\n",
    "                best_accuracy_file=model_file\n",
    "\n",
    "            if current_loss<=best_loss:\n",
    "                best_loss=current_loss\n",
    "                best_loss_file=model_file\n",
    "                \n",
    "            \n",
    "            if current_precision>=best_precision:\n",
    "                best_precision=current_precision\n",
    "                best_precision_file=model_file\n",
    "\n",
    "            if current_recall>=best_recall:\n",
    "                best_recall=current_recall\n",
    "                best_recall_file=model_file\n",
    "                \n",
    "            if current_f1_score>=best_f1_score:\n",
    "                best_f1_score=current_f1_score\n",
    "                best_f1_score_file=model_file\n",
    "                    \n",
    "\n",
    "            if details or i%5==0:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_file))\n",
    "                print(\"*\"*80)\n",
    "                show_confusion_matrix(test_generator, y_classes, classes)\n",
    "                print(cls_report_print)\n",
    "                print(\"%s%.2f%s\"% (\"Current Accuracy: \", current_accuracy, \"%\"))\n",
    "                print(\"%s%.2f\"% (\"Current Loss: \", current_loss))\n",
    "                print(\"%s%.2f%s\"% (\"Current Precision: \", current_precision, \"%\"))\n",
    "                print(\"%s%.2f\"% (\"Current Recall: \", current_recall, \"%\"))\n",
    "                print(\"%s%.2f%s\"% (\"Current F1_score: \", current_f1_score, \"%\"))\n",
    "\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            i+=1\n",
    "    print(\"Testing dataset evaluation and prediction report generation complete\")\n",
    "    \n",
    "    report = {\"Best Accuracy\" : [best_accuracy, best_accuracy_file], \n",
    "                   \"Best Loss\" : [best_loss, best_loss_file],\n",
    "                   \"Best Precision\" : [best_precision, best_precision_file],\n",
    "                   \"Best Recall\": [best_recall, best_recall_file],\n",
    "                   \"Best F1-Score\":[best_f1_score, best_f1_score_file]}\n",
    "    \n",
    "    \n",
    "    return results1, results2, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = True\n",
    "class_name = \"PNEUMONIA\"\n",
    "\n",
    "report_type = \"full\"\n",
    "results1, results2, report = test_all_models(model_dir, details, report_type, classes, class_name=class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of  Performance Over All Epochs/Models based on Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=[[1,2,3],[2,3,4]]\n",
    "\n",
    "fig_size = (10, 8)\n",
    "title=[\"Test Dataset Performance (Accuracy)\", \"Test Dataset Performance (Loss)\"]\n",
    "xlabel=[\"Epoch\", \"Epoch\"]\n",
    "ylabel=[\"Accuracy (100%)\", \"Loss\"]\n",
    "\n",
    "line_plot_over_epochs_loss_acc(array, title, fig_size=fig_size, xlabel=xlabel, ylabel=ylabel, title_fontsize=title_fontsize, label_fontsize=label_fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_callbacks(checkpoint, reduce_lr, early_stopping, tensorboard)\n",
    "# reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration for Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file=model_dir+\"retrain-{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "### Full model training parameter configuration for Loss, Optimizer and Performance Metrics\n",
    "\n",
    "# optimizer\n",
    "# adam lr=0.01/0.001/0.0001/0.00001/0.000001, decay = decay=1e-5/ 1e-6\n",
    "optimizer=optimizers.Adam()\n",
    "\n",
    "\n",
    "# loss function\n",
    "# loss='binary_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "# performance metrics ('accuracy', 'binary_accuracy', precision, recall)\n",
    "metrics=['accuracy']\n",
    "\n",
    "\n",
    "### Main model training parameter configuration\n",
    "\n",
    "# epochs = 20/30/50\n",
    "epochs=30\n",
    "\n",
    "# steps\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "# verbose 0=nothing 1=each line\n",
    "verbose=0\n",
    "\n",
    "\n",
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard\n",
    "\n",
    "# checkpoint\n",
    "ck_monitor='val_acc'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "# red_lr_patience=5\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "# red_lr_min_lr=0.0001 # default\n",
    "red_lr_min_lr=0.000001\n",
    "\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "# es_patience=0\n",
    "es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "\n",
    "################################################ Retrain #########################################################\n",
    "epochs=epochs+1\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard for Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Best Model\n",
    "### Selecting best model file based on validation accuracy mentioned in file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best model file / checkpoint for retraining\n",
    "# model_path = model_dir+r\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "# model_path = model_dir+r\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "# best accuracy/ F-1 score\n",
    "# model_path = \"data/output/models/\"+\"17-val_acc-0.82-val_loss-0.42.hdf5\"\n",
    "\n",
    "# Lowest validation Loss\n",
    "# model_path = \"data/output/models/\"+\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "\n",
    "# Best Recall\n",
    "# model_path = \"data/output/models/\"+\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "model_path = model_dir+r\"20-val_acc-0.71-val_loss-1.26.hdf5\"\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "# retrain by loading last good model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    # verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight,\n",
    "    initial_epoch=initial_epoch)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    extracted_id = b[0]\n",
    "    \n",
    "    return extracted_id\n",
    "\n",
    "\n",
    "\n",
    "test_filenames = test_generator.filenames\n",
    "df_preds = pd.DataFrame(predictions, columns=classes)\n",
    "df_preds['file_names'] = test_filenames\n",
    "df_preds['id'] = df_preds['file_names'].apply(extract_id)\n",
    "df_preds.head()\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['Cancer']\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "roc_auc_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':image_id, \n",
    "                           'label':y_pred, \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('patch_preds.csv', columns=['label']) \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retriving actual labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (test_generator.class_indices)\n",
    "label_map_rev = {v: name_correct(k) for k,v in label_map.items()}\n",
    "num_batch_t = len(test_generator)\n",
    "print(label_map)\n",
    "print(label_map_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing accuracy for Model over Single Batch of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0, num_batch_t-1)\n",
    "y_img_batch, y_class_batch = test_generator[num] \n",
    "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
    "y_true = np.argmax(y_class_batch,-1)\n",
    "print(\"Selected Batch No: %d\\nBatch Size: %d\"%(num, len(y_pred)))\n",
    "print(\"Accuracy : \", sum(y_pred==y_true)/batch_size*100, \"%\")\n",
    "\n",
    "y_true_labels = [label_map_rev[c] for c in y_true]\n",
    "y_pred_labels = [label_map_rev[c] for c in y_pred]\n",
    "batch_size_t = len(y_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n",
    "Visualization of performance of a random test dataset batch and few random images from a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/result\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "\n",
    "cols = 8\n",
    "rows= batch_size_t/cols\n",
    "if batch_size_t%cols==0:\n",
    "    rows = int(batch_size_t/cols)\n",
    "else:\n",
    "    rows = int(batch_size_t/cols)+1\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org : \"\n",
    "pred_label_title_prefix = \"pred: \"\n",
    "\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "for i in range(0, batch_size_t): # how many imgs will show from the mxn grid\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[i])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[i]==y_pred_labels[i]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i], color=false_prediction_label_color)\n",
    "        \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)\n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/sample\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "cols = 4\n",
    "rows= 2\n",
    "\n",
    "count = rows*cols\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "# titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org:  \"\n",
    "pred_label_title_prefix = \"pred: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "\n",
    "batch_size_tmp = batch_size_t\n",
    "\n",
    "m = {}\n",
    "\n",
    "for i in range(0, count): \n",
    "    num = random.randint(0, batch_size_tmp-1)\n",
    "    while num in m:\n",
    "        num = random.randint(0, batch_size_tmp-1)\n",
    "    \n",
    "    m[num]=1\n",
    "    \n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[num])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[num]==y_pred_labels[num]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num], color=false_prediction_label_color)\n",
    "    \n",
    "   \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)   \n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
