{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "<pre>\n",
    "Author           : Anjana Tiha\n",
    "Project Name     : Detection of Pneumonia from Chest X-Ray Images using Convolutional Neural Network, \n",
    "                   and Transfer Learning.\n",
    "Description      : 1. Detected Pneumonia from Chest X-Ray images by retraining pretrained model “InceptionV3” \n",
    "                      with 5856 images of X-ray (1.15GB).\n",
    "                   2. For retraining removed output layers, freezed first few layers and Fine-tuned model for \n",
    "                      two new label classes (Pneumonia and Normal).\n",
    "                   3. Attained testing accuracy 83.44% and loss 0.42.\n",
    "Method           : \n",
    "Tools/Library    : Python, Keras, PyTorch, TensorFlow\n",
    "Version History  : 1.0.0.0\n",
    "Current Version  : 1.0.0.0\n",
    "Last Update      : 11.24.2018\n",
    "Comments         : Please use Anaconda editor for convenience.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "<pre>\n",
    "GitHub Link      : <a href=https://github.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitHub)</a>\n",
    "GitLab Link      : <a href=https://gitlab.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitLab)</a>\n",
    "Portfolio        : <a href=https://anjanatiha.wixsite.com/website>Anjana Tiha's Portfolio</a>\n",
    "</pre>\n",
    "\n",
    "#### Dataset\n",
    "<pre>\n",
    "Dataset Name     : Chest X-Ray Images (Pneumonia)\n",
    "Dataset Link     : <a href=https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia>Chest X-Ray Images (Pneumonia) Dataset (Kaggle)</a>\n",
    "                 : <a href=https://data.mendeley.com/datasets/rscbjbr9sj/2>Chest X-Ray Images (Pneumonia) Dataset (Original Dataset)</a>\n",
    "Original Paper   : <a href=https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5>Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning</a>\n",
    "                   (Daniel S. Kermany, Michael Goldbaum, Wenjia Cai, M. Anthony Lewis, Huimin Xia, Kang Zhang)\n",
    "                   https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library/Tools Version\n",
    "- Python - v3.6.7\n",
    "- argparse\n",
    "- random\n",
    "- numpy\n",
    "- shutil\n",
    "- gc\n",
    "- re\n",
    "- Keras - 2.2.4\n",
    "- Keras-preprocessing - v1.0.5\n",
    "- TensorFlow - 1.12\n",
    "- PIL/Pillow - 5.1.0\n",
    "- Matplotlib - 2.2.2\n",
    "- scikit-learn - 0.19.1\n",
    "- mlxtend - 0.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands / Running Instruction\n",
    "<pre>\n",
    "tensorboard --logdir=logs\n",
    "%config IPCompleter.greedy=True\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>Dataset Details</b>\n",
    "Dataset Name            : Chest X-Ray Images (Pneumonia)\n",
    "Number of Class         : 2\n",
    "Number/Size of Images   : Total      : 5856 (1.15 Gigabyte (GB))\n",
    "                          Training   : 5216 (1.07 Gigabyte (GB))\n",
    "                          Validation : 320  (42.8 Megabyte (MB))\n",
    "                          Testing    : 320  (35.4 Megabyte (MB))\n",
    "\n",
    "<b>Model Parameters</b>\n",
    "Machine Learning Library: Keras\n",
    "Base Model              : InceptionV3\n",
    "Optimizers              : Adam\n",
    "Loss Function           : categorical_crossentropy\n",
    "\n",
    "<b>Training Parameters</b>\n",
    "Batch Size              : 64\n",
    "Number of Epochs        : 50\n",
    "Training Time           : 3 Hours\n",
    "\n",
    "<b>Output (Prediction/ Recognition / Classification Metrics)</b>\n",
    "<!--<b>Validation</b>-->\n",
    "<b>Testing</b>\n",
    "Accuracy                : 83.44%\n",
    "Loss                    : 0.42\n",
    "<!--Precision               : -->\n",
    "Recall                  : 94% (highest)\n",
    "<!--Specificity             : -->\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import inspect\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "tf.reset_default_graph()\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions:\n",
    "<pre>\n",
    "Resetting model and log directory\n",
    "class name cleansing\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Make or reset directory\n",
    "def mk_reset_dir(directory, remove=False):\n",
    "    if remove and os.path.exists(directory):\n",
    "        try:\n",
    "            shutil.rmtree(directory)\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "def date_time(x):\n",
    "    if x==1:\n",
    "        print('Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==2:    \n",
    "        print('Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==3:  \n",
    "        print('Date now: %s' % datetime.datetime.now())\n",
    "    if x==4:  \n",
    "        print('Date today: %s' % datetime.date.today())\n",
    "        \n",
    "def debug(x):\n",
    "    print(\"-\"*40, x, \"-\"*40)    \n",
    "\n",
    "# Remove everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def count_bar(master_directory):\n",
    "    dir_list = os.listdir(master_directory)\n",
    "    num_class = len(dir_list)\n",
    "\n",
    "    dir_name = []\n",
    "    dir_file_count = []\n",
    "\n",
    "    for directory in dir_list:\n",
    "        cur_dir = os.path.join(master_directory, directory)\n",
    "        count_sample = len(os.listdir(cur_dir))\n",
    "        dir_name.append(directory)\n",
    "        dir_file_count.append(count_sample)\n",
    "    \n",
    "    return dir_name, dir_file_count\n",
    "               \n",
    "\n",
    "def bar_plot(x, y, title, xlabel, ylabel, title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x=x, y= y)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)                          \n",
    "    max_val = float(max(counter.values()))     \n",
    "    class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Input/ Output Directory\n",
    "<pre>\n",
    "Data             : training, validation, testing\n",
    "Model and output : model directory and logs directory\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input/ output directory\n",
    "# Configure training, validation, testing directory\n",
    "\n",
    "input_directory = r\"data/input/\"\n",
    "output_directory = r\"data/output/\"\n",
    "\n",
    "training_dir = input_directory+ r\"train\"\n",
    "testing_dir = input_directory+ r\"test\"\n",
    "validation_dir = input_directory+ r\"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel=\"Count\"\n",
    "ylabel=\"CaseType\"\n",
    "title_fontsize=14\n",
    "label_fontsize=12\n",
    "\n",
    "master_directory = training_dir\n",
    "dir_name, dir_file_count = count_bar(master_directory)\n",
    "x=dir_name\n",
    "y=dir_file_count\n",
    "title=\"Number of Cases\"\n",
    "bar_plot(x, y, title, xlabel, ylabel, title_fontsize, label_fontsize)\n",
    "\n",
    "\n",
    "master_directory = validation_dir\n",
    "dir_name, dir_file_count = count_bar(master_directory)\n",
    "x=dir_name\n",
    "y=dir_file_count\n",
    "title=\"Number of Cases (Validation)\"\n",
    "bar_plot(x, y, title, xlabel, ylabel, title_fontsize, label_fontsize)\n",
    "\n",
    "master_directory = testing_dir\n",
    "dir_name, dir_file_count = count_bar(master_directory)\n",
    "x=dir_name\n",
    "y=dir_file_count\n",
    "title=\"Number of Cases (Testing)\"\n",
    "bar_plot(x, y, title, xlabel, ylabel, title_fontsize, label_fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (Image Preprocessing)\n",
    "#### Setting up Parameters for Image Transformation of Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of label/ class / category\n",
    "num_class = len(os.listdir(training_dir))\n",
    "print(num_class)\n",
    "\n",
    "# Configure image preprocessing parameters for generating batches of tensor image data from train, test, validation datasets\n",
    "# with real-time data augmentation. The data will be looped over (in batches).\n",
    "norm = 255.0\n",
    "rescale=1./norm\n",
    "shear_range=0.2\n",
    "zoom_range=0.2\n",
    "horizontal_flip=True\n",
    "\n",
    "# Image dimention and Batch size \n",
    "target_size=(224, 224)\n",
    "batch_size=32\n",
    "# batch_size=64\n",
    "\n",
    "test_batch_size=1\n",
    "\n",
    "# Data label class\n",
    "class_mode='categorical'\n",
    "# class_mode='binary'\n",
    "# class_mode='sparse'\n",
    "\n",
    "# classes = ['Cancer', 'Normal']\n",
    "classes = ['Normal', 'PNEUMONIA']\n",
    "\n",
    "# iaa.Multiply((1.2, 1.5))]) #random brightness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (Image Preprocessing)\n",
    "#### Transformation Image Dataset for Training, Validation, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches)\n",
    "# Generate batches of tensor image data with real-time data augmentation from training dataset\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=rescale,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        training_dir,\n",
    "        target_size=target_size,\n",
    "        classes = classes,\n",
    "        class_mode=class_mode,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "# Generate batches of tensor image data with real-time data augmentation from validation dataset\n",
    "validation_datagen = ImageDataGenerator(rescale=rescale)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=target_size,\n",
    "        classes = classes,\n",
    "        class_mode=class_mode,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "# Generate batches of tensor image data with real-time data augmentation from testing dataset\n",
    "test_datagen = ImageDataGenerator(rescale=rescale)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        testing_dir,\n",
    "        target_size=target_size,\n",
    "        classes = classes,\n",
    "        class_mode=class_mode,\n",
    "#         batch_size=batch_size,\n",
    "        batch_size=test_batch_size,\n",
    "        shuffle=False) ## false added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_generator.classes\n",
    "class_weight=get_class_weights(y)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "<p>1. Imports Pretrained model InceptionV3 <br>\n",
    "   2. Disabled training on first few layers <br>\n",
    "   3. Enabled training on top and output layers<br>\n",
    "   4. Adjust output Dense Layer to number of Image Classes <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "def get_inception_model(train_generator, validation_generator, epochs, verbose, sgd, loss, metrics, tensorboard, callbacks, num_class, include_top=False, non_trainable_index=249, print_layers = False):    \n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=include_top)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    # Setting model layers specially output layer with class number\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 2 classes\n",
    "\n",
    "    # softmax for multi-class\n",
    "    predictions = Dense(num_class, activation='softmax')(x) \n",
    "    \n",
    "    # sigmoid for 2 class or binary class\n",
    "    # predictions = Dense(num_class, activation='sigmoid')(x) \n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "     \n",
    "    # compile model with loss, optimizer and metrics \n",
    "    model.compile(sgd, loss=loss, metrics=metrics)\n",
    "    \n",
    "    tensorboard.set_model(model) \n",
    "    \n",
    "    # train the model on the new data for a few epochs\n",
    "    model.fit_generator(train_generator,\n",
    "                        steps_per_epoch = len(train_generator),\n",
    "                        epochs=epochs,\n",
    "                        # verbose=verbose, \n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=len(validation_generator),\n",
    "                        class_weight = class_weight)\n",
    "\n",
    "    # at this point, the top layers are well trained and we can start fine-tuning\n",
    "    # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "    # and train the remaining top layers.\n",
    "\n",
    "    # let's visualize layer names and layer indices to see how many layers\n",
    "    # we should freeze:\n",
    "    if print_layers:\n",
    "        for i, layer in enumerate(base_model.layers):\n",
    "            print(i, layer.name)\n",
    "\n",
    "    # Freeze or set first few layers as untrainable\n",
    "    # Unfreeze or set rest of the layers as trainable\n",
    "    for layer in model.layers[:non_trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[non_trainable_index:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Base Model Import and Initial Training\n",
    "##### Base Model - InceptionV3 (pretrained) import and initial training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception base top layer discarded\n",
    "include_top = False\n",
    "\n",
    "# number of layers freezed\n",
    "non_trainable_index = 249\n",
    "\n",
    "print_layers=False\n",
    "\n",
    "init_epochs=1\n",
    "# initial_epochs=3\n",
    "# initial_epochs=5\n",
    "init_verbose = 0\n",
    "init_callbacks = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Import and Parameter Setting For Main Training\n",
    "#### Configuration of Loss, Optimizer and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer\n",
    "# sgd = optimizers.Adam()\n",
    "# sgd = optimizers.Adam(lr=0.001)\n",
    "\n",
    "## works best\n",
    "sgd = optimizers.Adam(lr=0.0001)\n",
    "# sgd = optimizers.Adam(lr=0.0001, decay=1e-5)\n",
    "\n",
    "# sgd = optimizers.SGD()\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# sgd = optimizer=SGD(lr=0.0001, momentum=0.9)\n",
    "\n",
    "# set loss function\n",
    "loss='categorical_crossentropy'\n",
    "# loss='binary_crossentropy'\n",
    "\n",
    "# set performance metrics\n",
    "metrics=['accuracy']\n",
    "# metrics=['accuracy', 'binary_accuracy', precision, recall]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Import and Parameter Setting For Main Training\n",
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 50\n",
    "epochs = 20\n",
    "\n",
    "steps_per_epoch=len(train_generator)\n",
    "verbose = 0\n",
    "validation_steps=len(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Import and Parameter Setting For Main Training\n",
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "# setting model and log output directory\n",
    "model_dir =  output_directory + r\"models/\"\n",
    "log_dir = output_directory + r\"logs\"\n",
    "\n",
    "# make or reset directory\n",
    "# mk_reset_dir(model_dir, False)\n",
    "# mk_reset_dir(log_dir, False)\n",
    "\n",
    "model_file = model_dir+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "# checkpoint\n",
    "ck_monitor='val_acc'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "# red_lr_patience=5\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "# red_lr_min_lr=0.0001 # default\n",
    "red_lr_min_lr=0.00001\n",
    "\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "es_patience=0\n",
    "# es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Import and Parameter Setting For Main Training\n",
    "#### Setup Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Import and Parameter Compilation For Main Training\n",
    "### Model Import and compiling with loss, optimizer and performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "163/163 [==============================] - 209s 1s/step - loss: 0.5344 - acc: 0.8462 - val_loss: 0.5606 - val_acc: 0.7469\n",
      "0 input_1\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed0\n",
      "41 conv2d_16\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_14\n",
      "45 conv2d_17\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 average_pooling2d_2\n",
      "51 conv2d_13\n",
      "52 conv2d_15\n",
      "53 conv2d_18\n",
      "54 conv2d_19\n",
      "55 batch_normalization_13\n",
      "56 batch_normalization_15\n",
      "57 batch_normalization_18\n",
      "58 batch_normalization_19\n",
      "59 activation_13\n",
      "60 activation_15\n",
      "61 activation_18\n",
      "62 activation_19\n",
      "63 mixed1\n",
      "64 conv2d_23\n",
      "65 batch_normalization_23\n",
      "66 activation_23\n",
      "67 conv2d_21\n",
      "68 conv2d_24\n",
      "69 batch_normalization_21\n",
      "70 batch_normalization_24\n",
      "71 activation_21\n",
      "72 activation_24\n",
      "73 average_pooling2d_3\n",
      "74 conv2d_20\n",
      "75 conv2d_22\n",
      "76 conv2d_25\n",
      "77 conv2d_26\n",
      "78 batch_normalization_20\n",
      "79 batch_normalization_22\n",
      "80 batch_normalization_25\n",
      "81 batch_normalization_26\n",
      "82 activation_20\n",
      "83 activation_22\n",
      "84 activation_25\n",
      "85 activation_26\n",
      "86 mixed2\n",
      "87 conv2d_28\n",
      "88 batch_normalization_28\n",
      "89 activation_28\n",
      "90 conv2d_29\n",
      "91 batch_normalization_29\n",
      "92 activation_29\n",
      "93 conv2d_27\n",
      "94 conv2d_30\n",
      "95 batch_normalization_27\n",
      "96 batch_normalization_30\n",
      "97 activation_27\n",
      "98 activation_30\n",
      "99 max_pooling2d_3\n",
      "100 mixed3\n",
      "101 conv2d_35\n",
      "102 batch_normalization_35\n",
      "103 activation_35\n",
      "104 conv2d_36\n",
      "105 batch_normalization_36\n",
      "106 activation_36\n",
      "107 conv2d_32\n",
      "108 conv2d_37\n",
      "109 batch_normalization_32\n",
      "110 batch_normalization_37\n",
      "111 activation_32\n",
      "112 activation_37\n",
      "113 conv2d_33\n",
      "114 conv2d_38\n",
      "115 batch_normalization_33\n",
      "116 batch_normalization_38\n",
      "117 activation_33\n",
      "118 activation_38\n",
      "119 average_pooling2d_4\n",
      "120 conv2d_31\n",
      "121 conv2d_34\n",
      "122 conv2d_39\n",
      "123 conv2d_40\n",
      "124 batch_normalization_31\n",
      "125 batch_normalization_34\n",
      "126 batch_normalization_39\n",
      "127 batch_normalization_40\n",
      "128 activation_31\n",
      "129 activation_34\n",
      "130 activation_39\n",
      "131 activation_40\n",
      "132 mixed4\n",
      "133 conv2d_45\n",
      "134 batch_normalization_45\n",
      "135 activation_45\n",
      "136 conv2d_46\n",
      "137 batch_normalization_46\n",
      "138 activation_46\n",
      "139 conv2d_42\n",
      "140 conv2d_47\n",
      "141 batch_normalization_42\n",
      "142 batch_normalization_47\n",
      "143 activation_42\n",
      "144 activation_47\n",
      "145 conv2d_43\n",
      "146 conv2d_48\n",
      "147 batch_normalization_43\n",
      "148 batch_normalization_48\n",
      "149 activation_43\n",
      "150 activation_48\n",
      "151 average_pooling2d_5\n",
      "152 conv2d_41\n",
      "153 conv2d_44\n",
      "154 conv2d_49\n",
      "155 conv2d_50\n",
      "156 batch_normalization_41\n",
      "157 batch_normalization_44\n",
      "158 batch_normalization_49\n",
      "159 batch_normalization_50\n",
      "160 activation_41\n",
      "161 activation_44\n",
      "162 activation_49\n",
      "163 activation_50\n",
      "164 mixed5\n",
      "165 conv2d_55\n",
      "166 batch_normalization_55\n",
      "167 activation_55\n",
      "168 conv2d_56\n",
      "169 batch_normalization_56\n",
      "170 activation_56\n",
      "171 conv2d_52\n",
      "172 conv2d_57\n",
      "173 batch_normalization_52\n",
      "174 batch_normalization_57\n",
      "175 activation_52\n",
      "176 activation_57\n",
      "177 conv2d_53\n",
      "178 conv2d_58\n",
      "179 batch_normalization_53\n",
      "180 batch_normalization_58\n",
      "181 activation_53\n",
      "182 activation_58\n",
      "183 average_pooling2d_6\n",
      "184 conv2d_51\n",
      "185 conv2d_54\n",
      "186 conv2d_59\n",
      "187 conv2d_60\n",
      "188 batch_normalization_51\n",
      "189 batch_normalization_54\n",
      "190 batch_normalization_59\n",
      "191 batch_normalization_60\n",
      "192 activation_51\n",
      "193 activation_54\n",
      "194 activation_59\n",
      "195 activation_60\n",
      "196 mixed6\n",
      "197 conv2d_65\n",
      "198 batch_normalization_65\n",
      "199 activation_65\n",
      "200 conv2d_66\n",
      "201 batch_normalization_66\n",
      "202 activation_66\n",
      "203 conv2d_62\n",
      "204 conv2d_67\n",
      "205 batch_normalization_62\n",
      "206 batch_normalization_67\n",
      "207 activation_62\n",
      "208 activation_67\n",
      "209 conv2d_63\n",
      "210 conv2d_68\n",
      "211 batch_normalization_63\n",
      "212 batch_normalization_68\n",
      "213 activation_63\n",
      "214 activation_68\n",
      "215 average_pooling2d_7\n",
      "216 conv2d_61\n",
      "217 conv2d_64\n",
      "218 conv2d_69\n",
      "219 conv2d_70\n",
      "220 batch_normalization_61\n",
      "221 batch_normalization_64\n",
      "222 batch_normalization_69\n",
      "223 batch_normalization_70\n",
      "224 activation_61\n",
      "225 activation_64\n",
      "226 activation_69\n",
      "227 activation_70\n",
      "228 mixed7\n",
      "229 conv2d_73\n",
      "230 batch_normalization_73\n",
      "231 activation_73\n",
      "232 conv2d_74\n",
      "233 batch_normalization_74\n",
      "234 activation_74\n",
      "235 conv2d_71\n",
      "236 conv2d_75\n",
      "237 batch_normalization_71\n",
      "238 batch_normalization_75\n",
      "239 activation_71\n",
      "240 activation_75\n",
      "241 conv2d_72\n",
      "242 conv2d_76\n",
      "243 batch_normalization_72\n",
      "244 batch_normalization_76\n",
      "245 activation_72\n",
      "246 activation_76\n",
      "247 max_pooling2d_4\n",
      "248 mixed8\n",
      "249 conv2d_81\n",
      "250 batch_normalization_81\n",
      "251 activation_81\n",
      "252 conv2d_78\n",
      "253 conv2d_82\n",
      "254 batch_normalization_78\n",
      "255 batch_normalization_82\n",
      "256 activation_78\n",
      "257 activation_82\n",
      "258 conv2d_79\n",
      "259 conv2d_80\n",
      "260 conv2d_83\n",
      "261 conv2d_84\n",
      "262 average_pooling2d_8\n",
      "263 conv2d_77\n",
      "264 batch_normalization_79\n",
      "265 batch_normalization_80\n",
      "266 batch_normalization_83\n",
      "267 batch_normalization_84\n",
      "268 conv2d_85\n",
      "269 batch_normalization_77\n",
      "270 activation_79\n",
      "271 activation_80\n",
      "272 activation_83\n",
      "273 activation_84\n",
      "274 batch_normalization_85\n",
      "275 activation_77\n",
      "276 mixed9_0\n",
      "277 concatenate_1\n",
      "278 activation_85\n",
      "279 mixed9\n",
      "280 conv2d_90\n",
      "281 batch_normalization_90\n",
      "282 activation_90\n",
      "283 conv2d_87\n",
      "284 conv2d_91\n",
      "285 batch_normalization_87\n",
      "286 batch_normalization_91\n",
      "287 activation_87\n",
      "288 activation_91\n",
      "289 conv2d_88\n",
      "290 conv2d_89\n",
      "291 conv2d_92\n",
      "292 conv2d_93\n",
      "293 average_pooling2d_9\n",
      "294 conv2d_86\n",
      "295 batch_normalization_88\n",
      "296 batch_normalization_89\n",
      "297 batch_normalization_92\n",
      "298 batch_normalization_93\n",
      "299 conv2d_94\n",
      "300 batch_normalization_86\n",
      "301 activation_88\n",
      "302 activation_89\n",
      "303 activation_92\n",
      "304 activation_93\n",
      "305 batch_normalization_94\n",
      "306 activation_86\n",
      "307 mixed9_1\n",
      "308 concatenate_2\n",
      "309 activation_94\n",
      "310 mixed10\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2050        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,788,130\n",
      "Trainable params: 2,100,226\n",
      "Non-trainable params: 10,687,904\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "# get inception model\n",
    "model = get_inception_model(train_generator, validation_generator, init_epochs, init_verbose, sgd, loss, metrics, tensorboard, init_callbacks, num_class, include_top, non_trainable_index, print_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Training\n",
    "#### Starts training with given parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f3bcb0d4a7d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# compile model with loss, optimizer and metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m history = model.fit_generator(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m             self.writer = tf.summary.FileWriter(self.log_dir,\n\u001b[1;32m--> 854\u001b[1;33m                                                 self.sess.graph)\n\u001b[0m\u001b[0;32m    855\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, logdir, graph, max_queue, flush_secs, graph_def, filename_suffix, session)\u001b[0m\n\u001b[0;32m    365\u001b[0m       event_writer = EventFileWriter(logdir, max_queue, flush_secs,\n\u001b[0;32m    366\u001b[0m                                      filename_suffix)\n\u001b[1;32m--> 367\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, event_writer, graph, graph_def)\u001b[0m\n\u001b[0;32m     88\u001b[0m       self.add_meta_graph(\n\u001b[0;32m     89\u001b[0m           meta_graph.create_meta_graph_def(graph_def=graph_def or\n\u001b[1;32m---> 90\u001b[1;33m                                            maybe_graph_as_def))\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# This set contains tags of Summary Values that have been encountered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36madd_meta_graph\u001b[1;34m(self, meta_graph_def, global_step)\u001b[0m\n\u001b[0;32m    244\u001b[0m       raise TypeError(\"meta_graph_def must be type MetaGraphDef, saw type: %s\" %\n\u001b[0;32m    245\u001b[0m                       type(meta_graph_def))\n\u001b[1;32m--> 246\u001b[1;33m     \u001b[0mmeta_graph_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m     \u001b[0mevent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevent_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmeta_graph_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mSerializeToString\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m           'Message %s is missing required fields: %s' % (\n\u001b[0;32m   1041\u001b[0m           self.DESCRIPTOR.full_name, ','.join(self.FindInitializationErrors())))\n\u001b[1;32m-> 1042\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m   \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSerializeToString\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mSerializePartialToString\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m   \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mInternalSerialize\u001b[1;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m         \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m         \u001b[0mwrite_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py\u001b[0m in \u001b[0;36mEncodeField\u001b[1;34m(write, value, deterministic)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mEncodeField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m       \u001b[0mlocal_EncodeVarint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mEncodeField\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mByteSize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m         \u001b[0msize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[0msize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py\u001b[0m in \u001b[0;36mRepeatedFieldSize\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    300\u001b[0m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlocal_VarintSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mByteSize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1017\u001b[0m       \u001b[0msize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields_by_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1019\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1020\u001b[0m         \u001b[0msize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mListFields\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m     \u001b[0mall_fields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_IsPresent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    779\u001b[0m     \u001b[0mall_fields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mall_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m     \u001b[0mall_fields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_IsPresent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    779\u001b[0m     \u001b[0mall_fields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mall_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36m_IsPresent\u001b[1;34m(item)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_IsPresent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m   \"\"\"Given a (FieldDescriptor, value) tuple from _fields, return true if the\n\u001b[0;32m    764\u001b[0m   value should be included in the list returned by ListFields().\"\"\"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "model.compile(sgd, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "#     verbose=verbose,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Import and Validation Performance Visualization\n",
    "#### Plotting Training and Validation Performance over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining \n",
    "#### Retraining Best Model\n",
    "###### Selecting Best Model File and Parameters for Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best model file / checkpoint for retraining\n",
    "model_path = model_dir+r\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "model_path = model_dir+r\"20-val_acc-0.66-val_loss-1.97.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining \n",
    "#### Retraining Best Model\n",
    "###### Loading Best Model for Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining \n",
    "#### Retraining Best Model\n",
    "#### Configuration for Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=32\n",
    "# # batch_size=64\n",
    "# class_mode='categorical'\n",
    "# # class_mode='binary'\n",
    "\n",
    "# loss='categorical_crossentropy'\n",
    "# # loss='binary_crossentropy'\n",
    "\n",
    "# # metrics=['accuracy', 'binary_accuracy', precision, recall]\n",
    "# metrics=['accuracy']\n",
    "\n",
    "epochs = 50\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retrain the selected best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain by loading last good model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_pos_neg(CM, print_bool):\n",
    "    tp=CM[0][0]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    tn=CM[1][1]\n",
    "    if print_bool:\n",
    "        print(tp, fp, tn, fn, tn)\n",
    "    return [tp, fp, tn, fn, tn]\n",
    "\n",
    "\n",
    "def report(CM, reverse):\n",
    "    if not reverse:\n",
    "        tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "    else:\n",
    "        tp=CM[0][0]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        tn=CM[1][1]\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "    print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "#### Testing all saved models\n",
    "##### Testing all models saved on each epochs to search for the best model based on test dataset image recognition performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model\n",
    "\n",
    "details = False\n",
    "best_accuracy = 0\n",
    "best_loss = 0\n",
    "\n",
    "lowest_accuracy = 100\n",
    "lowest_loss = 1000000\n",
    "\n",
    "models_path = \"data\\\\output\\\\models\\\\\"\n",
    "\n",
    "best_model_acc = \"\"\n",
    "best_model_loss = \"\"\n",
    "\n",
    "models_arr = []\n",
    "accuracy_arr = []\n",
    "loss_arr = []\n",
    "\n",
    "model_files = os.listdir(models_path)\n",
    "\n",
    "i=0\n",
    "for model_file in model_files:\n",
    "    model_path = models_path+\"\\\\\"+model_file\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        pass\n",
    "    tf.reset_default_graph()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    model = keras.models.load_model(model_path)\n",
    "    \n",
    "    result = model.evaluate_generator(generator=test_generator, steps=len(test_generator))\n",
    "    \n",
    "    accuracy = result[1]*100\n",
    "    loss = result[0]\n",
    "    \n",
    "    accuracy_arr.append(accuracy)\n",
    "    loss_arr.append(loss)\n",
    "    models_arr.append(model_path)\n",
    "    \n",
    "    if accuracy>best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_loss = loss\n",
    "        best_model_acc=model_path\n",
    "        \n",
    "    if loss<lowest_loss:\n",
    "        lowest_accuracy = accuracy\n",
    "        lowest_loss = loss\n",
    "        best_model_loss=model_path\n",
    "        \n",
    "    if details:\n",
    "        print(\"%s%s\"%(\"Model No: \", i))\n",
    "        print(\"%s%s\"%(\"Model File Path: \", model_file))\n",
    "        print(\"*\"*80)\n",
    "        print(\"%s%.2f%s\"% (\"Current Accuracy: \", accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Current Loss: \", loss))\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        print(\"%s%.2f%s\"% (\"Best Test Accuracy (Accuracy wise):\", best_accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Best Test Loss (Accuracy wise): \", best_loss))\n",
    "\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        print(\"%s%.2f%s\"% (\"Best Test Accuracy (Loss wise): \", lowest_accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Best Test Loss (Loss wise): \", lowest_loss))\n",
    "\n",
    "    elif i%10==0:\n",
    "        print(\"%s%s\"%(\"Model No: \", i))\n",
    "        print(\"%s%s\"%(\"Model File Path: \", model_file))\n",
    "        print(\"*\"*80)\n",
    "        \n",
    "        print(\"%s%.2f%s\"% (\"Best Test Accuracy: \", best_accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Best Test Loss: \", best_loss))\n",
    "\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        print(\"%s%.2f%s\"% (\"Best Test Accuracy (Loss wise): \", lowest_accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Best Test Loss (Loss wise): \", lowest_loss))\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model  2\n",
    "\n",
    "target_names = ['Cancer', 'Normal']\n",
    "CM_list = []\n",
    "    \n",
    "details = True\n",
    "best_accuracy = 0\n",
    "best_loss = 0\n",
    "\n",
    "lowest_accuracy = 100\n",
    "lowest_loss = 1000000\n",
    "\n",
    "models_path = \"data\\\\output\\\\models\\\\\"\n",
    "\n",
    "best_model_acc = \"\"\n",
    "best_model_loss = \"\"\n",
    "\n",
    "models_arr = []\n",
    "accuracy_arr = []\n",
    "loss_arr = []\n",
    "\n",
    "model_files = os.listdir(models_path)\n",
    "\n",
    "i=0\n",
    "\n",
    "for model_file in model_files:\n",
    "    model_path = models_path+\"\\\\\"+model_file\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        pass\n",
    "    tf.reset_default_graph()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "    preds = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "    y_classes = preds.argmax(axis=-1)\n",
    "\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    CM_report = classification_report(test_generator.classes, y_classes, target_names=target_names)\n",
    "    \n",
    "    models_arr.append(model_path)\n",
    "    CM_list.append({model_file: CM})\n",
    "        \n",
    "    if details:\n",
    "        print(\"%s%s\"%(\"Model No: \", i))\n",
    "        print(\"%s%s\"%(\"Model File Path: \", model_file))\n",
    "        print(\"*\"*80)\n",
    "        print(CM_report)\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print(\"-\"*80)\n",
    "\n",
    "    elif i%10==0:\n",
    "        print(\"%s%s\"%(\"Model No: \", i))\n",
    "        print(\"%s%s\"%(\"Model File Path: \", model_file))\n",
    "        print(\"*\"*80)\n",
    "        print(CM_report)\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print(\"-\"*80)\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing best model accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*17,\"Summary of Model Performance on Test Dataset\", \"-\"*17)\n",
    "\n",
    "print(\"%s%s\"% (\"Best Model Path (Accuracy): \", best_model_acc))\n",
    "print(\"%s%.2f%s\"% (\"Best Test Accuracy: \", best_accuracy, \"%\"))\n",
    "print(\"%s%.2f\"% (\"Best Test Loss: \", best_loss))\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"%s%s\"% (\"Best Model Path (Loss): \", best_model_loss))\n",
    "print(\"%s%.2f%s\"% (\"Best Test Accuracy: \", lowest_accuracy, \"%\"))\n",
    "print(\"%s%.2f\"% (\"Best Test Loss: \", lowest_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting all model performance over all epochs and models for accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_arr = np.arange(len(accuracy_arr))\n",
    "plt.title(\"Test Dataset Performance (Accuracy)\")\n",
    "plt.plot(x_axis_arr, accuracy_arr)\n",
    "plt.xlabel(\"Iteration Number\")\n",
    "plt.ylabel(\"Accuracy (100%)\")\n",
    "plt.show()\n",
    "\n",
    "x_axis_arr = np.arange(len(loss_arr))\n",
    "plt.title(\"Test Dataset Performance (Loss)\")\n",
    "plt.plot(x_axis_arr, loss_arr)\n",
    "plt.xlabel(\"Iteration Number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting Best Model for full evaluation (for accuracy/f1 score or recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy/ F-1 score\n",
    "# model_path = \"data/output/models/\"+\"17-val_acc-0.82-val_loss-0.42.hdf5\"\n",
    "\n",
    "# Lowest validation Loss\n",
    "# model_path = \"data/output/models/\"+\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "\n",
    "# Best Recall\n",
    "model_path = \"data/output/models/\"+\"20-val_acc-0.66-val_loss-1.97.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Best Model for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model\n",
    "model = keras.models.load_model(model_path)\n",
    "result = model.evaluate_generator(generator=test_generator, steps=len(test_generator), verbose=1)\n",
    "print(\"-\"*17,\"Summary of Best Model Performance on Test Dataset\", \"-\"*17)\n",
    "print(\"%s%.2f%s\"% (\"Test Accuracy: \", result[1]*100, \"%\"))\n",
    "print(\"%s%.2f\"% (\"Test Loss: \", result[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting Best Model for further analysis, evaluation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model\n",
    "model = keras.models.load_model(model_path)\n",
    "preds = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "y_classes = preds.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def extract_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    extracted_id = b[0]\n",
    "    \n",
    "    return extracted_id\n",
    "\n",
    "\n",
    "\n",
    "test_filenames = test_generator.filenames\n",
    "df_preds = pd.DataFrame(predictions, columns=classes)\n",
    "df_preds['file_names'] = test_filenames\n",
    "df_preds['id'] = df_preds['file_names'].apply(extract_id)\n",
    "df_preds.head()\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['Cancer']\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "roc_auc_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':image_id, \n",
    "                           'label':y_pred, \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('patch_preds.csv', columns=['label']) \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing Confusion Matrix of Model Performance for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Cancer', 'Normal']\n",
    "\n",
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), target_names, fontsize=16)\n",
    "plt.yticks(range(2), target_names, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing precision, recall, f1-score, support for Model Performance over Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report_print = classification_report(test_generator.classes, y_classes, target_names=target_names)\n",
    "print(classification_report_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing calcualted precision, recall for Model over Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision and Recall\n",
    "tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retriving actual labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (test_generator.class_indices)\n",
    "label_map_rev = {v: name_correct(k) for k,v in label_map.items()}\n",
    "num_batch_t = len(test_generator)\n",
    "print(label_map)\n",
    "print(label_map_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing accuracy for Model over Single Batch of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0, num_batch_t-1)\n",
    "y_img_batch, y_class_batch = test_generator[num] \n",
    "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
    "y_true = np.argmax(y_class_batch,-1)\n",
    "print(\"Selected Batch No: %d\\nBatch Size: %d\"%(num, len(y_pred)))\n",
    "print(\"Accuracy : \", sum(y_pred==y_true)/batch_size*100, \"%\")\n",
    "\n",
    "y_true_labels = [label_map_rev[c] for c in y_true]\n",
    "y_pred_labels = [label_map_rev[c] for c in y_pred]\n",
    "batch_size_t = len(y_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n",
    "Visualization of performance of a random test dataset batch and few random images from a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/result\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "\n",
    "cols = 8\n",
    "rows= batch_size_t/cols\n",
    "if batch_size_t%cols==0:\n",
    "    rows = int(batch_size_t/cols)\n",
    "else:\n",
    "    rows = int(batch_size_t/cols)+1\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org : \"\n",
    "pred_label_title_prefix = \"pred: \"\n",
    "\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "for i in range(0, batch_size_t): # how many imgs will show from the mxn grid\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[i])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[i]==y_pred_labels[i]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i], color=false_prediction_label_color)\n",
    "        \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)\n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/sample\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "cols = 4\n",
    "rows= 2\n",
    "\n",
    "count = rows*cols\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "# titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org:  \"\n",
    "pred_label_title_prefix = \"pred: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "\n",
    "batch_size_tmp = batch_size_t\n",
    "\n",
    "m = {}\n",
    "\n",
    "for i in range(0, count): \n",
    "    num = random.randint(0, batch_size_tmp-1)\n",
    "    while num in m:\n",
    "        num = random.randint(0, batch_size_tmp-1)\n",
    "    \n",
    "    m[num]=1\n",
    "    \n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[num])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[num]==y_pred_labels[num]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num], color=false_prediction_label_color)\n",
    "    \n",
    "   \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)   \n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
