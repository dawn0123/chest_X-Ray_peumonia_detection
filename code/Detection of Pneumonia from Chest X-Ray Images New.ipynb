{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "<pre>\n",
    "Author           : Anjana Tiha\n",
    "Project Name     : Detection of Pneumonia from Chest X-Ray Images using Convolutional Neural Network, \n",
    "                   and Transfer Learning.\n",
    "Description      : 1. Detected Pneumonia from Chest X-Ray images by retraining pretrained model “InceptionV3” \n",
    "                      with 5856 images of X-ray (1.15GB).\n",
    "                   2. For retraining removed output layers, freezed first few layers and Fine-tuned model for \n",
    "                      two new label classes (Pneumonia and Normal).\n",
    "                   3. Attained testing accuracy 83.44% and loss 0.42.\n",
    "Method           : \n",
    "Tools/Library    : Python, Keras, PyTorch, TensorFlow\n",
    "Version History  : 1.0.0.0\n",
    "Current Version  : 1.0.0.0\n",
    "Last Update      : 11.30.2018\n",
    "Comments         : Please use Anaconda editor for convenience of visualization.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "<pre>\n",
    "GitHub Link      : <a href=https://github.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitHub)</a>\n",
    "GitLab Link      : <a href=https://gitlab.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitLab)</a>\n",
    "Portfolio        : <a href=https://anjanatiha.wixsite.com/website>Anjana Tiha's Portfolio</a>\n",
    "</pre>\n",
    "\n",
    "#### Dataset\n",
    "<pre>\n",
    "Dataset Name     : Chest X-Ray Images (Pneumonia)\n",
    "Dataset Link     : <a href=https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia>Chest X-Ray Images (Pneumonia) Dataset (Kaggle)</a>\n",
    "                 : <a href=https://data.mendeley.com/datasets/rscbjbr9sj/2>Chest X-Ray Images (Pneumonia) Dataset (Original Dataset)</a>\n",
    "Original Paper   : <a href=https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5>Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning</a>\n",
    "                   (Daniel S. Kermany, Michael Goldbaum, Wenjia Cai, M. Anthony Lewis, Huimin Xia, Kang Zhang)\n",
    "                   https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library/Tools Version\n",
    "- Python - v3.6.7\n",
    "- argparse\n",
    "- random\n",
    "- numpy\n",
    "- shutil\n",
    "- gc\n",
    "- re\n",
    "- Keras - 2.2.4\n",
    "- Keras-preprocessing - v1.0.5\n",
    "- TensorFlow - 1.12\n",
    "- PIL/Pillow - 5.1.0\n",
    "- Matplotlib - 2.2.2\n",
    "- scikit-learn - 0.19.1\n",
    "- mlxtend - 0.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands / Running Instruction\n",
    "<pre>\n",
    "tensorboard --logdir=logs\n",
    "%config IPCompleter.greedy=True\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>Dataset Details</b>\n",
    "Dataset Name            : Chest X-Ray Images (Pneumonia)\n",
    "Number of Class         : 2\n",
    "Number/Size of Images   : Total      : 5856 (1.15 Gigabyte (GB))\n",
    "                          Training   : 5216 (1.07 Gigabyte (GB))\n",
    "                          Validation : 320  (42.8 Megabyte (MB))\n",
    "                          Testing    : 320  (35.4 Megabyte (MB))\n",
    "\n",
    "<b>Model Parameters</b>\n",
    "Machine Learning Library: Keras\n",
    "Base Model              : InceptionV3\n",
    "Optimizers              : Adam\n",
    "Loss Function           : categorical_crossentropy\n",
    "\n",
    "<b>Training Parameters</b>\n",
    "Batch Size              : 64\n",
    "Number of Epochs        : 50\n",
    "Training Time           : 3 Hours\n",
    "\n",
    "<b>Output (Prediction/ Recognition / Classification Metrics)</b>\n",
    "<!--<b>Validation</b>-->\n",
    "<b>Testing</b>\n",
    "Accuracy                : 83.44%\n",
    "Loss                    : 0.42\n",
    "<!--Precision               : -->\n",
    "Recall                  : 94% (highest)\n",
    "<!--Specificity             : -->\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import inspect\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes directory, if directory exists removes if remove parameter is set to True \n",
    "def mk_reset_dir(directory, remove=False):\n",
    "    if remove and os.path.exists(directory):\n",
    "        try:\n",
    "            shutil.rmtree(directory)\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory)\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print time with date, month, year and hour, minute, second in format given by parameter\n",
    "def date_time(x):\n",
    "    if x==1:\n",
    "        print('Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==2:    \n",
    "        print('Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==3:  \n",
    "        print('Date now: %s' % datetime.datetime.now())\n",
    "    if x==4:  \n",
    "        print('Date today: %s' % datetime.date.today())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints a integer for degugging\n",
    "def debug(x):\n",
    "    print(\"-\"*40, x, \"-\"*40)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of files in each subdirectory of a directory\n",
    "def count_bar(master_directory):\n",
    "    dir_list = os.listdir(master_directory)\n",
    "    num_class = len(dir_list)\n",
    "\n",
    "    dir_name = []\n",
    "    dir_file_count = []\n",
    "\n",
    "    for directory in dir_list:\n",
    "        cur_dir = os.path.join(master_directory, directory)\n",
    "        count_sample = len(os.listdir(cur_dir))\n",
    "        dir_name.append(directory)\n",
    "        dir_file_count.append(count_sample)\n",
    "    \n",
    "    return dir_name, dir_file_count\n",
    "               \n",
    "\n",
    "# show barplot\n",
    "def bar_plot(x, y, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    sns.barplot(x=x, y=y)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    \n",
    "\n",
    "# show bar plot for count of labels in subdirectory of a directory\n",
    "def count_bar_plot(master_directory, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    dir_name, dir_file_count = count_bar(master_directory)\n",
    "    x=dir_name\n",
    "    y=dir_file_count\n",
    "    bar_plot(x, y, title, xlabel, ylabel, figsize=fig_size, title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=subplot_no)\n",
    "    \n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a training, validation, testing directory    \n",
    "def show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    count_bar_plot(training_dir, title +\" (Training)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=131)\n",
    "    count_bar_plot(validation_dir, title +\" (Validation)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=132)\n",
    "    count_bar_plot(testing_dir, title +\" (Testing)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=133)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches)\n",
    "def get_transformed_image_batch(directory, target_size, classes, class_mode='categorical', batch_size=1, shuffle=True, rescale=None, shear_range=0.0, zoom_range=0.0, horizontal_flip=False, validation_split=0.0):       \n",
    "    datagen = ImageDataGenerator(\n",
    "            rescale=rescale,\n",
    "            shear_range=shear_range,\n",
    "            zoom_range=zoom_range,\n",
    "            horizontal_flip=horizontal_flip,\n",
    "            validation_split=validation_split)     \n",
    "    \n",
    "    image_generator = datagen.flow_from_directory(\n",
    "            directory,\n",
    "            target_size=target_size,\n",
    "            classes = classes,\n",
    "            class_mode=class_mode,\n",
    "            batch_size=batch_size)\n",
    "    return image_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Label Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust class weights for imbalanced dataset of classes of images\n",
    "def get_class_weight(y):\n",
    "    counter = Counter(y)                          \n",
    "    max_val = float(max(counter.values()))     \n",
    "    class_weight = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Graph Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tensorflow graph tp free up memory and resource allocation \n",
    "def reset_graph(model=None):\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        return False\n",
    "    tf.reset_default_graph()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    return True\n",
    "\n",
    "\n",
    "# reset callbacks \n",
    "def reset_callbacks(checkpoint=None, reduce_lr=None, early_stopping=None, tensorboard=None):\n",
    "    checkpoint=None\n",
    "    reduce_lr = None\n",
    "    early_stopping = None\n",
    "    tensorboard = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish_activation(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "def basic_model(optimizer, loss, metrics, input_shape=(3,150,150), activation='relu', activation2='sigmoid', padding=\"same\", padding2=\"valid\", pool_size=(2, 2), dilation_rate=(2, 2)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(64, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(96, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(96, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(128, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation=swish_activation))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2 , activation=activation2))\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=metrics)\n",
    "\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "    \n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization Function\n",
    "#### Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "<p>1. Imports Pretrained model InceptionV3 <br>\n",
    "   2. Disabled training on first few layers <br>\n",
    "   3. Enabled training on top and output layers<br>\n",
    "   4. Adjust output Dense Layer to number of Image Classes <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and configure model InceptionV3 for fine-tuning with new class labels\n",
    "def get_inception_model(train_generator, validation_generator, epochs, verbose, optimizer, loss, metrics, tensorboard, callbacks, num_class, include_top=False, non_trainable_index=249, print_layers = False):    \n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=include_top)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    # Setting model layers specially output layer with class number\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 2 classes\n",
    "\n",
    "    # softmax for multi-class\n",
    "    predictions = Dense(num_class, activation='softmax')(x) \n",
    "    \n",
    "    # sigmoid for 2 class or binary class\n",
    "    # predictions = Dense(num_class, activation='sigmoid')(x) \n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "     \n",
    "    # compile model with loss, optimizer and metrics \n",
    "    model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    \n",
    "    if callbacks:\n",
    "        tensorboard.set_model(model) \n",
    "    \n",
    "    # train the model on the new data for a few epochs\n",
    "    model.fit_generator(train_generator,\n",
    "                        steps_per_epoch = len(train_generator),\n",
    "                        epochs=epochs,\n",
    "                        # verbose=verbose, \n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=len(validation_generator),\n",
    "                        class_weight = class_weight)\n",
    "\n",
    "    # at this point, the top layers are well trained and we can start fine-tuning\n",
    "    # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "    # and train the remaining top layers.\n",
    "\n",
    "    # let's visualize layer names and layer indices to see how many layers\n",
    "    # we should freeze:\n",
    "    if print_layers:\n",
    "        for i, layer in enumerate(base_model.layers):\n",
    "            print(i, layer.name)\n",
    "\n",
    "    # Freeze or set first few layers as untrainable\n",
    "    # Unfreeze or set rest of the layers as trainable\n",
    "    for layer in model.layers[:non_trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[non_trainable_index:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Performance Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation performance\n",
    "def plot_history(history, plot_val, title, xlabel, ylabel, legend=[['Train', 'Val'], ['Train', 'Val']], fig_size=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history[plot_val[0][0]])\n",
    "    plt.plot(history.history[plot_val[0][1]])\n",
    "    plt.title(title[0], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[0], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[0], fontsize=label_fontsize)\n",
    "    plt.legend(legend[0], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history[plot_val[1][0]])\n",
    "    plt.plot(history.history[plot_val[1][1]])\n",
    "    plt.title(title[1], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[1], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[1], fontsize=label_fontsize)\n",
    "    plt.legend(legend[1], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Performance Report Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_report(model, test_generator, classes, print_report=False):\n",
    "    y_preds = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "    y_classes = y_preds.argmax(axis=-1)\n",
    "\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    CM_report = classification_report(test_generator.classes, y_classes, target_names=classes)\n",
    "    \n",
    "    if print_report: \n",
    "        print(CM_report)\n",
    "    return y_preds, y_classes, CM, CM_report\n",
    "\n",
    "def model_evaluate(model, test_generator, print_report=False):\n",
    "    result = model.evaluate_generator(generator=test_generator, steps=len(test_generator))\n",
    "    \n",
    "    accuracy = result[1]*100\n",
    "    loss = result[0]\n",
    "    \n",
    "    if print_report:\n",
    "        print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "    \n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse classification report for reporting negetive classes (0)\n",
    "def reverse_pos_neg(CM, print_bool):\n",
    "    tp=CM[0][0]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    tn=CM[1][1]\n",
    "    if print_bool:\n",
    "        print(tp, fp, tn, fn, tn)\n",
    "    return [tp, fp, tn, fn, tn]\n",
    "\n",
    "# reverse and report classification report for reporting negetive classes (0)\n",
    "def report(CM, reverse):\n",
    "    if not reverse:\n",
    "        tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "    else:\n",
    "        tp=CM[0][0]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        tn=CM[1][1]\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "    print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_models(model_dir, details, report_type, classes):\n",
    "    results = {}\n",
    "    \n",
    "    model_files = os.listdir(model_dir)\n",
    "    \n",
    "    i=0\n",
    "    model = None\n",
    "    \n",
    "    for model_file in model_files:\n",
    "        \n",
    "        model_path = model_dir+\"\\\\\"+model_file\n",
    "        \n",
    "        if not path.isdir(model_path):\n",
    "            reset_graph(model)\n",
    "\n",
    "            model = keras.models.load_model(model_path)\n",
    "\n",
    "            if report_type==\"Complete\":\n",
    "                y_preds, y_classes, CM, CM_report = predict_report(model, test_generator, classes)\n",
    "                results[model_file] = [CM, CM_report]\n",
    "\n",
    "            else:\n",
    "                accuracy, loss =  model_evaluate(model, test_generator, print_report=False)\n",
    "\n",
    "                results[model_file] = [accuracy, loss]\n",
    "\n",
    "\n",
    "            if details:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_file))\n",
    "                print(\"*\"*80)\n",
    "                if report_type==\"Complete\":\n",
    "                    print(CM_report)\n",
    "                else:\n",
    "                    print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "                    print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            elif not details and i%10==0:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_file))\n",
    "                print(\"*\"*80)\n",
    "                if report_type==\"Complete\":\n",
    "                    print(CM_report)\n",
    "                else:\n",
    "                    print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "                    print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            i+=1\n",
    "    print(\"Test complete\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_over_epochs(array, title, xlabel=\"Epoch\", ylabel=\"Value\", title_fontsize=14, label_fontsize=12, subplot_no=0):\n",
    "    x_axis_arr = np.arange(len(array))\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.plot(x_axis_arr, array)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    \n",
    "def line_plot_over_epochs_loss_acc(array, title, fig_size=(10, 8), xlabel=[\"Epoch\", \"Epoch\"], ylabel=[\"Value\",\"Value\"], title_fontsize=14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    line_plot_over_epochs(array[0], title[0], xlabel=xlabel[0], ylabel=ylabel[0], title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=121)\n",
    "    line_plot_over_epochs(array[1], title[1], xlabel=xlabel[1], ylabel=ylabel[1], title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=122)\n",
    "    plt.show()\n",
    "    \n",
    "def show_confusion_matrix(test_generator, y_classes, classes, figsize=(10,8), stick_fontsize=12):\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=figsize, hide_ticks=True,cmap=plt.cm.Blues)\n",
    "    plt.xticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.yticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.show()\n",
    "    return CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-455a2dc4cf83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreset_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Train, Validation and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input/ output directory\n",
    "# Configure training, validation, testing directory\n",
    "\n",
    "input_directory = r\"data/input/\"\n",
    "output_directory = r\"data/output/\"\n",
    "\n",
    "training_dir = input_directory+ r\"train\"\n",
    "testing_dir = input_directory+ r\"test\"\n",
    "validation_dir = input_directory+ r\"val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xlabel=\"Count\"\n",
    "ylabel=\"CaseType\"\n",
    "fig_size = (14,4)\n",
    "# fig_size = (4,2)\n",
    "# title_fontsize=14\n",
    "title_fontsize=13\n",
    "# label_fontsize=12\n",
    "label_fontsize=13\n",
    "title=\"Number of Cases\"\n",
    "\n",
    "\n",
    "show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=fig_size, title_fontsize = title_fontsize, label_fontsize=label_fontsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (Image Preprocessing)\n",
    "#### Configuring Image Transformation Parameters for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get number of label/ class / category\n",
    "num_class = len(os.listdir(training_dir))\n",
    "print(num_class)\n",
    "\n",
    "\n",
    "#Image Augmentation/ Preprocessing before training\n",
    "norm=255.0\n",
    "rescale=1./norm\n",
    "# shear_range=0.2\n",
    "shear_range=0.1\n",
    "# zoom_range=0.2\n",
    "zoom_range=0.1\n",
    "horizontal_flip=True\n",
    "\n",
    "\n",
    "# flow from directory function\n",
    "# Target Image dimention\n",
    "target_size=(224, 224)\n",
    "\n",
    "# Batch size\n",
    "# train\n",
    "# batch_size=32\n",
    "batch_size=64\n",
    "# batch_size=128\n",
    "\n",
    "# validation\n",
    "validation_batch_size=1\n",
    "# test\n",
    "test_batch_size=1\n",
    "\n",
    "# shuffle\n",
    "# test\n",
    "test_shuffle=False\n",
    "\n",
    "# validation split for train\n",
    "validation_split=0.0\n",
    "\n",
    "# class mode\n",
    "# class_mode='binary'\n",
    "class_mode='categorical'\n",
    "# class_mode='sparse'\n",
    "\n",
    "\n",
    "classes = ['Normal', 'PNEUMONIA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_transformed_image_batch(training_dir, target_size, classes, class_mode=class_mode, batch_size=batch_size, rescale=rescale, shear_range=shear_range, zoom_range=zoom_range, horizontal_flip=horizontal_flip)       \n",
    "\n",
    "validation_generator = get_transformed_image_batch(validation_dir, target_size, classes, class_mode=class_mode, batch_size=validation_batch_size, rescale=rescale)       \n",
    "\n",
    "test_generator = get_transformed_image_batch(validation_dir, target_size, classes, class_mode=class_mode, batch_size=test_batch_size, shuffle = test_shuffle, rescale=rescale) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Adjustmanet for Class Label Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_generator.classes\n",
    "class_weight=get_class_weight(y)\n",
    "# class_weight=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model and Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model and log output directory\n",
    "model_dir=output_directory + r\"models/\"\n",
    "log_dir=output_directory + r\"logs\"\n",
    "\n",
    "# make or reset directory\n",
    "# mk_reset_dir(model_dir, False)\n",
    "# mk_reset_dir(log_dir, False)\n",
    "\n",
    "model_file=model_dir+\"base-\"+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(3,150,150)\n",
    "activation='relu'\n",
    "activation2='sigmoid'\n",
    "padding=\"same\"\n",
    "padding2=\"valid\"\n",
    "pool_size=(2, 2)\n",
    "dilation_rate=(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Base Model and Training Configuration for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Base Model - InceptionV3 (pretrained) initial training settings\n",
    "\n",
    "# inception base top layer discarded\n",
    "include_top=False\n",
    "\n",
    "# number of layers freezed\n",
    "non_trainable_index = 249\n",
    "\n",
    "# init_optimizer=optimizers.Adam()\n",
    "init_optimizer=optimizers.Adam(0.000001)\n",
    "\n",
    "print_layers=False\n",
    "\n",
    "# initial epochs on only output layers\n",
    "# init_epochs=1\n",
    "# initial_epochs=3\n",
    "init_epochs=15\n",
    "\n",
    "# verbose\n",
    "init_verbose=0\n",
    "\n",
    "# callbacks\n",
    "init_callbacks=None\n",
    "\n",
    "# model report\n",
    "print_layers=True\n",
    "\n",
    "\n",
    "### Full model training parameter configuration for Loss, Optimizer and Performance Metrics\n",
    "\n",
    "# optimizer\n",
    "# adam lr=0.01/0.001/0.0001/0.00001/0.000001, decay = decay=1e-5/ 1e-6\n",
    "# optimizer=optimizers.Adam()\n",
    "# optimizer=Adam(lr=0.0001, decay=1e-5)\n",
    "optimizer=optimizers.Adam(0.1)\n",
    "\n",
    "\n",
    "# loss function\n",
    "# loss='binary_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "# performance metrics ('accuracy', 'binary_accuracy', precision, recall)\n",
    "# metrics=['accuracy']\n",
    "metrics=['mae', 'acc']\n",
    "\n",
    "\n",
    "### Main model training parameter configuration\n",
    "\n",
    "# epochs = 20/30/50\n",
    "epochs = 30\n",
    "\n",
    "# steps\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "# verbose 0=nothing 1=each line\n",
    "verbose=0\n",
    "\n",
    "\n",
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard\n",
    "\n",
    "# checkpoint\n",
    "ck_monitor='val_acc'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "red_lr_patience=10\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "red_lr_min_lr=0.0\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "# es_patience=0\n",
    "es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "update_freq='epoch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks - checkpoint, reduce_lr, early_stopping, tensorboard\n",
    "init_callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/82 [==============================] - 158s 2s/step - loss: 1.0477 - mean_absolute_error: 0.5084 - acc: 0.4630 - val_loss: 0.9789 - val_mean_absolute_error: 0.5759 - val_acc: 0.3438\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 136s 2s/step - loss: 1.0020 - mean_absolute_error: 0.4828 - acc: 0.5722 - val_loss: 0.9412 - val_mean_absolute_error: 0.5676 - val_acc: 0.3406\n",
      "Epoch 3/100\n",
      "33/82 [===========>..................] - ETA: 59s - loss: 0.9766 - mean_absolute_error: 0.4741 - acc: 0.6098 "
     ]
    }
   ],
   "source": [
    "# get inception model\n",
    "init_epochs = 100\n",
    "print_layers=False\n",
    "model = get_inception_model(train_generator, validation_generator, init_epochs, init_verbose, init_optimizer, loss, metrics, tensorboard, init_callbacks, num_class, include_top, non_trainable_index, print_layers)\n",
    "main_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model Performance with Minimum Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report=True\n",
    "\n",
    "y_preds, y_classes, CM, CM_report = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "accuracy, loss =  model_evaluate(model, test_generator, print_report)\n",
    "\n",
    "show_confusion_matrix(test_generator, y_classes, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "\n",
    "epochs=100\n",
    "optimizer=optimizers.adam(lr=0.00001, decay=1e-6)\n",
    "# model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val=[['acc', 'val_acc'], ['loss', 'val_loss']]\n",
    "\n",
    "title = ['Model accuracy', 'Model loss']\n",
    "\n",
    "xlabel = ['Epoch', 'Epoch']\n",
    "ylabel = ['Accuracy', 'Loss']\n",
    "\n",
    "legend = ['Train', 'Val']\n",
    "\n",
    "fig_size=(14, 5)\n",
    "\n",
    "\n",
    "title_fontsize=17\n",
    "label_fontsize=15\n",
    "\n",
    "plot_history(history, plot_val, title, xlabel, ylabel, fig_size=fig_size, title_fontsize=title_fontsize, label_fontsize=label_fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance of All Models on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = True\n",
    "# report_type = \"Acc_Loss\"\n",
    "report_type = \"Complete\"\n",
    "\n",
    "results=test_all_models(model_dir, details, report_type, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of  Performance Over All Epochs/Models based on Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=[[1,2,3],[2,3,4]]\n",
    "\n",
    "fig_size = (10, 8)\n",
    "title=[\"Test Dataset Performance (Accuracy)\", \"Test Dataset Performance (Loss)\"]\n",
    "xlabel=[\"Epoch\", \"Epoch\"]\n",
    "ylabel=[\"Accuracy (100%)\", \"Loss\"]\n",
    "\n",
    "line_plot_over_epochs_loss_acc(array, title, fig_size=fig_size, xlabel=xlabel, ylabel=ylabel, title_fontsize=title_fontsize, label_fontsize=label_fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_callbacks(checkpoint, reduce_lr, early_stopping, tensorboard)\n",
    "# reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration for Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model and log output directory\n",
    "model_dir=output_directory+r\"models/\"\n",
    "log_dir=output_directory+r\"logs\"\n",
    "\n",
    "# make or reset directory\n",
    "# mk_reset_dir(model_dir, False)\n",
    "# mk_reset_dir(log_dir, False)\n",
    "\n",
    "model_file=model_dir+\"base-\"+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "##### Base Model - InceptionV3 (pretrained) initial training settings\n",
    "\n",
    "# inception base top layer discarded\n",
    "include_top=False\n",
    "\n",
    "# number of layers freezed\n",
    "non_trainable_index=249\n",
    "\n",
    "print_layers=False\n",
    "\n",
    "# initial epochs on only output layers\n",
    "# init_epochs=1\n",
    "# initial_epochs=3\n",
    "init_epochs=20\n",
    "\n",
    "# verbose\n",
    "init_verbose=0\n",
    "\n",
    "# callbacks\n",
    "init_callbacks=None\n",
    "\n",
    "# model report\n",
    "print_report=True\n",
    "\n",
    "\n",
    "### Full model training parameter configuration for Loss, Optimizer and Performance Metrics\n",
    "\n",
    "# optimizer\n",
    "# adam lr=0.01/0.001/0.0001/0.00001/0.000001, decay = decay=1e-5/ 1e-6\n",
    "optimizer=optimizers.Adam()\n",
    "\n",
    "\n",
    "# loss function\n",
    "# loss='binary_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "# performance metrics ('accuracy', 'binary_accuracy', precision, recall)\n",
    "metrics=['accuracy']\n",
    "\n",
    "\n",
    "### Main model training parameter configuration\n",
    "\n",
    "# epochs = 20/30/50\n",
    "epochs=30\n",
    "\n",
    "# steps\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "# verbose 0=nothing 1=each line\n",
    "verbose=0\n",
    "\n",
    "\n",
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard\n",
    "\n",
    "# checkpoint\n",
    "ck_monitor='val_acc'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "# red_lr_patience=5\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "# red_lr_min_lr=0.0001 # default\n",
    "red_lr_min_lr=0.000001\n",
    "\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "# es_patience=0\n",
    "es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "\n",
    "################################################ Retrain #########################################################\n",
    "initial_epoch=epochs+1\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard for Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Best Model\n",
    "### Selecting best model file based on validation accuracy mentioned in file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best model file / checkpoint for retraining\n",
    "# model_path = model_dir+r\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "# model_path = model_dir+r\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "# best accuracy/ F-1 score\n",
    "# model_path = \"data/output/models/\"+\"17-val_acc-0.82-val_loss-0.42.hdf5\"\n",
    "\n",
    "# Lowest validation Loss\n",
    "# model_path = \"data/output/models/\"+\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "\n",
    "# Best Recall\n",
    "# model_path = \"data/output/models/\"+\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "model_path = model_dir+r\"20-val_acc-0.71-val_loss-1.26.hdf5\"\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "# retrain by loading last good model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    # verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight,\n",
    "    initial_epoch=initial_epoch)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def extract_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    extracted_id = b[0]\n",
    "    \n",
    "    return extracted_id\n",
    "\n",
    "\n",
    "\n",
    "test_filenames = test_generator.filenames\n",
    "df_preds = pd.DataFrame(predictions, columns=classes)\n",
    "df_preds['file_names'] = test_filenames\n",
    "df_preds['id'] = df_preds['file_names'].apply(extract_id)\n",
    "df_preds.head()\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['Cancer']\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "roc_auc_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':image_id, \n",
    "                           'label':y_pred, \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('patch_preds.csv', columns=['label']) \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing Confusion Matrix of Model Performance for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), classes, fontsize=16)\n",
    "plt.yticks(range(2), classes, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing precision, recall, f1-score, support for Model Performance over Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report_print = classification_report(test_generator.classes, y_classes, target_names=target_names)\n",
    "print(classification_report_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing calcualted precision, recall for Model over Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision and Recall\n",
    "tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retriving actual labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (test_generator.class_indices)\n",
    "label_map_rev = {v: name_correct(k) for k,v in label_map.items()}\n",
    "num_batch_t = len(test_generator)\n",
    "print(label_map)\n",
    "print(label_map_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing accuracy for Model over Single Batch of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0, num_batch_t-1)\n",
    "y_img_batch, y_class_batch = test_generator[num] \n",
    "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
    "y_true = np.argmax(y_class_batch,-1)\n",
    "print(\"Selected Batch No: %d\\nBatch Size: %d\"%(num, len(y_pred)))\n",
    "print(\"Accuracy : \", sum(y_pred==y_true)/batch_size*100, \"%\")\n",
    "\n",
    "y_true_labels = [label_map_rev[c] for c in y_true]\n",
    "y_pred_labels = [label_map_rev[c] for c in y_pred]\n",
    "batch_size_t = len(y_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n",
    "Visualization of performance of a random test dataset batch and few random images from a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/result\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "\n",
    "cols = 8\n",
    "rows= batch_size_t/cols\n",
    "if batch_size_t%cols==0:\n",
    "    rows = int(batch_size_t/cols)\n",
    "else:\n",
    "    rows = int(batch_size_t/cols)+1\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org : \"\n",
    "pred_label_title_prefix = \"pred: \"\n",
    "\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "for i in range(0, batch_size_t): # how many imgs will show from the mxn grid\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[i])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[i]==y_pred_labels[i]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i], color=false_prediction_label_color)\n",
    "        \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)\n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/sample\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "cols = 4\n",
    "rows= 2\n",
    "\n",
    "count = rows*cols\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "# titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org:  \"\n",
    "pred_label_title_prefix = \"pred: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "\n",
    "batch_size_tmp = batch_size_t\n",
    "\n",
    "m = {}\n",
    "\n",
    "for i in range(0, count): \n",
    "    num = random.randint(0, batch_size_tmp-1)\n",
    "    while num in m:\n",
    "        num = random.randint(0, batch_size_tmp-1)\n",
    "    \n",
    "    m[num]=1\n",
    "    \n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[num])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[num]==y_pred_labels[num]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num], color=false_prediction_label_color)\n",
    "    \n",
    "   \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)   \n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
