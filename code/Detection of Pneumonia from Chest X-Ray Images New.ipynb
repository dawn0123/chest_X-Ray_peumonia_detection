{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "<pre>\n",
    "Author           : Anjana Tiha\n",
    "Project Name     : Detection of Pneumonia from Chest X-Ray Images using Convolutional Neural Network, \n",
    "                   and Transfer Learning.\n",
    "Description      : 1. Detected Pneumonia from Chest X-Ray images by retraining pretrained model “InceptionV3” \n",
    "                      with 5856 images of X-ray (1.15GB).\n",
    "                   2. For retraining removed output layers, freezed first few layers and Fine-tuned model for \n",
    "                      two new label classes (Pneumonia and Normal).\n",
    "                   3. Attained testing accuracy 83.44% and loss 0.42.\n",
    "Method           : \n",
    "Tools/Library    : Python, Keras, PyTorch, TensorFlow\n",
    "Version History  : 1.0.0.0\n",
    "Current Version  : 1.0.0.0\n",
    "Last Update      : 11.24.2018\n",
    "Comments         : Please use Anaconda editor for convenience.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "<pre>\n",
    "GitHub Link      : <a href=https://github.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitHub)</a>\n",
    "GitLab Link      : <a href=https://gitlab.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitLab)</a>\n",
    "Portfolio        : <a href=https://anjanatiha.wixsite.com/website>Anjana Tiha's Portfolio</a>\n",
    "</pre>\n",
    "\n",
    "#### Dataset\n",
    "<pre>\n",
    "Dataset Name     : Chest X-Ray Images (Pneumonia)\n",
    "Dataset Link     : <a href=https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia>Chest X-Ray Images (Pneumonia) Dataset (Kaggle)</a>\n",
    "                 : <a href=https://data.mendeley.com/datasets/rscbjbr9sj/2>Chest X-Ray Images (Pneumonia) Dataset (Original Dataset)</a>\n",
    "Original Paper   : <a href=https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5>Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning</a>\n",
    "                   (Daniel S. Kermany, Michael Goldbaum, Wenjia Cai, M. Anthony Lewis, Huimin Xia, Kang Zhang)\n",
    "                   https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library/Tools Version\n",
    "- Python - v3.6.7\n",
    "- argparse\n",
    "- random\n",
    "- numpy\n",
    "- shutil\n",
    "- gc\n",
    "- re\n",
    "- Keras - 2.2.4\n",
    "- Keras-preprocessing - v1.0.5\n",
    "- TensorFlow - 1.12\n",
    "- PIL/Pillow - 5.1.0\n",
    "- Matplotlib - 2.2.2\n",
    "- scikit-learn - 0.19.1\n",
    "- mlxtend - 0.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands / Running Instruction\n",
    "<pre>\n",
    "tensorboard --logdir=logs\n",
    "%config IPCompleter.greedy=True\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>Dataset Details</b>\n",
    "Dataset Name            : Chest X-Ray Images (Pneumonia)\n",
    "Number of Class         : 2\n",
    "Number/Size of Images   : Total      : 5856 (1.15 Gigabyte (GB))\n",
    "                          Training   : 5216 (1.07 Gigabyte (GB))\n",
    "                          Validation : 320  (42.8 Megabyte (MB))\n",
    "                          Testing    : 320  (35.4 Megabyte (MB))\n",
    "\n",
    "<b>Model Parameters</b>\n",
    "Machine Learning Library: Keras\n",
    "Base Model              : InceptionV3\n",
    "Optimizers              : Adam\n",
    "Loss Function           : categorical_crossentropy\n",
    "\n",
    "<b>Training Parameters</b>\n",
    "Batch Size              : 64\n",
    "Number of Epochs        : 50\n",
    "Training Time           : 3 Hours\n",
    "\n",
    "<b>Output (Prediction/ Recognition / Classification Metrics)</b>\n",
    "<!--<b>Validation</b>-->\n",
    "<b>Testing</b>\n",
    "Accuracy                : 83.44%\n",
    "Loss                    : 0.42\n",
    "<!--Precision               : -->\n",
    "Recall                  : 94% (highest)\n",
    "<!--Specificity             : -->\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import inspect\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "tf.reset_default_graph()\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions:\n",
    "<pre>\n",
    "Resetting model and log directory\n",
    "class name cleansing\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Make or reset directory\n",
    "def mk_reset_dir(directory, remove=False):\n",
    "    if remove and os.path.exists(directory):\n",
    "        try:\n",
    "            shutil.rmtree(directory)\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "def date_time(x):\n",
    "    if x==1:\n",
    "        print('Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==2:    \n",
    "        print('Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==3:  \n",
    "        print('Date now: %s' % datetime.datetime.now())\n",
    "    if x==4:  \n",
    "        print('Date today: %s' % datetime.date.today())\n",
    "        \n",
    "def debug(x):\n",
    "    print(\"-\"*40, x, \"-\"*40)    \n",
    "\n",
    "# Remove everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def count_bar(master_directory):\n",
    "    dir_list = os.listdir(master_directory)\n",
    "    num_class = len(dir_list)\n",
    "\n",
    "    dir_name = []\n",
    "    dir_file_count = []\n",
    "\n",
    "    for directory in dir_list:\n",
    "        cur_dir = os.path.join(master_directory, directory)\n",
    "        count_sample = len(os.listdir(cur_dir))\n",
    "        dir_name.append(directory)\n",
    "        dir_file_count.append(count_sample)\n",
    "    \n",
    "    return dir_name, dir_file_count\n",
    "               \n",
    "\n",
    "def bar_plot(x, y, title, xlabel, ylabel, title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x=x, y= y)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)                          \n",
    "    max_val = float(max(counter.values()))     \n",
    "    class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Input/ Output Directory\n",
    "<pre>\n",
    "Data             : training, validation, testing\n",
    "Model and output : model directory and logs directory\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input/ output directory\n",
    "# Configure training, validation, testing directory\n",
    "\n",
    "input_directory = r\"data/input/\"\n",
    "output_directory = r\"data/output/\"\n",
    "\n",
    "training_dir = input_directory+ r\"train\"\n",
    "testing_dir = input_directory+ r\"test\"\n",
    "validation_dir = input_directory+ r\"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xlabel=\"Count\"\n",
    "ylabel=\"CaseType\"\n",
    "title_fontsize=14\n",
    "label_fontsize=12\n",
    "\n",
    "master_directory = training_dir\n",
    "dir_name, dir_file_count = count_bar(master_directory)\n",
    "x=dir_name\n",
    "y=dir_file_count\n",
    "title=\"Number of Cases\"\n",
    "bar_plot(x, y, title, xlabel, ylabel, title_fontsize, label_fontsize)\n",
    "\n",
    "\n",
    "master_directory = validation_dir\n",
    "dir_name, dir_file_count = count_bar(master_directory)\n",
    "x=dir_name\n",
    "y=dir_file_count\n",
    "title=\"Number of Cases (Validation)\"\n",
    "bar_plot(x, y, title, xlabel, ylabel, title_fontsize, label_fontsize)\n",
    "\n",
    "master_directory = testing_dir\n",
    "dir_name, dir_file_count = count_bar(master_directory)\n",
    "x=dir_name\n",
    "y=dir_file_count\n",
    "title=\"Number of Cases (Testing)\"\n",
    "bar_plot(x, y, title, xlabel, ylabel, title_fontsize, label_fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (Image Preprocessing)\n",
    "#### Setting up Parameters for Image Transformation of Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get number of label/ class / category\n",
    "num_class = len(os.listdir(training_dir))\n",
    "print(num_class)\n",
    "\n",
    "# Configure image preprocessing parameters for generating batches of tensor image data from train, test, validation datasets\n",
    "# with real-time data augmentation. The data will be looped over (in batches).\n",
    "norm = 255.0\n",
    "rescale=1./norm\n",
    "shear_range=0.2\n",
    "zoom_range=0.2\n",
    "horizontal_flip=True\n",
    "\n",
    "# Image dimention and Batch size \n",
    "target_size=(224, 224)\n",
    "batch_size=32\n",
    "# batch_size=64\n",
    "\n",
    "test_batch_size=1\n",
    "\n",
    "# Data label class\n",
    "class_mode='categorical'\n",
    "# class_mode='binary'\n",
    "# class_mode='sparse'\n",
    "\n",
    "# classes = ['Cancer', 'Normal']\n",
    "classes = ['Normal', 'PNEUMONIA']\n",
    "\n",
    "# iaa.Multiply((1.2, 1.5))]) #random brightness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (Image Preprocessing)\n",
    "#### Transformation Image Dataset for Training, Validation, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches)\n",
    "# Generate batches of tensor image data with real-time data augmentation from training dataset\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=rescale,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        training_dir,\n",
    "        target_size=target_size,\n",
    "        classes = classes,\n",
    "        class_mode=class_mode,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "# Generate batches of tensor image data with real-time data augmentation from validation dataset\n",
    "validation_datagen = ImageDataGenerator(rescale=rescale)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=target_size,\n",
    "        classes = classes,\n",
    "        class_mode=class_mode,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "# Generate batches of tensor image data with real-time data augmentation from testing dataset\n",
    "test_datagen = ImageDataGenerator(rescale=rescale)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        testing_dir,\n",
    "        target_size=target_size,\n",
    "        classes = classes,\n",
    "        class_mode=class_mode,\n",
    "#         batch_size=batch_size,\n",
    "        batch_size=test_batch_size,\n",
    "        shuffle=False) ## false added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.889634601043997, 1: 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=train_generator.classes\n",
    "class_weight=get_class_weights(y)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "<p>1. Imports Pretrained model InceptionV3 <br>\n",
    "   2. Disabled training on first few layers <br>\n",
    "   3. Enabled training on top and output layers<br>\n",
    "   4. Adjust output Dense Layer to number of Image Classes <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "def get_inception_model(train_generator, validation_generator, epochs, verbose, sgd, loss, metrics, tensorboard, callbacks, num_class, include_top=False, non_trainable_index=249, print_layers = False):    \n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=include_top)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    # Setting model layers specially output layer with class number\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 2 classes\n",
    "\n",
    "    # softmax for multi-class\n",
    "    predictions = Dense(num_class, activation='softmax')(x) \n",
    "    \n",
    "    # sigmoid for 2 class or binary class\n",
    "    # predictions = Dense(num_class, activation='sigmoid')(x) \n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "     \n",
    "    # compile model with loss, optimizer and metrics \n",
    "    model.compile(sgd, loss=loss, metrics=metrics)\n",
    "    \n",
    "    if callbacks:\n",
    "        tensorboard.set_model(model) \n",
    "    \n",
    "    # train the model on the new data for a few epochs\n",
    "    model.fit_generator(train_generator,\n",
    "                        steps_per_epoch = len(train_generator),\n",
    "                        epochs=epochs,\n",
    "                        # verbose=verbose, \n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=len(validation_generator),\n",
    "                        class_weight = class_weight)\n",
    "\n",
    "    # at this point, the top layers are well trained and we can start fine-tuning\n",
    "    # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "    # and train the remaining top layers.\n",
    "\n",
    "    # let's visualize layer names and layer indices to see how many layers\n",
    "    # we should freeze:\n",
    "    if print_layers:\n",
    "        for i, layer in enumerate(base_model.layers):\n",
    "            print(i, layer.name)\n",
    "\n",
    "    # Freeze or set first few layers as untrainable\n",
    "    # Unfreeze or set rest of the layers as trainable\n",
    "    for layer in model.layers[:non_trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[non_trainable_index:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Base Model Import and Initial Training\n",
    "##### Base Model - InceptionV3 (pretrained) import and initial training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception base top layer discarded\n",
    "include_top = False\n",
    "\n",
    "# number of layers freezed\n",
    "non_trainable_index = 249\n",
    "\n",
    "print_layers=False\n",
    "\n",
    "init_epochs=1\n",
    "# initial_epochs=3\n",
    "# initial_epochs=5\n",
    "init_verbose = 0\n",
    "init_callbacks = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Import and Parameter Setting For Main Training\n",
    "#### Configuration of Loss, Optimizer and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer\n",
    "# sgd = optimizers.Adam()\n",
    "# sgd = optimizers.Adam(lr=0.001)\n",
    "\n",
    "## works best\n",
    "sgd = optimizers.Adam(lr=0.0001)\n",
    "# sgd = optimizers.Adam(lr=0.0001, decay=1e-5)\n",
    "\n",
    "# sgd = optimizers.SGD()\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# sgd = optimizer=SGD(lr=0.0001, momentum=0.9)\n",
    "\n",
    "# set loss function\n",
    "loss='categorical_crossentropy'\n",
    "# loss='binary_crossentropy'\n",
    "\n",
    "# set performance metrics\n",
    "metrics=['accuracy']\n",
    "# metrics=['accuracy', 'binary_accuracy', precision, recall]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Import and Parameter Setting For Main Training\n",
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 50\n",
    "epochs = 20\n",
    "\n",
    "steps_per_epoch=len(train_generator)\n",
    "verbose = 0\n",
    "validation_steps=len(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Import and Parameter Setting For Main Training\n",
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "# setting model and log output directory\n",
    "model_dir =  output_directory + r\"models/\"\n",
    "log_dir = output_directory + r\"logs\"\n",
    "\n",
    "# make or reset directory\n",
    "# mk_reset_dir(model_dir, False)\n",
    "# mk_reset_dir(log_dir, False)\n",
    "\n",
    "model_file = model_dir+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "# checkpoint\n",
    "ck_monitor='val_acc'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "# red_lr_patience=5\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "# red_lr_min_lr=0.0001 # default\n",
    "red_lr_min_lr=0.00001\n",
    "\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "es_patience=0\n",
    "# es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Import and Parameter Setting For Main Training\n",
    "#### Setup Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Import and Parameter Compilation For Main Training\n",
    "### Model Import and compiling with loss, optimizer and performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "163/163 [==============================] - 159s 975ms/step - loss: 0.5522 - acc: 0.8286 - val_loss: 0.5551 - val_acc: 0.7594\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2050        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,788,130\n",
      "Trainable params: 2,100,226\n",
      "Non-trainable params: 10,687,904\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "# get inception model\n",
    "model = get_inception_model(train_generator, validation_generator, init_epochs, init_verbose, sgd, loss, metrics, tensorboard, init_callbacks, num_class, include_top, non_trainable_index, print_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Training\n",
    "#### Starts training with given parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "163/163 [==============================] - 168s 1s/step - loss: 0.3146 - acc: 0.9183 - val_loss: 1.6825 - val_acc: 0.7312\n",
      "Epoch 2/20\n",
      "163/163 [==============================] - 152s 934ms/step - loss: 0.1868 - acc: 0.9502 - val_loss: 2.5892 - val_acc: 0.6344\n",
      "Epoch 3/20\n",
      "163/163 [==============================] - 137s 840ms/step - loss: 0.1496 - acc: 0.9555 - val_loss: 1.0939 - val_acc: 0.7188\n",
      "Epoch 4/20\n",
      "163/163 [==============================] - 131s 805ms/step - loss: 0.1490 - acc: 0.9595 - val_loss: 1.4468 - val_acc: 0.7000\n",
      "Epoch 5/20\n",
      "163/163 [==============================] - 130s 799ms/step - loss: 0.1333 - acc: 0.9651 - val_loss: 2.2743 - val_acc: 0.6406\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 6/20\n",
      "163/163 [==============================] - 134s 825ms/step - loss: 0.1078 - acc: 0.9666 - val_loss: 1.8118 - val_acc: 0.6531\n",
      "Epoch 7/20\n",
      "163/163 [==============================] - 129s 790ms/step - loss: 0.1022 - acc: 0.9739 - val_loss: 1.6911 - val_acc: 0.6656\n",
      "Epoch 8/20\n",
      "163/163 [==============================] - 128s 787ms/step - loss: 0.0947 - acc: 0.9739 - val_loss: 1.3218 - val_acc: 0.7063\n",
      "Epoch 9/20\n",
      " 99/163 [=================>............] - ETA: 48s - loss: 0.0975 - acc: 0.9719"
     ]
    }
   ],
   "source": [
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "model.compile(sgd, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "#     verbose=verbose,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Main Model Import and Validation Performance Visualization\n",
    "#### Plotting Training and Validation Performance over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining \n",
    "#### Retraining Best Model\n",
    "###### Selecting Best Model File and Parameters for Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best model file / checkpoint for retraining\n",
    "model_path = model_dir+r\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "model_path = model_dir+r\"20-val_acc-0.66-val_loss-1.97.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining \n",
    "#### Retraining Best Model\n",
    "###### Loading Best Model for Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining \n",
    "#### Retraining Best Model\n",
    "#### Configuration for Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=32\n",
    "# # batch_size=64\n",
    "# class_mode='categorical'\n",
    "# # class_mode='binary'\n",
    "\n",
    "# loss='categorical_crossentropy'\n",
    "# # loss='binary_crossentropy'\n",
    "\n",
    "# # metrics=['accuracy', 'binary_accuracy', precision, recall]\n",
    "# metrics=['accuracy']\n",
    "\n",
    "epochs = 50\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retrain the selected best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain by loading last good model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_pos_neg(CM, print_bool):\n",
    "    tp=CM[0][0]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    tn=CM[1][1]\n",
    "    if print_bool:\n",
    "        print(tp, fp, tn, fn, tn)\n",
    "    return [tp, fp, tn, fn, tn]\n",
    "\n",
    "\n",
    "def report(CM, reverse):\n",
    "    if not reverse:\n",
    "        tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "    else:\n",
    "        tp=CM[0][0]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        tn=CM[1][1]\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "    print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "#### Testing all saved models\n",
    "##### Testing all models saved on each epochs to search for the best model based on test dataset image recognition performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model\n",
    "\n",
    "details = False\n",
    "best_accuracy = 0\n",
    "best_loss = 0\n",
    "\n",
    "lowest_accuracy = 100\n",
    "lowest_loss = 1000000\n",
    "\n",
    "models_path = \"data\\\\output\\\\models\\\\\"\n",
    "\n",
    "best_model_acc = \"\"\n",
    "best_model_loss = \"\"\n",
    "\n",
    "models_arr = []\n",
    "accuracy_arr = []\n",
    "loss_arr = []\n",
    "\n",
    "model_files = os.listdir(models_path)\n",
    "\n",
    "i=0\n",
    "for model_file in model_files:\n",
    "    model_path = models_path+\"\\\\\"+model_file\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        pass\n",
    "    tf.reset_default_graph()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    model = keras.models.load_model(model_path)\n",
    "    \n",
    "    result = model.evaluate_generator(generator=test_generator, steps=len(test_generator))\n",
    "    \n",
    "    accuracy = result[1]*100\n",
    "    loss = result[0]\n",
    "    \n",
    "    accuracy_arr.append(accuracy)\n",
    "    loss_arr.append(loss)\n",
    "    models_arr.append(model_path)\n",
    "    \n",
    "    if accuracy>best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_loss = loss\n",
    "        best_model_acc=model_path\n",
    "        \n",
    "    if loss<lowest_loss:\n",
    "        lowest_accuracy = accuracy\n",
    "        lowest_loss = loss\n",
    "        best_model_loss=model_path\n",
    "        \n",
    "    if details:\n",
    "        print(\"%s%s\"%(\"Model No: \", i))\n",
    "        print(\"%s%s\"%(\"Model File Path: \", model_file))\n",
    "        print(\"*\"*80)\n",
    "        print(\"%s%.2f%s\"% (\"Current Accuracy: \", accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Current Loss: \", loss))\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        print(\"%s%.2f%s\"% (\"Best Test Accuracy (Accuracy wise):\", best_accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Best Test Loss (Accuracy wise): \", best_loss))\n",
    "\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        print(\"%s%.2f%s\"% (\"Best Test Accuracy (Loss wise): \", lowest_accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Best Test Loss (Loss wise): \", lowest_loss))\n",
    "\n",
    "    elif i%10==0:\n",
    "        print(\"%s%s\"%(\"Model No: \", i))\n",
    "        print(\"%s%s\"%(\"Model File Path: \", model_file))\n",
    "        print(\"*\"*80)\n",
    "        \n",
    "        print(\"%s%.2f%s\"% (\"Best Test Accuracy: \", best_accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Best Test Loss: \", best_loss))\n",
    "\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        print(\"%s%.2f%s\"% (\"Best Test Accuracy (Loss wise): \", lowest_accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Best Test Loss (Loss wise): \", lowest_loss))\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model  2\n",
    "\n",
    "target_names = ['Cancer', 'Normal']\n",
    "CM_list = []\n",
    "    \n",
    "details = True\n",
    "best_accuracy = 0\n",
    "best_loss = 0\n",
    "\n",
    "lowest_accuracy = 100\n",
    "lowest_loss = 1000000\n",
    "\n",
    "models_path = \"data\\\\output\\\\models\\\\\"\n",
    "\n",
    "best_model_acc = \"\"\n",
    "best_model_loss = \"\"\n",
    "\n",
    "models_arr = []\n",
    "accuracy_arr = []\n",
    "loss_arr = []\n",
    "\n",
    "model_files = os.listdir(models_path)\n",
    "\n",
    "i=0\n",
    "\n",
    "for model_file in model_files:\n",
    "    model_path = models_path+\"\\\\\"+model_file\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        pass\n",
    "    tf.reset_default_graph()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "    preds = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "    y_classes = preds.argmax(axis=-1)\n",
    "\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    CM_report = classification_report(test_generator.classes, y_classes, target_names=target_names)\n",
    "    \n",
    "    models_arr.append(model_path)\n",
    "    CM_list.append({model_file: CM})\n",
    "        \n",
    "    if details:\n",
    "        print(\"%s%s\"%(\"Model No: \", i))\n",
    "        print(\"%s%s\"%(\"Model File Path: \", model_file))\n",
    "        print(\"*\"*80)\n",
    "        print(CM_report)\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print(\"-\"*80)\n",
    "\n",
    "    elif i%10==0:\n",
    "        print(\"%s%s\"%(\"Model No: \", i))\n",
    "        print(\"%s%s\"%(\"Model File Path: \", model_file))\n",
    "        print(\"*\"*80)\n",
    "        print(CM_report)\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print(\"-\"*80)\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing best model accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*17,\"Summary of Model Performance on Test Dataset\", \"-\"*17)\n",
    "\n",
    "print(\"%s%s\"% (\"Best Model Path (Accuracy): \", best_model_acc))\n",
    "print(\"%s%.2f%s\"% (\"Best Test Accuracy: \", best_accuracy, \"%\"))\n",
    "print(\"%s%.2f\"% (\"Best Test Loss: \", best_loss))\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"%s%s\"% (\"Best Model Path (Loss): \", best_model_loss))\n",
    "print(\"%s%.2f%s\"% (\"Best Test Accuracy: \", lowest_accuracy, \"%\"))\n",
    "print(\"%s%.2f\"% (\"Best Test Loss: \", lowest_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting all model performance over all epochs and models for accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_arr = np.arange(len(accuracy_arr))\n",
    "plt.title(\"Test Dataset Performance (Accuracy)\")\n",
    "plt.plot(x_axis_arr, accuracy_arr)\n",
    "plt.xlabel(\"Iteration Number\")\n",
    "plt.ylabel(\"Accuracy (100%)\")\n",
    "plt.show()\n",
    "\n",
    "x_axis_arr = np.arange(len(loss_arr))\n",
    "plt.title(\"Test Dataset Performance (Loss)\")\n",
    "plt.plot(x_axis_arr, loss_arr)\n",
    "plt.xlabel(\"Iteration Number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting Best Model for full evaluation (for accuracy/f1 score or recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best accuracy/ F-1 score\n",
    "# model_path = \"data/output/models/\"+\"17-val_acc-0.82-val_loss-0.42.hdf5\"\n",
    "\n",
    "# Lowest validation Loss\n",
    "# model_path = \"data/output/models/\"+\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "\n",
    "# Best Recall\n",
    "model_path = \"data/output/models/\"+\"20-val_acc-0.66-val_loss-1.97.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Best Model for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model\n",
    "model = keras.models.load_model(model_path)\n",
    "result = model.evaluate_generator(generator=test_generator, steps=len(test_generator), verbose=1)\n",
    "print(\"-\"*17,\"Summary of Best Model Performance on Test Dataset\", \"-\"*17)\n",
    "print(\"%s%.2f%s\"% (\"Test Accuracy: \", result[1]*100, \"%\"))\n",
    "print(\"%s%.2f\"% (\"Test Loss: \", result[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting Best Model for further analysis, evaluation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model\n",
    "model = keras.models.load_model(model_path)\n",
    "preds = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "y_classes = preds.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def extract_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    extracted_id = b[0]\n",
    "    \n",
    "    return extracted_id\n",
    "\n",
    "\n",
    "\n",
    "test_filenames = test_generator.filenames\n",
    "df_preds = pd.DataFrame(predictions, columns=classes)\n",
    "df_preds['file_names'] = test_filenames\n",
    "df_preds['id'] = df_preds['file_names'].apply(extract_id)\n",
    "df_preds.head()\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['Cancer']\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "roc_auc_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':image_id, \n",
    "                           'label':y_pred, \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('patch_preds.csv', columns=['label']) \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing Confusion Matrix of Model Performance for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Cancer', 'Normal']\n",
    "\n",
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), target_names, fontsize=16)\n",
    "plt.yticks(range(2), target_names, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing precision, recall, f1-score, support for Model Performance over Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report_print = classification_report(test_generator.classes, y_classes, target_names=target_names)\n",
    "print(classification_report_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing calcualted precision, recall for Model over Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision and Recall\n",
    "tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retriving actual labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (test_generator.class_indices)\n",
    "label_map_rev = {v: name_correct(k) for k,v in label_map.items()}\n",
    "num_batch_t = len(test_generator)\n",
    "print(label_map)\n",
    "print(label_map_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing accuracy for Model over Single Batch of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0, num_batch_t-1)\n",
    "y_img_batch, y_class_batch = test_generator[num] \n",
    "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
    "y_true = np.argmax(y_class_batch,-1)\n",
    "print(\"Selected Batch No: %d\\nBatch Size: %d\"%(num, len(y_pred)))\n",
    "print(\"Accuracy : \", sum(y_pred==y_true)/batch_size*100, \"%\")\n",
    "\n",
    "y_true_labels = [label_map_rev[c] for c in y_true]\n",
    "y_pred_labels = [label_map_rev[c] for c in y_pred]\n",
    "batch_size_t = len(y_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n",
    "Visualization of performance of a random test dataset batch and few random images from a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/result\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "\n",
    "cols = 8\n",
    "rows= batch_size_t/cols\n",
    "if batch_size_t%cols==0:\n",
    "    rows = int(batch_size_t/cols)\n",
    "else:\n",
    "    rows = int(batch_size_t/cols)+1\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org : \"\n",
    "pred_label_title_prefix = \"pred: \"\n",
    "\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "for i in range(0, batch_size_t): # how many imgs will show from the mxn grid\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[i])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[i]==y_pred_labels[i]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i], color=false_prediction_label_color)\n",
    "        \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)\n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/sample\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "cols = 4\n",
    "rows= 2\n",
    "\n",
    "count = rows*cols\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "# titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org:  \"\n",
    "pred_label_title_prefix = \"pred: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "\n",
    "batch_size_tmp = batch_size_t\n",
    "\n",
    "m = {}\n",
    "\n",
    "for i in range(0, count): \n",
    "    num = random.randint(0, batch_size_tmp-1)\n",
    "    while num in m:\n",
    "        num = random.randint(0, batch_size_tmp-1)\n",
    "    \n",
    "    m[num]=1\n",
    "    \n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[num])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[num]==y_pred_labels[num]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num], color=false_prediction_label_color)\n",
    "    \n",
    "   \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)   \n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
