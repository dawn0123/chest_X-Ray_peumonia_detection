{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "<pre>\n",
    "Author           : Anjana Tiha\n",
    "Project Name     : Detection of Pneumonia from Chest X-Ray Images using Convolutional Neural Network, \n",
    "                   and Transfer Learning.\n",
    "Description      : 1. Detected Pneumonia from Chest X-Ray images by retraining pretrained model “InceptionV3” \n",
    "                      with 5856 images of X-ray (1.15GB).\n",
    "                   2. For retraining removed output layers, freezed first few layers and Fine-tuned model for \n",
    "                      two new label classes (Pneumonia and Normal).\n",
    "                   3. Attained testing accuracy 83.44% and loss 0.42.\n",
    "Method           : \n",
    "Tools/Library    : Python, Keras, PyTorch, TensorFlow\n",
    "Version History  : 1.0.0.0\n",
    "Current Version  : 1.0.0.0\n",
    "Last Update      : 11.30.2018\n",
    "Comments         : Please use Anaconda editor for convenience of visualization.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "<pre>\n",
    "GitHub Link      : <a href=https://github.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitHub)</a>\n",
    "GitLab Link      : <a href=https://gitlab.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitLab)</a>\n",
    "Portfolio        : <a href=https://anjanatiha.wixsite.com/website>Anjana Tiha's Portfolio</a>\n",
    "</pre>\n",
    "\n",
    "#### Dataset\n",
    "<pre>\n",
    "Dataset Name     : Chest X-Ray Images (Pneumonia)\n",
    "Dataset Link     : <a href=https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia>Chest X-Ray Images (Pneumonia) Dataset (Kaggle)</a>\n",
    "                 : <a href=https://data.mendeley.com/datasets/rscbjbr9sj/2>Chest X-Ray Images (Pneumonia) Dataset (Original Dataset)</a>\n",
    "Original Paper   : <a href=https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5>Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning</a>\n",
    "                   (Daniel S. Kermany, Michael Goldbaum, Wenjia Cai, M. Anthony Lewis, Huimin Xia, Kang Zhang)\n",
    "                   https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library/Tools Version\n",
    "- Python - v3.6.7\n",
    "- argparse\n",
    "- random\n",
    "- numpy\n",
    "- shutil\n",
    "- gc\n",
    "- re\n",
    "- Keras - 2.2.4\n",
    "- Keras-preprocessing - v1.0.5\n",
    "- TensorFlow - 1.12\n",
    "- PIL/Pillow - 5.1.0\n",
    "- Matplotlib - 2.2.2\n",
    "- scikit-learn - 0.19.1\n",
    "- mlxtend - 0.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands / Running Instruction\n",
    "<pre>\n",
    "tensorboard --logdir=logs\n",
    "%config IPCompleter.greedy=True\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>Dataset Details</b>\n",
    "Dataset Name            : Chest X-Ray Images (Pneumonia)\n",
    "Number of Class         : 2\n",
    "Number/Size of Images   : Total      : 5856 (1.15 Gigabyte (GB))\n",
    "                          Training   : 5216 (1.07 Gigabyte (GB))\n",
    "                          Validation : 320  (42.8 Megabyte (MB))\n",
    "                          Testing    : 320  (35.4 Megabyte (MB))\n",
    "\n",
    "<b>Model Parameters</b>\n",
    "Machine Learning Library: Keras\n",
    "Base Model              : InceptionV3\n",
    "Optimizers              : Adam\n",
    "Loss Function           : categorical_crossentropy\n",
    "\n",
    "<b>Training Parameters</b>\n",
    "Batch Size              : 64\n",
    "Number of Epochs        : 50\n",
    "Training Time           : 3 Hours\n",
    "\n",
    "<b>Output (Prediction/ Recognition / Classification Metrics)</b>\n",
    "<!--<b>Validation</b>-->\n",
    "<b>Testing</b>\n",
    "Accuracy                : 83.44%\n",
    "Loss                    : 0.42\n",
    "<!--Precision               : -->\n",
    "Recall                  : 94% (highest)\n",
    "<!--Specificity             : -->\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import inspect\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes directory, if directory exists removes if remove parameter is set to True \n",
    "def mk_reset_dir(directory, remove=False):\n",
    "    if remove and os.path.exists(directory):\n",
    "        try:\n",
    "            shutil.rmtree(directory)\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory)\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print time with date, month, year and hour, minute, second in format given by parameter\n",
    "def date_time(x):\n",
    "    if x==1:\n",
    "        print('Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==2:    \n",
    "        print('Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==3:  \n",
    "        print('Date now: %s' % datetime.datetime.now())\n",
    "    if x==4:  \n",
    "        print('Date today: %s' % datetime.date.today())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints a integer for degugging\n",
    "def debug(x):\n",
    "    print(\"-\"*40, x, \"-\"*40)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of files in each subdirectory of a directory\n",
    "def count_bar(master_directory):\n",
    "    dir_list = os.listdir(master_directory)\n",
    "    num_class = len(dir_list)\n",
    "\n",
    "    dir_name = []\n",
    "    dir_file_count = []\n",
    "\n",
    "    for directory in dir_list:\n",
    "        cur_dir = os.path.join(master_directory, directory)\n",
    "        count_sample = len(os.listdir(cur_dir))\n",
    "        dir_name.append(directory)\n",
    "        dir_file_count.append(count_sample)\n",
    "    \n",
    "    return dir_name, dir_file_count\n",
    "               \n",
    "\n",
    "# show barplot\n",
    "def bar_plot(x, y, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    sns.barplot(x=x, y=y)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    \n",
    "\n",
    "# show bar plot for count of labels in subdirectory of a directory\n",
    "def count_bar_plot(master_directory, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12, subplot_no=0):\n",
    "    dir_name, dir_file_count = count_bar(master_directory)\n",
    "    x=dir_name\n",
    "    y=dir_file_count\n",
    "    bar_plot(x, y, title, xlabel, ylabel, figsize=fig_size, title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=subplot_no)\n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a training, validation, testing directory    \n",
    "def show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    count_bar_plot(training_dir, title +\" (Training)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=131)\n",
    "    count_bar_plot(validation_dir, title +\" (Validation)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=132)\n",
    "    count_bar_plot(testing_dir, title +\" (Testing)\", xlabel, ylabel, fig_size, title_fontsize, label_fontsize, subplot_no=133)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches)\n",
    "def get_transformed_image_batch(directory, target_size, classes, class_mode='categorical', batch_size=1, shuffle=True, rescale=None, shear_range=0.0, zoom_range=0.0, horizontal_flip=False, validation_split=0.0):       \n",
    "    datagen = ImageDataGenerator(\n",
    "            rescale=rescale,\n",
    "            shear_range=shear_range,\n",
    "            zoom_range=zoom_range,\n",
    "            horizontal_flip=horizontal_flip,\n",
    "            validation_split=validation_split)     \n",
    "    \n",
    "    image_generator = datagen.flow_from_directory(\n",
    "            directory,\n",
    "            target_size=target_size,\n",
    "            classes = classes,\n",
    "            class_mode=class_mode,\n",
    "            batch_size=batch_size)\n",
    "    return image_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Label Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust class weights for imbalanced dataset of classes of images\n",
    "def get_class_weight(y):\n",
    "    counter = Counter(y)                          \n",
    "    max_val = float(max(counter.values()))     \n",
    "    class_weight = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Graph Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tensorflow graph tp free up memory and resource allocation \n",
    "def reset_graph(model=None):\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        return False\n",
    "    tf.reset_default_graph()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    return True\n",
    "\n",
    "# reset callbacks \n",
    "def reset_callbacks(checkpoint=None, reduce_lr=None, early_stopping=None, tensorboard=None):\n",
    "    checkpoint=None\n",
    "    reduce_lr = None\n",
    "    early_stopping = None\n",
    "    tensorboard = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish_activation(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "def basic_model(optimizer, loss, metrics, input_shape=(3,150,150), activation='relu', activation2='sigmoid', padding=\"same\", padding2=\"valid\", pool_size=(2, 2), dilation_rate=(2, 2))\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=activation, padding=padding, input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, padding=padding))\n",
    "    model.add(Conv2D(64, (3, 3), padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(96, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(96, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), dilation_rate=dilation_rate, activation=activation, padding=padding))\n",
    "    model.add(Conv2D(128, (3, 3), padding2=padding2, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation=swish_activation))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2 , activation=activation2))\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=metrics)\n",
    "\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization Function\n",
    "#### Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "<p>1. Imports Pretrained model InceptionV3 <br>\n",
    "   2. Disabled training on first few layers <br>\n",
    "   3. Enabled training on top and output layers<br>\n",
    "   4. Adjust output Dense Layer to number of Image Classes <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and configure model InceptionV3 for fine-tuning with new class labels\n",
    "def get_inception_model(train_generator, validation_generator, epochs, verbose, optimizer, loss, metrics, tensorboard, callbacks, num_class, include_top=False, non_trainable_index=249, print_layers = False):    \n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=include_top)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    # Setting model layers specially output layer with class number\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 2 classes\n",
    "\n",
    "    # softmax for multi-class\n",
    "    predictions = Dense(num_class, activation='softmax')(x) \n",
    "    \n",
    "    # sigmoid for 2 class or binary class\n",
    "    # predictions = Dense(num_class, activation='sigmoid')(x) \n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "     \n",
    "    # compile model with loss, optimizer and metrics \n",
    "    model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    \n",
    "    if callbacks:\n",
    "        tensorboard.set_model(model) \n",
    "    \n",
    "    # train the model on the new data for a few epochs\n",
    "    model.fit_generator(train_generator,\n",
    "                        steps_per_epoch = len(train_generator),\n",
    "                        epochs=epochs,\n",
    "                        # verbose=verbose, \n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=len(validation_generator),\n",
    "                        class_weight = class_weight)\n",
    "\n",
    "    # at this point, the top layers are well trained and we can start fine-tuning\n",
    "    # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "    # and train the remaining top layers.\n",
    "\n",
    "    # let's visualize layer names and layer indices to see how many layers\n",
    "    # we should freeze:\n",
    "    if print_layers:\n",
    "        for i, layer in enumerate(base_model.layers):\n",
    "            print(i, layer.name)\n",
    "\n",
    "    # Freeze or set first few layers as untrainable\n",
    "    # Unfreeze or set rest of the layers as trainable\n",
    "    for layer in model.layers[:non_trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[non_trainable_index:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Performance Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation performance\n",
    "def plot_history(history, plot_val, title, xlabel, ylabel, legend=[['Train', 'Val'], ['Train', 'Val']], fig_size=(10,8), title_fontsize = 14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history[plot_val[0][0]])\n",
    "    plt.plot(history.history[plot_val[0][1]])\n",
    "    plt.title(title[0], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[0], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[0], fontsize=label_fontsize)\n",
    "    plt.legend(legend[0], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history[plot_val[1][0]])\n",
    "    plt.plot(history.history[plot_val[1][1]])\n",
    "    plt.title(title[1], fontsize=title_fontsize)\n",
    "    plt.ylabel(ylabel[1], fontsize=label_fontsize)\n",
    "    plt.xlabel(xlabel[1], fontsize=label_fontsize)\n",
    "    plt.legend(legend[1], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Performance Report Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_report(model, test_generator, classes, print_report=False):\n",
    "    y_preds = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "    y_classes = y_preds.argmax(axis=-1)\n",
    "\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    CM_report = classification_report(test_generator.classes, y_classes, target_names=classes)\n",
    "    \n",
    "    if print_report: \n",
    "        print(CM_report)\n",
    "    return y_preds, y_classes, CM, CM_report\n",
    "\n",
    "def model_evaluate(model, test_generator, print_report=False):\n",
    "    result = model.evaluate_generator(generator=test_generator, steps=len(test_generator))\n",
    "    \n",
    "    accuracy = result[1]*100\n",
    "    loss = result[0]\n",
    "    \n",
    "    if print_report:\n",
    "        print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "    \n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse classification report for reporting negetive classes (0)\n",
    "def reverse_pos_neg(CM, print_bool):\n",
    "    tp=CM[0][0]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    tn=CM[1][1]\n",
    "    if print_bool:\n",
    "        print(tp, fp, tn, fn, tn)\n",
    "    return [tp, fp, tn, fn, tn]\n",
    "\n",
    "# reverse and report classification report for reporting negetive classes (0)\n",
    "def report(CM, reverse):\n",
    "    if not reverse:\n",
    "        tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "    else:\n",
    "        tp=CM[0][0]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        tn=CM[1][1]\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "    print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_models(model_dir, details, report_type, classes):\n",
    "    results = {}\n",
    "    \n",
    "    model_files = os.listdir(model_dir)\n",
    "    \n",
    "    i=0\n",
    "    model = None\n",
    "    \n",
    "    for model_file in model_files:\n",
    "        \n",
    "        model_path = model_dir+\"\\\\\"+model_file\n",
    "        \n",
    "        if not path.isdir(model_path):\n",
    "            reset_graph(model)\n",
    "\n",
    "            model = keras.models.load_model(model_path)\n",
    "\n",
    "            if report_type==\"Complete\":\n",
    "                y_preds, y_classes, CM, CM_report = predict_report(model, test_generator, classes)\n",
    "                results[model_file] = [CM, CM_report]\n",
    "\n",
    "            else:\n",
    "                accuracy, loss =  model_evaluate(model, test_generator, print_report=False)\n",
    "\n",
    "                results[model_file] = [accuracy, loss]\n",
    "\n",
    "\n",
    "            if details:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_file))\n",
    "                print(\"*\"*80)\n",
    "                if report_type==\"Complete\":\n",
    "                    print(CM_report)\n",
    "                else:\n",
    "                    print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "                    print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            elif not details and i%10==0:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_file))\n",
    "                print(\"*\"*80)\n",
    "                if report_type==\"Complete\":\n",
    "                    print(CM_report)\n",
    "                else:\n",
    "                    print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "                    print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            i+=1\n",
    "    print(\"Test complete\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_over_epochs(array, title, xlabel=\"Epoch\", ylabel=\"Value\", title_fontsize=14, label_fontsize=12, subplot_no=0):\n",
    "    x_axis_arr = np.arange(len(array))\n",
    "    if subplot_no:\n",
    "        plt.subplot(subplot_no)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.plot(x_axis_arr, array)\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "    \n",
    "def line_plot_over_epochs_loss_acc(array, title, fig_size=(10, 8), xlabel=[\"Epoch\", \"Epoch\"], ylabel=[\"Value\",\"Value\"], title_fontsize=14, label_fontsize=12):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    line_plot_over_epochs(array[0], title[0], xlabel=xlabel[0], ylabel=ylabel[0], title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=121)\n",
    "    line_plot_over_epochs(array[1], title[1], xlabel=xlabel[1], ylabel=ylabel[1], title_fontsize=title_fontsize, label_fontsize=label_fontsize, subplot_no=122)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Train, Validation and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input/ output directory\n",
    "# Configure training, validation, testing directory\n",
    "\n",
    "input_directory = r\"data/input/\"\n",
    "output_directory = r\"data/output/\"\n",
    "\n",
    "training_dir = input_directory+ r\"train\"\n",
    "testing_dir = input_directory+ r\"test\"\n",
    "validation_dir = input_directory+ r\"val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xlabel=\"Count\"\n",
    "ylabel=\"CaseType\"\n",
    "fig_size = (14,4)\n",
    "# fig_size = (4,2)\n",
    "# title_fontsize=14\n",
    "title_fontsize=13\n",
    "# label_fontsize=12\n",
    "label_fontsize=13\n",
    "title=\"Number of Cases\"\n",
    "\n",
    "\n",
    "show_train_val_test(training_dir, validation_dir, testing_dir, title, xlabel, ylabel, figsize=fig_size, title_fontsize = title_fontsize, label_fontsize=label_fontsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (Image Preprocessing)\n",
    "#### Configuring Image Transformation Parameters for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get number of label/ class / category\n",
    "num_class = len(os.listdir(training_dir))\n",
    "print(num_class)\n",
    "\n",
    "\n",
    "#Image Augmentation/ Preprocessing before training\n",
    "norm=255.0\n",
    "rescale=1./norm\n",
    "shear_range=0.2\n",
    "zoom_range=0.2\n",
    "horizontal_flip=True\n",
    "\n",
    "\n",
    "# flow from directory function\n",
    "# Target Image dimention\n",
    "target_size=(224, 224)\n",
    "\n",
    "# Batch size\n",
    "# train\n",
    "# batch_size=32\n",
    "batch_size=64\n",
    "# batch_size=128\n",
    "\n",
    "# validation\n",
    "validation_batch_size=1\n",
    "# test\n",
    "test_batch_size=1\n",
    "\n",
    "# shuffle\n",
    "# test\n",
    "test_shuffle=False\n",
    "\n",
    "# validation split for train\n",
    "validation_split=0.0\n",
    "\n",
    "# class mode\n",
    "# class_mode='binary'\n",
    "class_mode='categorical'\n",
    "# class_mode='sparse'\n",
    "\n",
    "\n",
    "classes = ['Normal', 'PNEUMONIA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_transformed_image_batch(training_dir, target_size, classes, class_mode=class_mode, batch_size=batch_size, rescale=rescale, shear_range=shear_range, zoom_range=zoom_range, horizontal_flip=horizontal_flip)       \n",
    "\n",
    "validation_generator = get_transformed_image_batch(validation_dir, target_size, classes, class_mode=class_mode, batch_size=validation_batch_size, rescale=rescale)       \n",
    "\n",
    "test_generator = get_transformed_image_batch(validation_dir, target_size, classes, class_mode=class_mode, batch_size=test_batch_size, shuffle = test_shuffle, rescale=rescale) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Adjustmanet for Class Label Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_generator.classes\n",
    "class_weight=get_class_weight(y)\n",
    "# class_weight=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model and Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model and log output directory\n",
    "model_dir=output_directory + r\"models/\"\n",
    "log_dir=output_directory + r\"logs\"\n",
    "\n",
    "# make or reset directory\n",
    "# mk_reset_dir(model_dir, False)\n",
    "# mk_reset_dir(log_dir, False)\n",
    "\n",
    "model_file=model_dir+\"base-\"+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(3,150,150)\n",
    "activation='relu'\n",
    "activation2='sigmoid'\n",
    "padding=\"same\"\n",
    "padding2=\"valid\"\n",
    "pool_size=(2, 2)\n",
    "dilation_rate=(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Base Model and Training Configuration for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Base Model - InceptionV3 (pretrained) initial training settings\n",
    "\n",
    "# inception base top layer discarded\n",
    "include_top=False\n",
    "\n",
    "# number of layers freezed\n",
    "non_trainable_index = 249\n",
    "\n",
    "# init_optimizer=optimizers.Adam()\n",
    "init_optimizer=optimizers.Adam(0.000001)\n",
    "\n",
    "print_layers=False\n",
    "\n",
    "# initial epochs on only output layers\n",
    "# init_epochs=1\n",
    "# initial_epochs=3\n",
    "init_epochs=15\n",
    "\n",
    "# verbose\n",
    "init_verbose=0\n",
    "\n",
    "# callbacks\n",
    "init_callbacks=None\n",
    "\n",
    "# model report\n",
    "print_report=True\n",
    "\n",
    "\n",
    "### Full model training parameter configuration for Loss, Optimizer and Performance Metrics\n",
    "\n",
    "# optimizer\n",
    "# adam lr=0.01/0.001/0.0001/0.00001/0.000001, decay = decay=1e-5/ 1e-6\n",
    "# optimizer=optimizers.Adam()\n",
    "optimizer=optimizers.Adam(0.00001)\n",
    "\n",
    "\n",
    "# loss function\n",
    "# loss='binary_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "# performance metrics ('accuracy', 'binary_accuracy', precision, recall)\n",
    "# metrics=['accuracy']\n",
    "metrics=['mae', 'acc']\n",
    "\n",
    "\n",
    "### Main model training parameter configuration\n",
    "\n",
    "# epochs = 20/30/50\n",
    "epochs = 30\n",
    "\n",
    "# steps\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "# verbose 0=nothing 1=each line\n",
    "verbose=0\n",
    "\n",
    "\n",
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard\n",
    "\n",
    "# checkpoint\n",
    "ck_monitor='val_acc'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "red_lr_patience=10\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "red_lr_min_lr=0.0\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "# es_patience=0\n",
    "es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "update_freq='epoch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks - checkpoint, reduce_lr, early_stopping, tensorboard\n",
    "callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "41/41 [==============================] - 217s 5s/step - loss: 0.5780 - acc: 0.7711 - val_loss: 0.7854 - val_acc: 0.6531\n",
      "Epoch 2/15\n",
      "41/41 [==============================] - 129s 3s/step - loss: 0.2635 - acc: 0.8900 - val_loss: 1.1438 - val_acc: 0.6312\n",
      "Epoch 3/15\n",
      "41/41 [==============================] - 122s 3s/step - loss: 0.2254 - acc: 0.9087 - val_loss: 1.0745 - val_acc: 0.6469\n",
      "Epoch 4/15\n",
      "41/41 [==============================] - 126s 3s/step - loss: 0.2062 - acc: 0.9158 - val_loss: 1.7590 - val_acc: 0.6281\n",
      "Epoch 5/15\n",
      "41/41 [==============================] - 149s 4s/step - loss: 0.2138 - acc: 0.9115 - val_loss: 0.6489 - val_acc: 0.7406\n",
      "Epoch 6/15\n",
      "41/41 [==============================] - 171s 4s/step - loss: 0.1962 - acc: 0.9184 - val_loss: 0.6440 - val_acc: 0.7531\n",
      "Epoch 7/15\n",
      "41/41 [==============================] - 170s 4s/step - loss: 0.2113 - acc: 0.9148 - val_loss: 0.6231 - val_acc: 0.7469\n",
      "Epoch 8/15\n",
      "41/41 [==============================] - 171s 4s/step - loss: 0.1909 - acc: 0.9254 - val_loss: 1.0240 - val_acc: 0.6813\n",
      "Epoch 9/15\n",
      "41/41 [==============================] - 169s 4s/step - loss: 0.1971 - acc: 0.9210 - val_loss: 1.5997 - val_acc: 0.6406\n",
      "Epoch 10/15\n",
      "41/41 [==============================] - 177s 4s/step - loss: 0.1932 - acc: 0.9212 - val_loss: 0.9241 - val_acc: 0.6969\n",
      "Epoch 11/15\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.1834 - acc: 0.9270 - val_loss: 0.6082 - val_acc: 0.7750\n",
      "Epoch 12/15\n",
      "41/41 [==============================] - 149s 4s/step - loss: 0.1808 - acc: 0.9327 - val_loss: 0.8295 - val_acc: 0.7188\n",
      "Epoch 13/15\n",
      "41/41 [==============================] - 135s 3s/step - loss: 0.1886 - acc: 0.9270 - val_loss: 0.8652 - val_acc: 0.7125\n",
      "Epoch 14/15\n",
      "41/41 [==============================] - 159s 4s/step - loss: 0.1793 - acc: 0.9311 - val_loss: 0.9798 - val_acc: 0.6937\n",
      "Epoch 15/15\n",
      "41/41 [==============================] - 154s 4s/step - loss: 0.1824 - acc: 0.9261 - val_loss: 1.3938 - val_acc: 0.6500\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2050        dense_1[0][0]                    \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 12,788,130\n",
      "Trainable params: 2,100,226\n",
      "Non-trainable params: 10,687,904\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "# # get inception model\n",
    "model = get_inception_model(train_generator, validation_generator, init_epochs, init_verbose, init_optimizer, loss, metrics, tensorboard, init_callbacks, num_class, include_top, non_trainable_index, print_layers)\n",
    "main_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model Performance with Minimum Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.28      0.04      0.07       121\n",
      "  PNEUMONIA       0.62      0.93      0.74       199\n",
      "\n",
      "avg / total       0.49      0.60      0.49       320\n",
      "\n",
      "Accuracy: 64.06%\n",
      "Loss: 1.40\n"
     ]
    }
   ],
   "source": [
    "print_report=True\n",
    "\n",
    "y_preds, y_classes, CM, CM_report = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "accuracy, loss =  model_evaluate(model, test_generator, print_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 174s 4s/step - loss: 0.1635 - acc: 0.9369 - val_loss: 2.0591 - val_acc: 0.6281\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 149s 4s/step - loss: 0.1495 - acc: 0.9468 - val_loss: 1.6007 - val_acc: 0.6531\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 167s 4s/step - loss: 0.1358 - acc: 0.9482 - val_loss: 1.8466 - val_acc: 0.6312\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 146s 4s/step - loss: 0.1226 - acc: 0.9529 - val_loss: 1.5848 - val_acc: 0.6562\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 179s 4s/step - loss: 0.1205 - acc: 0.9578 - val_loss: 1.8135 - val_acc: 0.6375\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 160s 4s/step - loss: 0.1130 - acc: 0.9592 - val_loss: 1.4081 - val_acc: 0.6656\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 152s 4s/step - loss: 0.1082 - acc: 0.9575 - val_loss: 1.3269 - val_acc: 0.6750\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 161s 4s/step - loss: 0.1039 - acc: 0.9607 - val_loss: 1.3610 - val_acc: 0.6625\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 159s 4s/step - loss: 0.1048 - acc: 0.9581 - val_loss: 1.2628 - val_acc: 0.6687\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 147s 4s/step - loss: 0.0992 - acc: 0.9639 - val_loss: 1.2148 - val_acc: 0.6875\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 160s 4s/step - loss: 0.0959 - acc: 0.9626 - val_loss: 1.3567 - val_acc: 0.6656\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 156s 4s/step - loss: 0.0925 - acc: 0.9666 - val_loss: 1.3027 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 147s 4s/step - loss: 0.0917 - acc: 0.9660 - val_loss: 1.3185 - val_acc: 0.6750\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 146s 4s/step - loss: 0.0881 - acc: 0.9660 - val_loss: 1.3455 - val_acc: 0.6719\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 141s 3s/step - loss: 0.0847 - acc: 0.9656 - val_loss: 1.3122 - val_acc: 0.6781\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 142s 3s/step - loss: 0.0920 - acc: 0.9644 - val_loss: 1.3077 - val_acc: 0.6813\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 136s 3s/step - loss: 0.0884 - acc: 0.9661 - val_loss: 1.3567 - val_acc: 0.6594\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 132s 3s/step - loss: 0.0879 - acc: 0.9675 - val_loss: 1.2951 - val_acc: 0.6781\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 132s 3s/step - loss: 0.0848 - acc: 0.9706 - val_loss: 1.2561 - val_acc: 0.6875\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 133s 3s/step - loss: 0.0959 - acc: 0.9649 - val_loss: 1.3146 - val_acc: 0.6719\n",
      "Epoch 21/100\n",
      " 7/41 [====>.........................] - ETA: 1:12 - loss: 0.0834 - acc: 0.9732"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-9922e8a4d485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     class_weight=class_weight)\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "\n",
    "epochs=100\n",
    "optimizer=optimizers.adam(lr=0.00001, decay=1e-6)\n",
    "# model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-a3d2b0e188e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mlabel_fontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mplot_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfig_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfig_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle_fontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle_fontsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_fontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_fontsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_val=[['acc', 'val_acc'], ['loss', 'val_loss']]\n",
    "\n",
    "title = ['Model accuracy', 'Model loss']\n",
    "\n",
    "xlabel = ['Epoch', 'Epoch']\n",
    "ylabel = ['Accuracy', 'Loss']\n",
    "\n",
    "legend = ['Train', 'Val']\n",
    "\n",
    "fig_size=(14, 5)\n",
    "\n",
    "\n",
    "title_fontsize=17\n",
    "label_fontsize=15\n",
    "\n",
    "plot_history(history, plot_val, title, xlabel, ylabel, fig_size=fig_size, title_fontsize=title_fontsize, label_fontsize=label_fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance of All Models on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model No: 1\n",
      "Model File: 01-val_acc-0.63-val_loss-1.34.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.50      0.01      0.02       121\n",
      "  PNEUMONIA       0.62      0.99      0.77       199\n",
      "\n",
      "avg / total       0.58      0.62      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model No: 2\n",
      "Model File: 01-val_acc-0.64-val_loss-1.80.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.00      0.00      0.00       121\n",
      "  PNEUMONIA       0.62      1.00      0.77       199\n",
      "\n",
      "avg / total       0.39      0.62      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 3\n",
      "Model File: 02-val_acc-0.58-val_loss-1.86.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       1.00      0.01      0.02       121\n",
      "  PNEUMONIA       0.62      1.00      0.77       199\n",
      "\n",
      "avg / total       0.77      0.62      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model No: 4\n",
      "Model File: 02-val_acc-0.62-val_loss-2.04.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.00      0.00      0.00       121\n",
      "  PNEUMONIA       0.62      1.00      0.77       199\n",
      "\n",
      "avg / total       0.39      0.62      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 5\n",
      "Model File: 03-val_acc-0.65-val_loss-1.70.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       1.00      0.01      0.02       121\n",
      "  PNEUMONIA       0.62      1.00      0.77       199\n",
      "\n",
      "avg / total       0.77      0.62      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 6\n",
      "Model File: 04-val_acc-0.64-val_loss-1.66.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       1.00      0.01      0.02       121\n",
      "  PNEUMONIA       0.62      1.00      0.77       199\n",
      "\n",
      "avg / total       0.77      0.62      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 7\n",
      "Model File: 05-val_acc-0.63-val_loss-1.64.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.50      0.01      0.02       121\n",
      "  PNEUMONIA       0.62      0.99      0.77       199\n",
      "\n",
      "avg / total       0.58      0.62      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 8\n",
      "Model File: 06-val_acc-0.67-val_loss-1.01.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.57      0.07      0.12       121\n",
      "  PNEUMONIA       0.63      0.97      0.76       199\n",
      "\n",
      "avg / total       0.61      0.63      0.52       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 9\n",
      "Model File: 07-val_acc-0.65-val_loss-1.31.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.50      0.02      0.05       121\n",
      "  PNEUMONIA       0.62      0.98      0.76       199\n",
      "\n",
      "avg / total       0.58      0.62      0.49       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 10\n",
      "Model File: 08-val_acc-0.66-val_loss-1.27.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.33      0.02      0.03       121\n",
      "  PNEUMONIA       0.62      0.98      0.76       199\n",
      "\n",
      "avg / total       0.51      0.62      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 11\n",
      "Model File: 09-val_acc-0.63-val_loss-1.36.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.38      0.02      0.05       121\n",
      "  PNEUMONIA       0.62      0.97      0.76       199\n",
      "\n",
      "avg / total       0.53      0.62      0.49       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 12\n",
      "Model File: 10-val_acc-0.68-val_loss-1.09.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.22      0.02      0.03       121\n",
      "  PNEUMONIA       0.62      0.96      0.75       199\n",
      "\n",
      "avg / total       0.47      0.61      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 13\n",
      "Model File: 11-val_acc-0.67-val_loss-1.23.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.20      0.02      0.03       121\n",
      "  PNEUMONIA       0.62      0.96      0.75       199\n",
      "\n",
      "avg / total       0.46      0.60      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 14\n",
      "Model File: 12-val_acc-0.65-val_loss-1.20.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.18      0.02      0.03       121\n",
      "  PNEUMONIA       0.61      0.95      0.75       199\n",
      "\n",
      "avg / total       0.45      0.60      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 15\n",
      "Model File: 13-val_acc-0.68-val_loss-1.08.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.17      0.02      0.03       121\n",
      "  PNEUMONIA       0.61      0.95      0.75       199\n",
      "\n",
      "avg / total       0.44      0.60      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 16\n",
      "Model File: 14-val_acc-0.68-val_loss-1.11.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.21      0.02      0.04       121\n",
      "  PNEUMONIA       0.61      0.94      0.74       199\n",
      "\n",
      "avg / total       0.46      0.60      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 17\n",
      "Model File: 15-val_acc-0.64-val_loss-1.28.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.17      0.02      0.03       121\n",
      "  PNEUMONIA       0.61      0.95      0.75       199\n",
      "\n",
      "avg / total       0.44      0.60      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 18\n",
      "Model File: 16-val_acc-0.70-val_loss-1.10.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.17      0.02      0.03       121\n",
      "  PNEUMONIA       0.61      0.95      0.75       199\n",
      "\n",
      "avg / total       0.44      0.60      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 19\n",
      "Model File: 17-val_acc-0.64-val_loss-1.20.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.08      0.01      0.02       121\n",
      "  PNEUMONIA       0.61      0.94      0.74       199\n",
      "\n",
      "avg / total       0.41      0.59      0.47       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model No: 20\n",
      "Model File: 18-val_acc-0.68-val_loss-1.14.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.08      0.01      0.02       121\n",
      "  PNEUMONIA       0.61      0.94      0.74       199\n",
      "\n",
      "avg / total       0.41      0.59      0.47       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 21\n",
      "Model File: 19-val_acc-0.66-val_loss-1.18.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.08      0.01      0.02       121\n",
      "  PNEUMONIA       0.61      0.94      0.74       199\n",
      "\n",
      "avg / total       0.41      0.59      0.47       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 22\n",
      "Model File: 20-val_acc-0.67-val_loss-1.20.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.00      0.00      0.00       121\n",
      "  PNEUMONIA       0.61      0.94      0.74       199\n",
      "\n",
      "avg / total       0.38      0.58      0.46       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 23\n",
      "Model File: 21-val_acc-0.67-val_loss-1.28.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.09      0.01      0.02       121\n",
      "  PNEUMONIA       0.61      0.95      0.74       199\n",
      "\n",
      "avg / total       0.41      0.59      0.47       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 24\n",
      "Model File: 22-val_acc-0.68-val_loss-1.09.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.17      0.02      0.03       121\n",
      "  PNEUMONIA       0.61      0.95      0.75       199\n",
      "\n",
      "avg / total       0.44      0.60      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 25\n",
      "Model File: 23-val_acc-0.66-val_loss-1.18.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.25      0.02      0.05       121\n",
      "  PNEUMONIA       0.62      0.95      0.75       199\n",
      "\n",
      "avg / total       0.48      0.60      0.48       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 26\n",
      "Model File: 24-val_acc-0.67-val_loss-1.14.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.33      0.03      0.06       121\n",
      "  PNEUMONIA       0.62      0.96      0.75       199\n",
      "\n",
      "avg / total       0.51      0.61      0.49       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 27\n",
      "Model File: 25-val_acc-0.64-val_loss-1.28.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.46      0.05      0.09       121\n",
      "  PNEUMONIA       0.63      0.96      0.76       199\n",
      "\n",
      "avg / total       0.56      0.62      0.51       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 28\n",
      "Model File: 26-val_acc-0.68-val_loss-1.17.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.77      0.08      0.15       121\n",
      "  PNEUMONIA       0.64      0.98      0.77       199\n",
      "\n",
      "avg / total       0.69      0.64      0.54       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 29\n",
      "Model File: 27-val_acc-0.66-val_loss-1.24.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.75      0.07      0.14       121\n",
      "  PNEUMONIA       0.64      0.98      0.77       199\n",
      "\n",
      "avg / total       0.68      0.64      0.53       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 30\n",
      "Model File: 28-val_acc-0.64-val_loss-1.28.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.82      0.07      0.14       121\n",
      "  PNEUMONIA       0.64      0.99      0.78       199\n",
      "\n",
      "avg / total       0.71      0.64      0.53       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 31\n",
      "Model File: 29-val_acc-0.70-val_loss-1.02.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.85      0.09      0.16       121\n",
      "  PNEUMONIA       0.64      0.99      0.78       199\n",
      "\n",
      "avg / total       0.72      0.65      0.55       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Model No: 32\n",
      "Model File: 30-val_acc-0.64-val_loss-1.41.hdf5\n",
      "********************************************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Normal       0.82      0.07      0.14       121\n",
      "  PNEUMONIA       0.64      0.99      0.78       199\n",
      "\n",
      "avg / total       0.71      0.64      0.53       320\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'data/output/models/\\old', errno = 13, error message = 'Permission denied', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-d5bc72898451>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mreport_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Complete\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_all_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-eef892ce6e97>\u001b[0m in \u001b[0;36mtest_all_models\u001b[1;34m(model_dir, details, report_type, classes)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreport_type\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"Complete\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'data/output/models/\\old', errno = 13, error message = 'Permission denied', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "details = True\n",
    "# report_type = \"Acc_Loss\"\n",
    "report_type = \"Complete\"\n",
    "\n",
    "results=test_all_models(model_dir, details, report_type, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of  Performance Over All Epochs/Models based on Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "array=[[1,2,3],[2,3,4]]\n",
    "\n",
    "fig_size = (10, 8)\n",
    "title=[\"Test Dataset Performance (Accuracy)\", \"Test Dataset Performance (Loss)\"]\n",
    "xlabel=[\"Epoch\", \"Epoch\"]\n",
    "ylabel=[\"Accuracy (100%)\", \"Loss\"]\n",
    "\n",
    "line_plot_over_epochs_loss_acc(array, title, fig_size=fig_size, xlabel=xlabel, ylabel=ylabel, title_fontsize=title_fontsize, label_fontsize=label_fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_callbacks(checkpoint, reduce_lr, early_stopping, tensorboard)\n",
    "# reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration for Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model and log output directory\n",
    "model_dir=output_directory+r\"models/\"\n",
    "log_dir=output_directory+r\"logs\"\n",
    "\n",
    "# make or reset directory\n",
    "# mk_reset_dir(model_dir, False)\n",
    "# mk_reset_dir(log_dir, False)\n",
    "\n",
    "model_file=model_dir+\"base-\"+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "##### Base Model - InceptionV3 (pretrained) initial training settings\n",
    "\n",
    "# inception base top layer discarded\n",
    "include_top=False\n",
    "\n",
    "# number of layers freezed\n",
    "non_trainable_index=249\n",
    "\n",
    "print_layers=False\n",
    "\n",
    "# initial epochs on only output layers\n",
    "# init_epochs=1\n",
    "# initial_epochs=3\n",
    "init_epochs=20\n",
    "\n",
    "# verbose\n",
    "init_verbose=0\n",
    "\n",
    "# callbacks\n",
    "init_callbacks=None\n",
    "\n",
    "# model report\n",
    "print_report=True\n",
    "\n",
    "\n",
    "### Full model training parameter configuration for Loss, Optimizer and Performance Metrics\n",
    "\n",
    "# optimizer\n",
    "# adam lr=0.01/0.001/0.0001/0.00001/0.000001, decay = decay=1e-5/ 1e-6\n",
    "optimizer=optimizers.Adam()\n",
    "\n",
    "\n",
    "# loss function\n",
    "# loss='binary_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "# performance metrics ('accuracy', 'binary_accuracy', precision, recall)\n",
    "metrics=['accuracy']\n",
    "\n",
    "\n",
    "### Main model training parameter configuration\n",
    "\n",
    "# epochs = 20/30/50\n",
    "epochs=30\n",
    "\n",
    "# steps\n",
    "steps_per_epoch=len(train_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "\n",
    "# verbose 0=nothing 1=each line\n",
    "verbose=0\n",
    "\n",
    "\n",
    "#### Configuration for Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard\n",
    "\n",
    "# checkpoint\n",
    "ck_monitor='val_acc'\n",
    "ck_verbose=0\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "# red_lr_patience=5\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "# red_lr_min_lr=0.0001 # default\n",
    "red_lr_min_lr=0.000001\n",
    "\n",
    "\n",
    "# early_stopping\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "# es_patience=0\n",
    "es_patience=5\n",
    "es_verbose=0\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "\n",
    "# tensorboard\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_size\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "\n",
    "################################################ Retrain #########################################################\n",
    "initial_epoch=epochs+1\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Callbacks - CheckPoint, ReduceLROnPlateau, Early Stopping, TensorBoard for Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_file, monitor=ck_monitor, verbose=ck_verbose, save_best_only=ck_save_best_only, save_weights_only=ck_save_weights_only, mode=ck_mode, period=ck_period)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=red_lr_monitor, factor=red_lr_factor, patience=red_lr_patience, verbose=red_lr_verbose, mode=red_lr_mode, min_delta=red_lr_min_delta, cooldown=red_lr_cooldown, min_lr=red_lr_min_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=es_monitor, min_delta=es_min_delta, patience=es_patience, verbose=es_verbose, mode=es_mode, baseline=es_baseline)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=tb_histogram_freq, batch_size=tb_batch_size, write_graph=tb_write_graph, write_grads=tb_write_grads, write_images=tb_write_images, embeddings_freq=tb_embeddings_freq, embeddings_layer_names=tb_embeddings_layer_names, embeddings_metadata=tb_embeddings_metadata, embeddings_data=tb_embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Best Model\n",
    "### Selecting best model file based on validation accuracy mentioned in file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best model file / checkpoint for retraining\n",
    "# model_path = model_dir+r\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "# model_path = model_dir+r\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "# best accuracy/ F-1 score\n",
    "# model_path = \"data/output/models/\"+\"17-val_acc-0.82-val_loss-0.42.hdf5\"\n",
    "\n",
    "# Lowest validation Loss\n",
    "# model_path = \"data/output/models/\"+\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "\n",
    "# Best Recall\n",
    "# model_path = \"data/output/models/\"+\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "model_path = model_dir+r\"20-val_acc-0.71-val_loss-1.26.hdf5\"\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "# retrain by loading last good model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    # verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight,\n",
    "    initial_epoch=initial_epoch)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def extract_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    extracted_id = b[0]\n",
    "    \n",
    "    return extracted_id\n",
    "\n",
    "\n",
    "\n",
    "test_filenames = test_generator.filenames\n",
    "df_preds = pd.DataFrame(predictions, columns=classes)\n",
    "df_preds['file_names'] = test_filenames\n",
    "df_preds['id'] = df_preds['file_names'].apply(extract_id)\n",
    "df_preds.head()\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['Cancer']\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "roc_auc_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':image_id, \n",
    "                           'label':y_pred, \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('patch_preds.csv', columns=['label']) \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing Confusion Matrix of Model Performance for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(test_generator, y_classes, classes, figsize, stick_fontsize):\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=figsize, hide_ticks=True,cmap=plt.cm.Blues)\n",
    "    plt.xticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.yticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.show()\n",
    "    return CM\n",
    "\n",
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), classes, fontsize=16)\n",
    "plt.yticks(range(2), classes, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing precision, recall, f1-score, support for Model Performance over Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report_print = classification_report(test_generator.classes, y_classes, target_names=target_names)\n",
    "print(classification_report_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing calcualted precision, recall for Model over Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision and Recall\n",
    "tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retriving actual labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (test_generator.class_indices)\n",
    "label_map_rev = {v: name_correct(k) for k,v in label_map.items()}\n",
    "num_batch_t = len(test_generator)\n",
    "print(label_map)\n",
    "print(label_map_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing accuracy for Model over Single Batch of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0, num_batch_t-1)\n",
    "y_img_batch, y_class_batch = test_generator[num] \n",
    "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
    "y_true = np.argmax(y_class_batch,-1)\n",
    "print(\"Selected Batch No: %d\\nBatch Size: %d\"%(num, len(y_pred)))\n",
    "print(\"Accuracy : \", sum(y_pred==y_true)/batch_size*100, \"%\")\n",
    "\n",
    "y_true_labels = [label_map_rev[c] for c in y_true]\n",
    "y_pred_labels = [label_map_rev[c] for c in y_pred]\n",
    "batch_size_t = len(y_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n",
    "Visualization of performance of a random test dataset batch and few random images from a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/result\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "\n",
    "cols = 8\n",
    "rows= batch_size_t/cols\n",
    "if batch_size_t%cols==0:\n",
    "    rows = int(batch_size_t/cols)\n",
    "else:\n",
    "    rows = int(batch_size_t/cols)+1\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org : \"\n",
    "pred_label_title_prefix = \"pred: \"\n",
    "\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "for i in range(0, batch_size_t): # how many imgs will show from the mxn grid\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[i])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[i]==y_pred_labels[i]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i], color=false_prediction_label_color)\n",
    "        \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)\n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/sample\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "cols = 4\n",
    "rows= 2\n",
    "\n",
    "count = rows*cols\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "# titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org:  \"\n",
    "pred_label_title_prefix = \"pred: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "\n",
    "batch_size_tmp = batch_size_t\n",
    "\n",
    "m = {}\n",
    "\n",
    "for i in range(0, count): \n",
    "    num = random.randint(0, batch_size_tmp-1)\n",
    "    while num in m:\n",
    "        num = random.randint(0, batch_size_tmp-1)\n",
    "    \n",
    "    m[num]=1\n",
    "    \n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[num])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[num]==y_pred_labels[num]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num], color=false_prediction_label_color)\n",
    "    \n",
    "   \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)   \n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
