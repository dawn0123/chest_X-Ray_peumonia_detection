{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "<pre>\n",
    "Author           : Anjana Tiha\n",
    "Project Name     : Detection of Pneumonia from Chest X-Ray Images using Convolutional Neural Network, \n",
    "                   and Transfer Learning.\n",
    "Description      : 1. Detected Pneumonia from Chest X-Ray images by retraining pretrained model “InceptionV3” \n",
    "                      with 5856 images of X-ray (1.15GB).\n",
    "                   2. For retraining removed output layers, freezed first few layers and Fine-tuned model for \n",
    "                      two new label classes (Pneumonia and Normal).\n",
    "                   3. Attained testing accuracy 83.44% and loss 0.42.\n",
    "Method           : \n",
    "Tools/Library    : Python, Keras, PyTorch, TensorFlow\n",
    "Version History  : 1.0.0.0\n",
    "Current Version  : 1.0.0.0\n",
    "Last Update      : 11.30.2018\n",
    "Comments         : Please use Anaconda editor for convenience of visualization.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "<pre>\n",
    "GitHub Link      : <a href=https://github.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitHub)</a>\n",
    "GitLab Link      : <a href=https://gitlab.com/anjanatiha/Detection-of-Pneumonia-from-Chest-X-Ray-Images>Detection of Pneumonia from Chest X-Ray Images(GitLab)</a>\n",
    "Portfolio        : <a href=https://anjanatiha.wixsite.com/website>Anjana Tiha's Portfolio</a>\n",
    "</pre>\n",
    "\n",
    "#### Dataset\n",
    "<pre>\n",
    "Dataset Name     : Chest X-Ray Images (Pneumonia)\n",
    "Dataset Link     : <a href=https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia>Chest X-Ray Images (Pneumonia) Dataset (Kaggle)</a>\n",
    "                 : <a href=https://data.mendeley.com/datasets/rscbjbr9sj/2>Chest X-Ray Images (Pneumonia) Dataset (Original Dataset)</a>\n",
    "Original Paper   : <a href=https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5>Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning</a>\n",
    "                   (Daniel S. Kermany, Michael Goldbaum, Wenjia Cai, M. Anthony Lewis, Huimin Xia, Kang Zhang)\n",
    "                   https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library/Tools Version\n",
    "- Python - v3.6.7\n",
    "- argparse\n",
    "- random\n",
    "- numpy\n",
    "- shutil\n",
    "- gc\n",
    "- re\n",
    "- Keras - 2.2.4\n",
    "- Keras-preprocessing - v1.0.5\n",
    "- TensorFlow - 1.12\n",
    "- PIL/Pillow - 5.1.0\n",
    "- Matplotlib - 2.2.2\n",
    "- scikit-learn - 0.19.1\n",
    "- mlxtend - 0.14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands / Running Instruction\n",
    "<pre>\n",
    "tensorboard --logdir=logs\n",
    "%config IPCompleter.greedy=True\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "<b>Dataset Details</b>\n",
    "Dataset Name            : Chest X-Ray Images (Pneumonia)\n",
    "Number of Class         : 2\n",
    "Number/Size of Images   : Total      : 5856 (1.15 Gigabyte (GB))\n",
    "                          Training   : 5216 (1.07 Gigabyte (GB))\n",
    "                          Validation : 320  (42.8 Megabyte (MB))\n",
    "                          Testing    : 320  (35.4 Megabyte (MB))\n",
    "\n",
    "<b>Model Parameters</b>\n",
    "Machine Learning Library: Keras\n",
    "Base Model              : InceptionV3\n",
    "Optimizers              : Adam\n",
    "Loss Function           : categorical_crossentropy\n",
    "\n",
    "<b>Training Parameters</b>\n",
    "Batch Size              : 64\n",
    "Number of Epochs        : 50\n",
    "Training Time           : 3 Hours\n",
    "\n",
    "<b>Output (Prediction/ Recognition / Classification Metrics)</b>\n",
    "<!--<b>Validation</b>-->\n",
    "<b>Testing</b>\n",
    "Accuracy                : 83.44%\n",
    "Loss                    : 0.42\n",
    "<!--Precision               : -->\n",
    "Recall                  : 94% (highest)\n",
    "<!--Specificity             : -->\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andromeda\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import inspect\n",
    "\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directory, if directory exists removes if remove parameter is set to True \n",
    "def create_directory(directory_path, remove=False):\n",
    "    if remove and os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Removes directory, if directory exists \n",
    "def remove_directory(directory_path):\n",
    "    if os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Deletes file, if file exists \n",
    "def remove_file(filename):\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            os.remove(filename)\n",
    "        except:\n",
    "            print(\"Could not remove file : \", filename)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print date and time for given type of representation\n",
    "def date_time(x):\n",
    "    if x==1:\n",
    "        print('Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==2:    \n",
    "        print('Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    if x==3:  \n",
    "        print('Date now: %s' % datetime.datetime.now())\n",
    "    if x==4:  \n",
    "        print('Date today: %s' % datetime.date.today())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints a integer for degugging\n",
    "def debug(x):\n",
    "    print(\"-\"*40, x, \"-\"*40)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of files in each subdirectory of a directory\n",
    "def subdirectory_file_count(master_directory):\n",
    "    subdirectories = os.listdir(master_directory)\n",
    "    subdirectory_count = len(subdirectories)\n",
    "\n",
    "    subdirectory_names = []\n",
    "    subdirectory_file_counts = []\n",
    "\n",
    "    for subdirectory in subdirectories:\n",
    "        current_directory = os.path.join(master_directory, subdirectory)\n",
    "        file_count = len(os.listdir(current_directory))\n",
    "        subdirectory_names.append(subdirectory)\n",
    "        subdirectory_file_counts.append(file_count)\n",
    "    \n",
    "    return subdirectory_names, subdirectory_file_counts\n",
    "         \n",
    "    \n",
    "def reset_plot_propert(plot_property=None):\n",
    "    plot_property = {\n",
    "        'figsize':(15, 5),\n",
    "        'title':'title',\n",
    "        'xlabel': None,\n",
    "        'ylabel': None,\n",
    "        'legend': None,\n",
    "        'title_fontsize' : 18,\n",
    "        'label_fontsize':14, \n",
    "        'subplot':None}\n",
    "    return plot_property\n",
    "\n",
    "# show barplot\n",
    "def bar_plot(x, y, plot_property):\n",
    "    if plot_property['subplot']:\n",
    "        plt.subplot(plot_property['subplot'])\n",
    "    sns.barplot(x=x, y=y)\n",
    "    plt.title(plot_property['title'], fontsize=plot_property['title_fontsize'])\n",
    "    plt.xlabel(plot_property['xlabel'], fontsize=plot_property['label_fontsize'])\n",
    "    plt.ylabel(plot_property['ylabel'], fontsize=plot_property['label_fontsize'])\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a directory\n",
    "def count_bar_plot(master_directory, plot_property):\n",
    "    dir_name, dir_file_count = subdirectory_file_count(master_directory)\n",
    "    x=dir_name\n",
    "    y=dir_file_count\n",
    "    bar_plot(x, y, plot_property)\n",
    "    \n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a training, validation, testing directory    \n",
    "def show_train_val_test(training_dir, validation_dir, testing_dir, plot_property):\n",
    "    plt.figure(figsize=plot_property['figsize'])\n",
    "    \n",
    "    title = plot_property['title']\n",
    "    plot_property['title'] = title +\" (Training)\"\n",
    "    subplot_no = plot_property['subplot'] \n",
    "\n",
    "    count_bar_plot(training_dir, plot_property)\n",
    "    \n",
    "    \n",
    "    plot_property['title'] = title +\" (Validation)\"\n",
    "    plot_property['subplot'] = subplot_no+1\n",
    "    count_bar_plot(validation_dir, plot_property)\n",
    "    \n",
    "    \n",
    "    plot_property['title'] = title +\" (Testing)\"\n",
    "    plot_property['subplot'] = subplot_no+2\n",
    "    count_bar_plot(testing_dir, plot_property)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches)\n",
    "def get_transformed_image_batch(directory, image_transform_params, batch_params):       \n",
    "    if x==1:\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center = image_transform_params['featurewise_center'], \n",
    "            samplewise_center = image_transform_params['samplewise_center'], \n",
    "            featurewise_std_normalization = image_transform_params['featurewise_std_normalization'],\n",
    "            samplewise_std_normalization = image_transform_params['samplewise_std_normalization'], \n",
    "            zca_whitening = image_transform_params['zca_whitening'], \n",
    "            zca_epsilon = image_transform_params['zca_epsilon'], \n",
    "            rotation_range = image_transform_params['rotation_range'], \n",
    "            width_shift_range = image_transform_params['width_shift_range'], \n",
    "            height_shift_range = image_transform_params['height_shift_range'], \n",
    "            brightness_range = image_transform_params['brightness_range'], \n",
    "            shear_range = image_transform_params['shear_range'], \n",
    "            zoom_range = image_transform_params['zoom_range'], \n",
    "            channel_shift_range = image_transform_params['channel_shift_range'], \n",
    "            fill_mode = image_transform_params['fill_mode'], \n",
    "            cval = image_transform_params['cval'], \n",
    "            horizontal_flip = image_transform_params['horizontal_flip'], \n",
    "            vertical_flip = image_transform_params['vertical_flip'], \n",
    "            rescale = image_transform_params['rescale'], \n",
    "            preprocessing_function = image_transform_params['preprocessing_function'], \n",
    "            data_format = image_transform_params['data_format'],\n",
    "            validation_split = image_transform_params['validation_split'], \n",
    "            dtype = image_transform_params['dtype'])     \n",
    "    \n",
    "    else:\n",
    "        datagen = ImageDataGenerator(\n",
    "            shear_range = image_transform_params['shear_range'], \n",
    "            zoom_range = image_transform_params['zoom_range'], \n",
    "            horizontal_flip = image_transform_params['horizontal_flip'], \n",
    "            rescale = image_transform_params['rescale'])  \n",
    "    \n",
    "    if x==1:\n",
    "        image_generator = datagen.flow_from_directory(\n",
    "            directory,\n",
    "            target_size=batch_params['target_size'],\n",
    "            color_mode=batch_params['color_mode'],\n",
    "            classes = batch_params['classes'],\n",
    "            class_mode=batch_params['class_mode'],\n",
    "            batch_size=batch_params['batch_size'],\n",
    "            shuffle=batch_params['shuffle'],\n",
    "            seed=batch_params['seed'],\n",
    "            save_to_dir=batch_params['save_to_dir'], \n",
    "            save_prefix=batch_params['save_prefix'],\n",
    "            save_format=batch_params['save_format'],\n",
    "            follow_links=batch_params['follow_links'], \n",
    "            subset=batch_params['subset'],\n",
    "            interpolation=batch_params['interpolation'])\n",
    "        \n",
    "    else:\n",
    "        image_generator = datagen.flow_from_directory(\n",
    "            directory,\n",
    "            target_size=batch_params['target_size'],\n",
    "            classes = batch_params['classes'],\n",
    "            class_mode=batch_params['class_mode'],\n",
    "            batch_size=batch_params['batch_size'],\n",
    "            shuffle=batch_params['shuffle'])\n",
    "    \n",
    "    return image_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Label Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust class weights for imbalanced dataset of classes of images\n",
    "def get_class_weight(y):\n",
    "    counter = Counter(y)                          \n",
    "    max_val = float(max(counter.values()))     \n",
    "    class_weight = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Graph Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tensorflow graph tp free up memory and resource allocation \n",
    "def reset_graph(model=None):\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# reset callbacks \n",
    "def reset_callbacks(checkpoint=None, reduce_lr=None, early_stopping=None, tensorboard=None):\n",
    "    checkpoint=None\n",
    "    reduce_lr = None\n",
    "    early_stopping = None\n",
    "    tensorboard = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization Function\n",
    "#### Load and Configure Model Function InceptionV3 for Fine-Tuning with New Class Labels\n",
    "<p>1. Imports Pretrained model InceptionV3 <br>\n",
    "   2. Disabled training on first few layers <br>\n",
    "   3. Enabled training on top and output layers<br>\n",
    "   4. Adjust output Dense Layer to number of Image Classes <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and configure model InceptionV3 for fine-tuning with new class labels\n",
    "def get_inception_model(train_generator, validation_generator, model_obj, training_obj, callbacks):    \n",
    "    # create the base pre-trained model\n",
    "    if model_obj['model_name'] == 'InceptionV3':\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=model_obj['include_top'])\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    # Setting model layers specially output layer with class number\n",
    "    x = base_model.output\n",
    "    \n",
    "#     x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    # and a logistic layer -- let's say we have 2 classes\n",
    "\n",
    "    # softmax for multi-class\n",
    "    predictions = Dense(num_class, activation=activation['activation'])(x) \n",
    "    \n",
    "    # sigmoid for 2 class or binary class\n",
    "    # predictions = Dense(num_class, activation='sigmoid')(x) \n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "     \n",
    "\n",
    "\n",
    "    \n",
    "    if callbacks:\n",
    "        # compile model with loss, optimizer and metrics \n",
    "        model.compile(model_obj['optimizer'], loss=model_obj['loss'], metrics=model_obj['metrics'])\n",
    "\n",
    "        callbacks['tensorboard'].set_model(model) \n",
    "    \n",
    "        # train the model on the new data for a few epochs\n",
    "        model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch = training_obj['steps_per_epoch'],\n",
    "            epochs=training_obj['epochs'],\n",
    "            # verbose=training_obj['verbose'], \n",
    "            callbacks=training_obj['callbacks'],\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=training_obj['validation_steps'],\n",
    "            class_weight = training_obj['class_weight'],\n",
    "            # max_queue_size = training_obj['max_queue_size'], \n",
    "            # workers = training_obj['workers'], \n",
    "            # use_multiprocessing = training_obj['use_multiprocessing'], \n",
    "            # shuffle = training_obj['shuffle'], \n",
    "            initial_epoch = training_obj['initial_epoch'])\n",
    "\n",
    "    # at this point, the top layers are well trained and we can start fine-tuning\n",
    "    # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "    # and train the remaining top layers.\n",
    "\n",
    "    # let's visualize layer names and layer indices to see how many layers\n",
    "    # we should freeze:\n",
    "    if model_obj['print_layers']:\n",
    "        for i, layer in enumerate(base_model.layers):\n",
    "            print(i, layer.name)\n",
    "\n",
    "    # Freeze or set first few layers as untrainable\n",
    "    # Unfreeze or set rest of the layers as trainable\n",
    "    for layer in model.layers[:model_obj['non_trainable_index']]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[model_obj['non_trainable_index']:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    if not callbacks:\n",
    "        model.compile(model_obj['optimizer'], loss=model_obj['loss'], metrics=model_obj['metrics'])\n",
    "        \n",
    "        model_obj['tensorboard'].set_model(model) \n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Performance Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation performance\n",
    "def plot_history(history, plot_val, plot_property):\n",
    "    plt.figure(figsize=plot_property['figsize'])\n",
    "    \n",
    "    plt.subplot(plot_property['subplot'][0])\n",
    "    \n",
    "    plt.plot(history.history[plot_val[0][0]])\n",
    "    plt.plot(history.history[plot_val[0][1]])\n",
    "    \n",
    "    plt.title(plot_property['title'][0], fontsize=plot_property['title_fontsize'])\n",
    "    plt.xlabel(plot_property['xlabel'][0], fontsize=plot_property['label_fontsize'])\n",
    "    plt.ylabel(plot_property['ylabel'][0], fontsize=plot_property['label_fontsize'])\n",
    "    \n",
    "    plt.legend(plot_property['legend'][0], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(plot_property['subplot'][1])\n",
    "    \n",
    "    plt.plot(history.history[plot_val[1][0]])\n",
    "    plt.plot(history.history[plot_val[1][1]])\n",
    "    \n",
    "    plt.title(plot_property['title'][1], fontsize=plot_property['title_fontsize'])\n",
    "    plt.ylabel(plot_property['ylabel'][1], fontsize=plot_property['label_fontsize'])\n",
    "    plt.xlabel(plot_property['xlabel'][1], fontsize=plot_property['label_fontsize'])\n",
    "    \n",
    "    plt.legend(plot_property['legend'][1], loc='upper left')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Performance Report Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, test_generator, print_report=False):\n",
    "    if len(test_generator)>1:\n",
    "        result = model.evaluate_generator(generator=test_generator, steps=len(test_generator))\n",
    "    else:\n",
    "        result = model.evaluate_generator(generator=test_generator, steps=len(test_generator), verbose=1)\n",
    "        \n",
    "    \n",
    "    accuracy = result[1]*100\n",
    "    loss = result[0]\n",
    "    \n",
    "    if print_report:\n",
    "        print(\"%s%.2f%s\"% (\"Accuracy: \", accuracy, \"%\"))\n",
    "        print(\"%s%.2f\"% (\"Loss: \", loss))\n",
    "    \n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "def predict_report(model, test_generator, classes, print_report=False):\n",
    "    if len(test_generator)>1:\n",
    "        y_preds = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "    else:\n",
    "        y_preds = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "        \n",
    "        \n",
    "    y_classes = y_preds.argmax(axis=-1)\n",
    "    \n",
    "\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    \n",
    "    cls_report_print = classification_report(test_generator.classes, y_classes, target_names=classes)\n",
    "    \n",
    "    cls_report = classification_report(test_generator.classes, y_classes, target_names=classes, output_dict=True)\n",
    "    \n",
    "    if print_report: \n",
    "        print(cls_report_print)\n",
    "        \n",
    "    return y_preds, y_classes, CM, cls_report, cls_report_print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse classification report for reporting negetive classes (0)\n",
    "def reverse_pos_neg(CM, print_bool):\n",
    "    tp=CM[0][0]\n",
    "    fp=CM[0][1]\n",
    "    fn=CM[1][0]\n",
    "    tn=CM[1][1]\n",
    "    \n",
    "    if print_bool:\n",
    "        print(tp, fp, tn, fn, tn)\n",
    "        \n",
    "    return [tp, fp, tn, fn, tn]\n",
    "\n",
    "# reverse and report classification report for reporting negetive classes (0)\n",
    "def report(CM, reverse):\n",
    "    if not reverse:\n",
    "        tn, fp, fn, tp = CM.ravel()\n",
    "\n",
    "    else:\n",
    "        tp=CM[0][0]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        tn=CM[1][1]\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "    print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_over_epochs(array, plot_obj):\n",
    "    x_axis_arr = np.arange(len(array))\n",
    "    \n",
    "    if plot_obj['subplot']:\n",
    "        plt.subplot(plot_obj['subplot'])\n",
    "        \n",
    "    plt.title(plot_obj['title'], fontsize=plot_obj['title_fontsize'])\n",
    "    plt.plot(x_axis_arr, array)\n",
    "    plt.xlabel(plot_obj['xlabel'], fontsize=plot_obj['label_fontsize'])\n",
    "    plt.ylabel(plot_obj['ylabel'], fontsize=plot_obj['label_fontsize'])\n",
    "    \n",
    "def line_plot_over_epochs_loss_acc(array, plot_obj):\n",
    "    plt.figure(figsize=plot_obj['fig_size'])\n",
    "    \n",
    "    title = plot_obj['title']\n",
    "    xlabel=plot_obj['xlabel']\n",
    "    ylabel=plot_obj['ylabel']\n",
    "    subplot_no=plot_obj['subplot']\n",
    "    \n",
    "    plot_obj['title'] = title[0]\n",
    "    plot_obj['xlabel'] = xlabel[0]\n",
    "    plot_obj['ylabel'] = ylabel[0]\n",
    "    plot_obj['subplot'] = subplot_no[0]\n",
    "    \n",
    "    line_plot_over_epochs(array[0], plot_obj)\n",
    "    \n",
    "    plot_obj['title'] = title[1]\n",
    "    plot_obj['xlabel'] = xlabel[1]\n",
    "    plot_obj['ylabel'] = ylabel[1]\n",
    "    plot_obj['subplot'] = subplot_no[1]\n",
    "    \n",
    "    line_plot_over_epochs(array[1], plot_obj)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def show_confusion_matrix(test_generator, y_classes, classes, figsize=(10,8), stick_fontsize=12):\n",
    "    CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "    \n",
    "    fig, ax = plot_confusion_matrix(\n",
    "        conf_mat=CM ,  \n",
    "        figsize=figsize, \n",
    "        hide_ticks=True,cmap=plt.cm.Blues)\n",
    "    \n",
    "    plt.xticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    plt.yticks(range(len(classes)), classes, fontsize=stick_fontsize)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_filename, details, report_type, classes, class_name):\n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "        \n",
    "    model_path = model_dir+\"\\\\\"+model_filename\n",
    "        \n",
    "    if not os.path.isdir(model_path):\n",
    "        return None\n",
    "    \n",
    "    reset_graph(model)\n",
    "\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "    accuracy, loss =  model_evaluate(\n",
    "        model, \n",
    "        test_generator, \n",
    "        print_report=False)\n",
    "    \n",
    "    y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes)\n",
    "\n",
    "\n",
    "    precision = cls_report[class_name]['precision'] *100\n",
    "    recall =  cls_report[class_name]['recall'] *100\n",
    "    f1_score =  cls_report['weighted avg']['f1-score'] *100\n",
    "\n",
    "\n",
    "\n",
    "    results1[model_filename] = [accuracy, loss]\n",
    "    results2[model_filename] = [CM, cls_report, cls_report_print]\n",
    "\n",
    "    print(\"%s%s\"%(\"Model File: \", model_filename))\n",
    "    print(\"*\"*80)\n",
    "    show_confusion_matrix(test_generator, y_classes, classes)\n",
    "    print(cls_report_print)\n",
    "    print(\"%s%.2f%s\"% (\"Current Accuracy: \", accuracy, \"%\"))\n",
    "    print(\"%s%.2f\"% (\"Current Loss: \", loss))\n",
    "    print(\"%s%.2f%s\"% (\"Current Precision: \", precision, \"%\"))\n",
    "    print(\"%s%.2f%s\"% (\"Current Recall: \", recall, \"%\"))\n",
    "    print(\"%s%.2f%s\"% (\"Current F1_score: \", f1_score, \"%\"))\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    \n",
    "    print(\"Testing dataset evaluation and prediction report generation complete\")\n",
    "\n",
    "    report = {\"Accuracy\" : accuracy, \n",
    "              \"Loss\" : loss,\n",
    "              \"Precision\" : precision,\n",
    "              \"Recall\": recall,\n",
    "              \"F1-Score\":f1_score}\n",
    "\n",
    "\n",
    "    return results1, results2, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_models(model_dir, details, report_type, classes, class_name):\n",
    "    results1 = {}\n",
    "    results2 = {}\n",
    "    \n",
    "    filenames=[]\n",
    "    \n",
    "    accuracy_list=[]\n",
    "    loss_list=[]\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    f1_score_list=[]\n",
    "    \n",
    "    \n",
    "    best_accuracy=0\n",
    "    best_accuracy_file=\"\"\n",
    "    \n",
    "    best_loss=1000\n",
    "    best_loss_file=\"\"\n",
    "    \n",
    "    \n",
    "    best_precision=0\n",
    "    best_precision_file=\"\"\n",
    "    \n",
    "    best_recall=0\n",
    "    best_recall_file=\"\"\n",
    "    \n",
    "    best_f1_score=0\n",
    "    best_f1_score_file=\"\"\n",
    "    \n",
    "\n",
    "    model_files = os.listdir(model_dir)\n",
    "    \n",
    "    model = None\n",
    "    reset_graph(model)\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for model_filename in model_files:\n",
    "        \n",
    "        model_path = model_dir+\"\\\\\"+model_filename\n",
    "        \n",
    "        if not os.path.isdir(model_path):\n",
    "            reset_graph(model)\n",
    "\n",
    "            model = keras.models.load_model(model_path)\n",
    "            \n",
    "            current_accuracy, current_loss =  model_evaluate(model, test_generator, print_report=False)\n",
    "            y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes)\n",
    "\n",
    "            \n",
    "            current_precision = cls_report[class_name]['precision'] *100\n",
    "            current_recall =  cls_report[class_name]['recall'] *100\n",
    "            current_f1_score =  cls_report['weighted avg']['f1-score'] *100\n",
    "            \n",
    "            filenames.append(model_file)\n",
    "            \n",
    "            accuracy_list.append(current_accuracy)\n",
    "            loss_list.append(current_loss)\n",
    "            \n",
    "            precision_list.append(current_precision)\n",
    "            recall_list.append(current_recall)\n",
    "            f1_score_list.append(current_f1_score)\n",
    "            \n",
    "            \n",
    "            results1[model_filename] = [current_accuracy, current_loss]\n",
    "            results2[model_filename] = [CM, cls_report, cls_report_print]\n",
    "\n",
    "                \n",
    "            if current_accuracy>=best_accuracy:\n",
    "                best_accuracy=current_accuracy\n",
    "                best_accuracy_file=model_filename\n",
    "\n",
    "            if current_loss<=best_loss:\n",
    "                best_loss=current_loss\n",
    "                best_loss_file=model_filename\n",
    "                \n",
    "            \n",
    "            if current_precision>=best_precision:\n",
    "                best_precision=current_precision\n",
    "                best_precision_file=model_filename\n",
    "\n",
    "            if current_recall>=best_recall:\n",
    "                best_recall=current_recall\n",
    "                best_recall_file=model_filename\n",
    "                \n",
    "            if current_f1_score>=best_f1_score:\n",
    "                best_f1_score=current_f1_score\n",
    "                best_f1_score_file=model_filename\n",
    "                    \n",
    "\n",
    "            if details or i%5==0:\n",
    "                print(\"%s%s\"%(\"Model No: \", i+1))\n",
    "                print(\"%s%s\"%(\"Model File: \", model_filename))\n",
    "                print(\"*\"*80)\n",
    "                show_confusion_matrix(test_generator, y_classes, classes)\n",
    "                print(cls_report_print)\n",
    "                print(\"%s%.2f%s\"% (\"Current Accuracy: \", current_accuracy, \"%\"))\n",
    "                print(\"%s%.2f\"% (\"Current Loss: \", current_loss))\n",
    "                print(\"%s%.2f%s\"% (\"Current Precision: \", current_precision, \"%\"))\n",
    "                print(\"%s%.2f%s\"% (\"Current Recall: \", current_recall, \"%\"))\n",
    "                print(\"%s%.2f%s\"% (\"Current F1_score: \", current_f1_score, \"%\"))\n",
    "\n",
    "                print(\"-\"*80)\n",
    "                print(\"-\"*80)\n",
    "\n",
    "            i+=1\n",
    "    print(\"Testing dataset evaluation and prediction report generation complete\")\n",
    "    \n",
    "    report = {\"Best Accuracy\" : [best_accuracy, best_accuracy_file], \n",
    "                   \"Best Loss\" : [best_loss, best_loss_file],\n",
    "                   \"Best Precision\" : [best_precision, best_precision_file],\n",
    "                   \"Best Recall\": [best_recall, best_recall_file],\n",
    "                   \"Best F1-Score\":[best_f1_score, best_f1_score_file]}\n",
    "    \n",
    "    \n",
    "    return results1, results2, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-06 01:50:34\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-23dd3853590a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdate_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mreset_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "x=1\n",
    "date_time(x)\n",
    "reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path for Train, Validation and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input/ output directory\n",
    "# Configure training, validation, testing directory\n",
    "\n",
    "input_directory = r\"data/input/\"\n",
    "output_directory = r\"data/output/\"\n",
    "\n",
    "training_dir = input_directory+ r\"train\"\n",
    "validation_dir = input_directory+ r\"val\"\n",
    "testing_dir = input_directory+ r\"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_property = reset_plot_propert(plot_property=None)\n",
    "\n",
    "plot_property['figsize'] = (18,4)\n",
    "\n",
    "plot_property['title_fontsize']=13\n",
    "plot_property['label_fontsize']=13\n",
    "\n",
    "plot_property['title'] = \"Number of Cases\"\n",
    "\n",
    "plot_property['xlabel']=\"Labels\"\n",
    "plot_property['ylabel']=\"Count\"\n",
    "\n",
    "plot_property['subplot']=131\n",
    "\n",
    "show_train_val_test(training_dir, validation_dir, testing_dir, plot_property)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (Image Preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuring Image Transformation Parameters for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Image normalization\n",
    "#----------------------#\n",
    "norm=255.0\n",
    "\n",
    "# recscaling\n",
    "#----------------------#\n",
    "rescale=1./norm\n",
    "\n",
    "\n",
    "\n",
    "#Image Augmentation/ Preprocessing before training\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Image Data Generator\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.preprocessing.image.ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, zca_whitening=False, zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.0, height_shift_range=0.0, brightness_range=None, shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0, fill_mode='nearest', cval=0.0, horizontal_flip=False, vertical_flip=False, rescale=None, preprocessing_function=None, data_format=None, validation_split=0.0, dtype=None)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Parameters\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "def reset_image_augmentation_params():\n",
    "    image_transform_params = {\n",
    "        'featurewise_center' : False, \n",
    "        'samplewise_center' : False, \n",
    "        'featurewise_std_normalization' : False, \n",
    "        'samplewise_std_normalization' : False, \n",
    "        'zca_whitening' : False, \n",
    "        'zca_epsilon' : 1e-06, \n",
    "        'rotation_range' : 0,\n",
    "        'width_shift_range' : 0.0, \n",
    "        'height_shift_range' : 0.0, \n",
    "        'brightness_range' : None, \n",
    "        'shear_range' : 0.0, \n",
    "        'zoom_range' : 0.0, \n",
    "        'channel_shift_range' : 0.0, \n",
    "        'fill_mode' : 'nearest', \n",
    "        'cval' : 0.0, \n",
    "        'horizontal_flip' : False, \n",
    "        'vertical_flip' : False, \n",
    "        'rescale' : None, \n",
    "        'preprocessing_function' : None, \n",
    "        'data_format' : None, \n",
    "        'validation_split' : 0.0, \n",
    "        'dtype' : None\n",
    "    }\n",
    "    return image_transform_params\n",
    "\n",
    "\n",
    "def reset_image_augmentation_params_pneumonia():\n",
    "    if x==1:\n",
    "        image_transform_params = reset_image_augmentation_params()\n",
    "        image_transform_params['rescale'] = rescale\n",
    "    \n",
    "    else:\n",
    "        image_transform_params = {\n",
    "            'rescale' : rescale\n",
    "        }\n",
    "    return image_transform_params\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Batch Generator\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# flow_from_directory(directory, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png', follow_links=False, subset=None, interpolation='nearest')\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Parameters\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "def reset_batch_params():\n",
    "    batch_params = {\n",
    "        'target_size' : (256, 256),\n",
    "        'color_mode':'rgb',\n",
    "        'classes' : None,\n",
    "        'class_mode':'categorical',\n",
    "        'batch_size' : 32,\n",
    "        'shuffle':True,\n",
    "        'seed':None,\n",
    "        'save_to_dir':None, \n",
    "        'save_prefix':'',\n",
    "        'save_format':'png', \n",
    "        'follow_links':False, \n",
    "        'subset':None, \n",
    "        'interpolation':'nearest'\n",
    "    }\n",
    "    \n",
    "    return batch_params\n",
    "\n",
    "\n",
    "def reset_batch_params_pneumonia(x=1):\n",
    "    if x==1:\n",
    "        batch_params = reset_batch_params()\n",
    "        \n",
    "        batch_params['target_size'] = (299, 299)\n",
    "        batch_params['classes'] = ['Normal', 'Cancer']\n",
    "        batch_params['class_mode']='categorical'\n",
    "        batch_params['batch_size'] = 128\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        batch_params = {\n",
    "            'target_size' : (299, 299),\n",
    "            'classes' : ['Normal', 'Cancer'],\n",
    "            'class_mode':'categorical',\n",
    "            'batch_size' : 128,\n",
    "            'shuffle':True\n",
    "        }\n",
    "\n",
    "    \n",
    "    return batch_params\n",
    "\n",
    "\n",
    "batch_params = reset_batch_params_pneumonia()\n",
    "image_transform_params = reset_image_augmentation_params_pneumonia()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation for Training, Validation, Testing and  Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1341 images belonging to 2 classes.\n",
      "Found 121 images belonging to 2 classes.\n",
      "Found 121 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_transformed_image_batch(training_dir, image_transform_params, batch_params)       \n",
    "\n",
    "validation_generator = get_transformed_image_batch(validation_dir, image_transform_params, batch_params) \n",
    "\n",
    "batch_params['shuffle'] = False\n",
    "\n",
    "test_generator = get_transformed_image_batch(testing_dir, image_transform_params, batch_params) \n",
    "\n",
    "# print(os.listdir(training_dir))\n",
    "# print(len(os.listdir(training_dir+\"/NORMAL\")))\n",
    "# print(len(os.listdir(training_dir+\"/PNEUMONIA\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight Adjustment for Class Label Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_generator.classes\n",
    "class_weight=get_class_weight(y)\n",
    "# class_weight=None\n",
    "# class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training Configuration\n",
    "### Setting Output Directory (Model and Log) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Model Directory\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "model_dir=output_directory + r\"models/\"+time.strftime('%Y-%m-%d %H-%M-%S')+\"/\"\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Log Directory\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "log_dir=output_directory + r\"logs/\"+time.strftime('%Y-%m-%d %H-%M-%S')\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "# Create Output Directory (Model and Log)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "create_directory(model_dir, remove=True)\n",
    "create_directory(log_dir, remove=True)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Model File Name Configuration\n",
    "#------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Initial Trainning Model Filename \n",
    "#----------------------------------------------------------------------------------------------------#\n",
    "init_model_file=model_dir+\"base-\"+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Trainning Model Filename \n",
    "#----------------------------------------------------------------------------------------------------#\n",
    "model_file=model_dir+\"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Retrainning Model Filename \n",
    "#----------------------------------------------------------------------------------------------------#\n",
    "retrain_model_file=model_dir+\"retrain-{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"\n",
    "#--------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model Configuration\n",
    "\n",
    "#### Base Model - InceptionV3 (pretrained) initial training settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\n",
    "    'include_top': False,\n",
    "    'non_trainable_index':249,\n",
    "    'print_layers': False\n",
    "}\n",
    "training_params = { \n",
    "    'epochs':15,\n",
    "    'init_verbose': 0,\n",
    "    'metrics': None,\n",
    "    'optimizer' = optimizers.Adam(),\n",
    "    'callbacks': None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning Parameters\n",
    "##### Settings for Loss, Optimizer and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Optimizer\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Optimizers\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "# Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "# Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "# Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "# Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Format\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.optimizers.X\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Optimizer\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# learning rate = 1.0/0.1/0.01/0.001/0.0001/0.00001/0.000001\n",
    "# Decay = decay=1e-5/ 1e-6\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_optimizer=optimizers.Adam()\n",
    "optimizer=optimizers.Adam()\n",
    "ret_optimizer=optimizers.Adam()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# loss Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Loss Functions\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# 'mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 'mean_squared_logarithmic_error',\n",
    "# 'squared_hinge', 'hinge', 'categorical_hinge', 'logcosh',\n",
    "# 'categorical_crossentropy', 'sparse_categorical_crossentropy', 'binary_crossentropy',\n",
    "# 'kullback_leibler_divergence', 'poisson', 'cosine_proximity'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Format\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.loss.X ??\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Optimizers\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_loss='categorical_crossentropy'\n",
    "loss='categorical_crossentropy'\n",
    "ret_loss='categorical_crossentropy'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Performance Metrics\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Metrics\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# 'binary_accuracy', 'categorical_accuracy', 'sparse_categorical_accuracy', \n",
    "# 'top_k_categorical_accuracy', 'sparse_top_k_categorical_accuracy\n",
    "# None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Format\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.metrics.X\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Optimizers\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_metrics=['accuracy']\n",
    "metrics=['accuracy']\n",
    "ret_metrics=['accuracy']\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_pred(y_true, y_pred):\n",
    "#     return K.mean(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning Parameters (Epochs, Steps, Verbose)\n",
    "#### Main model training parameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Epochs\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# epochs = 10/20/30/50\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Number of Epochs\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_epochs = 10\n",
    "epochs = 10\n",
    "ret_epochs = 10\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Steps\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Trainning Steps\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available\n",
    "# steps_per_epoch=60/600\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Steps Per Epoch\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_steps_per_epoch=len(train_generator)\n",
    "steps_per_epoch=len(train_generator)\n",
    "ret_steps_per_epoch=len(train_generator)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Validation Steps\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# validation_steps=1/20/200\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Validation Per Epoch\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_validation_steps=len(validation_generator)\n",
    "validation_steps=len(validation_generator)\n",
    "ret_validation_steps=len(validation_generator)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Verbose\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# 0=nothing \n",
    "# 1=each line\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Verbose\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_verbose=1\n",
    "verbose=1\n",
    "ret_verbose=1\n",
    "#--------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks (Configuration and Function Call)\n",
    "#### Important  - ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "#### Others - BaseLogger, TerminateOnNaN , ProgbarLogger,  History, LearningRateScheduler, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Base Logger\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.BaseLogger(stateful_metrics=None)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "base_logger_stateful_metrics=None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "base_logger = keras.callbacks.BaseLogger(stateful_metrics=base_logger_stateful_metrics)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# TerminateOnNaN\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.TerminateOnNaN()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "terminate_on_NaN = keras.callbacks.TerminateOnNaN()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Proggress Bar Logger\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.ProgbarLogger(count_mode='samples', stateful_metrics=None)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "progbar_logger_count_mode='samples'\n",
    "progbar_logger_stateful_metrics=None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "progbar_logger = keras.callbacks.ProgbarLogger(\n",
    "    count_mode=progbar_logger_count_mode, \n",
    "    stateful_metrics=progbar_logger_stateful_metrics)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# History\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.History()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "history = keras.callbacks.History()\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Model Checkpoint\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.ModelCheckpoint()\n",
    "# ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)#\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# monitor='val_loss'\n",
    "# verbose=0\n",
    "# save_best_only=False\n",
    "# save_weights_only=False\n",
    "# mode='auto'\n",
    "# period=1\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "filepath = model_file\n",
    "ck_monitor='val_loss'\n",
    "ck_verbose=1\n",
    "ck_save_best_only=False\n",
    "ck_save_weights_only=False\n",
    "ck_mode='auto'\n",
    "ck_period=1\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=model_file,\n",
    "    monitor=ck_monitor, \n",
    "    verbose=ck_verbose,\n",
    "    save_best_only=ck_save_best_only, \n",
    "    save_weights_only=ck_save_weights_only, \n",
    "    mode=ck_mode, \n",
    "    period=ck_period)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Early Stopping\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# monitor='val_loss'\n",
    "# min_delta=0\n",
    "# patience=0\n",
    "# verbose=0\n",
    "# mode='auto'\n",
    "# baseline=None\n",
    "# restore_best_weights=False\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "es_monitor = 'val_loss'\n",
    "es_min_delta=0\n",
    "es_patience=5\n",
    "es_verbose=1\n",
    "es_mode='auto'\n",
    "es_baseline=None\n",
    "restore_best_weights=False\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_early_stopping = EarlyStopping(\n",
    "    monitor=es_monitor, \n",
    "    min_delta=es_min_delta, \n",
    "    patience=es_patience, \n",
    "    verbose=es_verbose, \n",
    "    mode=es_mode, \n",
    "    baseline=es_baseline)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=es_monitor, \n",
    "    min_delta=es_min_delta, \n",
    "    patience=es_patience, \n",
    "    verbose=es_verbose, \n",
    "    mode=es_mode, \n",
    "    baseline=es_baseline)\n",
    "\n",
    "ret_early_stopping = EarlyStopping(\n",
    "    monitor=es_monitor, \n",
    "    min_delta=es_min_delta, \n",
    "    patience=es_patience, \n",
    "    verbose=es_verbose, \n",
    "    mode=es_mode, \n",
    "    baseline=es_baseline)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Learning Rate Scheduler\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.LearningRateScheduler(schedule, verbose=0)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "lr_schedule = None\n",
    "lr_scheduler_verbose=0\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# learning_rate_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, lr_scheduler_verbose=0)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Tensorboard\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# log_dir='./logs' \n",
    "# histogram_freq=0 \n",
    "# batch_size=32\n",
    "# write_graph=True\n",
    "# write_grads=False\n",
    "# write_images=False \n",
    "# embeddings_freq=0\n",
    "# embeddings_layer_names=None\n",
    "# embeddings_metadata=None\n",
    "# embeddings_data=None\n",
    "# update_freq='epoch'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "tb_log_dir=log_dir\n",
    "tb_histogram_freq=0\n",
    "tb_batch_size=batch_params['batch_size']\n",
    "tb_write_graph=True\n",
    "tb_write_grads=False\n",
    "tb_write_images=False\n",
    "tb_embeddings_freq=0\n",
    "tb_embeddings_layer_names=None\n",
    "tb_embeddings_metadata=None\n",
    "tb_embeddings_data=None\n",
    "update_freq='epoch'\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir=tb_log_dir, \n",
    "    histogram_freq=tb_histogram_freq, \n",
    "    batch_size=tb_batch_size,\n",
    "    write_graph=tb_write_graph, \n",
    "    write_grads=tb_write_grads, \n",
    "    write_images=tb_write_images,\n",
    "    embeddings_freq=tb_embeddings_freq,\n",
    "    embeddings_layer_names=tb_embeddings_layer_names, \n",
    "    embeddings_metadata=tb_embeddings_metadata, \n",
    "    embeddings_data=tb_embeddings_data)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# CSV Logger\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "CSV_logger_filename = log_dir+ \"\\\\csv_logger.csv\"\n",
    "CSV_logger_separator=','\n",
    "CSV_logger_append=False\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "CSV_logger = keras.callbacks.CSVLogger(\n",
    "    CSV_logger_filename, \n",
    "    separator=CSV_logger_separator,\n",
    "    append=CSV_logger_append)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Reduce Learning Rate On Plateau\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Default Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# monitor='val_loss'\n",
    "# factor=0.1\n",
    "# patience=10\n",
    "# verbose=0\n",
    "# mode='auto'\n",
    "# min_delta=0.0001\n",
    "# cooldown=0\n",
    "# min_lr=0\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Selected Settings\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "red_lr_monitor='val_loss'\n",
    "red_lr_factor=0.1 # default\n",
    "# red_lr_factor=0.5\n",
    "# red_lr_patience=5\n",
    "red_lr_patience=2\n",
    "red_lr_verbose=1\n",
    "red_lr_mode='auto'\n",
    "red_lr_min_delta=0.0001\n",
    "red_lr_cooldown=0\n",
    "red_lr_min_lr=0.0\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Call Function\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=red_lr_monitor, \n",
    "    factor=red_lr_factor, \n",
    "    patience=red_lr_patience,\n",
    "    verbose=red_lr_verbose, \n",
    "    mode=red_lr_mode, \n",
    "    min_delta=red_lr_min_delta,\n",
    "    cooldown=red_lr_cooldown,\n",
    "    min_lr=red_lr_min_lr)\n",
    "\n",
    "ret_reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=red_lr_monitor, \n",
    "    factor=red_lr_factor, \n",
    "    patience=red_lr_patience,\n",
    "    verbose=red_lr_verbose, \n",
    "    mode=red_lr_mode, \n",
    "    min_delta=red_lr_min_delta,\n",
    "    cooldown=red_lr_cooldown,\n",
    "    min_lr=red_lr_min_lr)\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks Selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Available Callbacks\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# base_logger \n",
    "# terminate_on_NaN \n",
    "# progbar_logger \n",
    "# history \n",
    "# checkpoint \n",
    "# early_stopping\n",
    "# tensorboard \n",
    "# CSV_logger \n",
    "# reduce_lr\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Format\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# callbacks = None\n",
    "# callbacks = [checkpoint, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "# callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard, history]\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Initial Model\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "init_callbacks = None\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Main Model\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "# Retrain Model\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n",
    "retrain_callbacks = [checkpoint, ret_reduce_lr, ret_early_stopping, tensorboard]\n",
    "#--------------------------------------------------------------------------------------------------------------------#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-06 02:05:20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_inception_model() takes 5 positional arguments but 13 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-87a8bf84e1ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mnon_trainable_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     print_layers)\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mmain_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_inception_model() takes 5 positional arguments but 13 were given"
     ]
    }
   ],
   "source": [
    "# get inception model\n",
    "date_time(1)\n",
    "\n",
    "model = get_inception_model(train_generator, validation_generator, model_obj, training_obj, callbacks)\n",
    "\n",
    "main_model = model\n",
    "\n",
    "date_time(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model Performance with Minimum Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_report=True\n",
    "\n",
    "# y_preds, y_classes, CM, CM_report, cls_report_print = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "# accuracy, loss =  model_evaluate(model, test_generator, print_report)\n",
    "# print(accuracy, loss)\n",
    "# res=show_confusion_matrix(test_generator, y_classes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Base Model for Fine-Tuning with New Class Labels\n",
    "#### Fine-Tuning InceptionV3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-05 02:01:45\n",
      "Epoch 1/10\n",
      "1032/1032 [==============================] - 7189s 7s/step - loss: 0.2989 - acc: 0.9014 - val_loss: 2.2894 - val_acc: 0.6004\n",
      "\n",
      "Epoch 00001: saving model to data/output/models/2018-12-05 01-57-41/01-val_acc-0.60-val_loss-2.29.hdf5\n",
      "Epoch 2/10\n",
      "1032/1032 [==============================] - 7588s 7s/step - loss: 0.2356 - acc: 0.9236 - val_loss: 1.5974 - val_acc: 0.6352\n",
      "\n",
      "Epoch 00002: saving model to data/output/models/2018-12-05 01-57-41/02-val_acc-0.64-val_loss-1.60.hdf5\n",
      "Epoch 3/10\n",
      "1032/1032 [==============================] - 6359s 6s/step - loss: 0.2137 - acc: 0.9316 - val_loss: 2.1584 - val_acc: 0.6165\n",
      "\n",
      "Epoch 00003: saving model to data/output/models/2018-12-05 01-57-41/03-val_acc-0.62-val_loss-2.16.hdf5\n",
      "Epoch 4/10\n",
      "1032/1032 [==============================] - 5512s 5s/step - loss: 0.2004 - acc: 0.9365 - val_loss: 1.5278 - val_acc: 0.6202\n",
      "\n",
      "Epoch 00004: saving model to data/output/models/2018-12-05 01-57-41/04-val_acc-0.62-val_loss-1.53.hdf5\n",
      "Epoch 5/10\n",
      "1032/1032 [==============================] - 5745s 6s/step - loss: 0.1886 - acc: 0.9390 - val_loss: 2.7698 - val_acc: 0.6009\n",
      "\n",
      "Epoch 00005: saving model to data/output/models/2018-12-05 01-57-41/05-val_acc-0.60-val_loss-2.77.hdf5\n",
      "Epoch 6/10\n",
      "1032/1032 [==============================] - 5528s 5s/step - loss: 0.1789 - acc: 0.9426 - val_loss: 1.3426 - val_acc: 0.6231\n",
      "\n",
      "Epoch 00006: saving model to data/output/models/2018-12-05 01-57-41/06-val_acc-0.62-val_loss-1.34.hdf5\n",
      "Epoch 7/10\n",
      "1032/1032 [==============================] - 5575s 5s/step - loss: 0.1706 - acc: 0.9456 - val_loss: 1.7185 - val_acc: 0.6215\n",
      "\n",
      "Epoch 00007: saving model to data/output/models/2018-12-05 01-57-41/07-val_acc-0.62-val_loss-1.72.hdf5\n",
      "Epoch 8/10\n",
      "1032/1032 [==============================] - 6036s 6s/step - loss: 0.1623 - acc: 0.9476 - val_loss: 2.2186 - val_acc: 0.6033\n",
      "\n",
      "Epoch 00008: saving model to data/output/models/2018-12-05 01-57-41/08-val_acc-0.60-val_loss-2.22.hdf5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/10\n",
      "1032/1032 [==============================] - 6879s 7s/step - loss: 0.1363 - acc: 0.9567 - val_loss: 2.5119 - val_acc: 0.6079\n",
      "\n",
      "Epoch 00009: saving model to data/output/models/2018-12-05 01-57-41/09-val_acc-0.61-val_loss-2.51.hdf5\n",
      "Epoch 10/10\n",
      "1032/1032 [==============================] - 6351s 6s/step - loss: 0.1280 - acc: 0.9596 - val_loss: 2.6067 - val_acc: 0.6129\n",
      "\n",
      "Epoch 00010: saving model to data/output/models/2018-12-05 01-57-41/10-val_acc-0.61-val_loss-2.61.hdf5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Timestamp: 2018-12-05 19:32:40\n"
     ]
    }
   ],
   "source": [
    "date_time(1)\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)\n",
    "\n",
    "date_time(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization over the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_val=[['acc', 'val_acc'], ['loss', 'val_loss']]\n",
    "\n",
    "\n",
    "plot_property =  {\n",
    "    'figsize':(15, 5),\n",
    "    'title':['Model accuracy', 'Model loss'],\n",
    "    'xlabel':['Epoch', 'Epoch'],\n",
    "    'ylabel':['Accuracy', 'Loss'],\n",
    "    'legend': ['Train', 'Val'],\n",
    "    'title_fontsize' : 17,\n",
    "    'label_fontsize':15, \n",
    "    'subplot':[121, 122]}\n",
    "\n",
    "\n",
    "plot_history(history, plot_val, plot_property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/344 [==============================] - 498s 1s/step\n"
     ]
    }
   ],
   "source": [
    "result  = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "\n",
    "# y_preds, y_classes, CM, CM_report, cls_report_print = predict_report(model, test_generator, classes, print_report)\n",
    "\n",
    "# accuracy, loss =  model_evaluate(model, test_generator, print_report)\n",
    "# print(accuracy, loss)\n",
    "# res=show_confusion_matrix(test_generator, y_classes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6067435538439625\n",
      "61.29303488835951 %\n"
     ]
    }
   ],
   "source": [
    "print(result[0])\n",
    "print(result[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/344 [==============================] - 838s 2s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes=y_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(10,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.yticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance of All Models on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2018-12-05 21:54:42\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[128,64,147,147] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_3/convolution}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@batch_normalization_3/cond/FusedBatchNorm/Switch\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_2/Relu, conv2d_3/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics/acc/Mean/_4021}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3245_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-07bd0fbba242>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mreport_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"full\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mresults1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_all_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdate_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-050d36fc9877>\u001b[0m in \u001b[0;36mtest_all_models\u001b[1;34m(model_dir, details, report_type, classes, class_name)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mcurrent_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_loss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmodel_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_report\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0my_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_report\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_report_print\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-7578c4a3d570>\u001b[0m in \u001b[0;36mmodel_evaluate\u001b[1;34m(model, test_generator, print_report)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmodel_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_report\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m             verbose=verbose)\n\u001b[0m\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    344\u001b[0m                                  \u001b[1;34m'or (x, y). Found: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                                  str(generator_output))\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[0;32m   1254\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1257\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,64,147,147] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_3/convolution}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@batch_normalization_3/cond/FusedBatchNorm/Switch\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_2/Relu, conv2d_3/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics/acc/Mean/_4021}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3245_metrics/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "date_time(1)\n",
    "\n",
    "details = True\n",
    "class_name = \"Cancer\"\n",
    "\n",
    "report_type = \"full\"\n",
    "results1, results2, report = test_all_models(model_dir, details, report_type, classes, class_name=class_name)\n",
    "\n",
    "date_time(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of  Performance Over All Epochs/Models based on Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename_list=[]\n",
    "model_file_path_list=[]\n",
    "for model_filename in results2:\n",
    "    model_filename_list.append(model_filename)\n",
    "    model_file_path_list.append(model_dir+model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array_names = ['Normal-precision', 'Normal-recall', 'Normal-f1-score', \n",
    "                     'Cancer-precision','Cancer-recall', 'Cancer-f1-score', \n",
    "                     'micro avg-precision', 'micro avg-recall', 'micro avg-f1-score', \n",
    "                     'macro avg-precision', 'macro avg-recall', 'macro avg-f1-score', \n",
    "                     'weighted avg-precision', 'weighted avg-recall', 'weighted avg-f1-score',\n",
    "                     'Accuracy', 'Loss']\n",
    "metric_array_list=[]\n",
    "\n",
    "\n",
    "# 0\n",
    "negative_precision_list = [results2[i][1]['Normal']['precision'] for i in results2]\n",
    "metric_array_list.append(negative_precision_list)\n",
    "\n",
    "# 1\n",
    "negative_recall_list = [results2[i][1]['Normal']['recall'] for i in results2]\n",
    "metric_array_list.append(negative_recall_list)\n",
    "\n",
    "# 2\n",
    "negative_f1_score_list = [results2[i][1]['Normal']['f1-score'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "\n",
    "# 3\n",
    "positive_precision_list = [results2[i][1]['Cancer']['precision'] for i in results2]\n",
    "metric_array_list.append(positive_precision_list)\n",
    "\n",
    "# 4\n",
    "positive_recall_list = [results2[i][1]['Cancer']['recall'] for i in results2]\n",
    "metric_array_list.append(positive_recall_list)\n",
    "\n",
    "# 5\n",
    "positive_f1_score_list = [results2[i][1]['Cancer']['f1-score'] for i in results2]\n",
    "metric_array_list.append(positive_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 6\n",
    "micro_precision_list = [results2[i][1]['micro avg']['precision'] for i in results2]\n",
    "metric_array_list.append(micro_precision_list)\n",
    "\n",
    "# 7\n",
    "micro_recall_list = [results2[i][1]['micro avg']['recall'] for i in results2]\n",
    "metric_array_list.append(micro_recall_list)\n",
    "\n",
    "# 8\n",
    "micro_f1_score_list = [results2[i][1]['micro avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(micro_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 9\n",
    "macro_precision_list = [results2[i][1]['macro avg']['precision'] for i in results2]\n",
    "metric_array_list.append(macro_precision_list)\n",
    "\n",
    "# 10\n",
    "macro_recall_list = [results2[i][1]['macro avg']['recall'] for i in results2]\n",
    "metric_array_list.append(macro_recall_list)\n",
    "\n",
    "# 11\n",
    "macro_f1_score_list = [results2[i][1]['macro avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(macro_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 12\n",
    "weighted_precision_list = [results2[i][1]['weighted avg']['precision'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "# 13\n",
    "weighted_recall_list = [results2[i][1]['weighted avg']['recall'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "# 14\n",
    "weighted_f1_score_list = [results2[i][1]['weighted avg']['f1-score'] for i in results2]\n",
    "metric_array_list.append(negative_f1_score_list)\n",
    "\n",
    "\n",
    "\n",
    "# 15\n",
    "accuracy_list = [results1[i][0] for i in results1]\n",
    "metric_array_list.append(accuracy_list)\n",
    "\n",
    "# 16\n",
    "loss_list = [results1[i][1]for i in results1]\n",
    "metric_array_list.append(loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array_list_percent = metric_array_list\n",
    "num_metrics = len(metric_array_list)\n",
    "for i in range(num_metrics):\n",
    "    if i!=16:\n",
    "        metric_array_list_percent[i] = [i*100 for i in metric_array_list[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_array_list_norm = metric_array_list\n",
    "# for i in range(len(metric_array_list)):\n",
    "#     m=max(metric_array_list[i])\n",
    "#     metric_array_list_norm[i] = [i/m for i in metric_array_list_norm[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_index = [1,2,7,8,10,11]\n",
    "plot_index = [2, 3,4,5, 12, 13, 14, 15]\n",
    "\n",
    "# plot_index = [2, 3,4,5, 12, 13, 14, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_col = 12\n",
    "figsize_row = 4\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'Large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperate_plot = False\n",
    "# seperate_plot = True\n",
    "\n",
    "filter_skip = False\n",
    "\n",
    "filter_plot = False\n",
    "filter_plot = True\n",
    "\n",
    "dpi=150\n",
    "\n",
    "\n",
    "length=len(metric_array_list)\n",
    "num_epochs=len(results2)\n",
    "x = np.arange(num_epochs)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(18, 12), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "for i in range(length):\n",
    "    if not filter_plot or i in plot_index:\n",
    "        if seperate_plot:  \n",
    "            fig, axs = plt.subplots(figsize=(figsize_col, figsize_row), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "            plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "            \n",
    "            plt.plot(x, metric_array_list_percent[i], label=metric_array_names[i])\n",
    "            plt.title(metric_array_names[i])\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Score (100%)\")\n",
    "#             plt.yticks(np.arange(0, 100, 5))\n",
    "#             plt.xticks(np.arange(0, num_epochs, 1))\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "#             plt.ylim([min(metric_array_list_percent[i]),max(metric_array_list_percent[i])])\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.plot(x, metric_array_list_percent[i], label=metric_array_names[i])\n",
    "            plt.title(metric_array_names[i])\n",
    "        \n",
    "\n",
    "            \n",
    "if not seperate_plot:\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Val\")\n",
    "#     plt.yticks(np.arange(0, 100, 5))\n",
    "#     plt.xticks(np.arange(0, num_epochs, 1))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_col=10\n",
    "figsize_row=3\n",
    "fig, axs = plt.subplots(figsize=(figsize_col, figsize_row), dpi=dpi, facecolor=facecolor, edgecolor=edgecolor)\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "\n",
    "\n",
    "x = np.arange(len(results1))\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(x, accuracy_list, label=\"Accuarcy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score(100%)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(x, loss_list, label= \"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [3,13,17, 18]\n",
    "num_model = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(metric_array_list_percent)):\n",
    "    print(\"%6s%10s%.2f\"%(metric_array_names[i],\":\", metric_array_list_percent[i][num_model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir=\"data\\\\output\\\\models\\\\20181201035451\\\\\"\n",
    "# model=keras.models.load_model(model_dir+\"30-val_acc-0.85-val_loss-0.66.hdf5\")\n",
    "\n",
    "model_path = model_file_path_list[num_model]\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "accuracy, loss =  model_evaluate(model, test_generator, print_report=True)\n",
    "y_preds, y_classes, CM, cls_report, cls_report_print = predict_report(model, test_generator, classes, print_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Normal', 'PNEUMONIA']\n",
    "CM = confusion_matrix(test_generator.classes, y_classes)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM , figsize=(10,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.yticks(range(len(classes)), classes, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_callbacks(checkpoint, reduce_lr, early_stopping, tensorboard)\n",
    "# reset_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_logger = keras.callbacks.BaseLogger(stateful_metrics=base_logger_stateful_metrics)\n",
    "terminate_on_NaN = keras.callbacks.TerminateOnNaN()\n",
    "progbar_logger = keras.callbacks.ProgbarLogger(count_mode=progbar_logger_count_mode, stateful_metrics=progbar_logger_stateful_metrics)\n",
    "history = keras.callbacks.History()\n",
    "# learning_rate_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, lr_scheduler_verbose=0)\n",
    "CSV_logger = keras.callbacks.CSVLogger(CSV_logger_filename, separator=CSV_logger_separator, append=CSV_logger_append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Best Model\n",
    "### Selecting best model file based on validation accuracy mentioned in file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best model file / checkpoint for retraining\n",
    "# model_path = model_dir+r\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "# model_path = model_dir+r\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "# best accuracy/ F-1 score\n",
    "# model_path = \"data/output/models/\"+\"17-val_acc-0.82-val_loss-0.42.hdf5\"\n",
    "\n",
    "# Lowest validation Loss\n",
    "# model_path = \"data/output/models/\"+\"12-val_acc-0.70-val_loss-1.09.hdf5\"\n",
    "\n",
    "# Best Recall\n",
    "# model_path = \"data/output/models/\"+\"20-val_acc-0.66-val_loss-1.97.hdf5\"\n",
    "\n",
    "model_path = model_dir+r\"20-val_acc-0.71-val_loss-1.26.hdf5\"\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# train inception model\n",
    "# fine-tuning the top layers\n",
    "# compile model with loss, optimizer and metrics \n",
    "model.compile(optimizer, loss=loss, metrics=metrics)\n",
    "tensorboard.set_model(model) \n",
    "\n",
    "# retrain by loading last good model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    # verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight,\n",
    "    initial_epoch=initial_epoch)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    extracted_id = b[0]\n",
    "    \n",
    "    return extracted_id\n",
    "\n",
    "\n",
    "\n",
    "test_filenames = test_generator.filenames\n",
    "df_preds = pd.DataFrame(predictions, columns=classes)\n",
    "df_preds['file_names'] = test_filenames\n",
    "df_preds['id'] = df_preds['file_names'].apply(extract_id)\n",
    "df_preds.head()\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['Cancer']\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "roc_auc_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':image_id, \n",
    "                           'label':y_pred, \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('patch_preds.csv', columns=['label']) \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retriving actual labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (test_generator.class_indices)\n",
    "label_map_rev = {v: name_correct(k) for k,v in label_map.items()}\n",
    "num_batch_t = len(test_generator)\n",
    "print(label_map)\n",
    "print(label_map_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showing accuracy for Model over Single Batch of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0, num_batch_t-1)\n",
    "y_img_batch, y_class_batch = test_generator[num] \n",
    "y_pred = np.argmax(model.predict(y_img_batch),-1)\n",
    "y_true = np.argmax(y_class_batch,-1)\n",
    "print(\"Selected Batch No: %d\\nBatch Size: %d\"%(num, len(y_pred)))\n",
    "print(\"Accuracy : \", sum(y_pred==y_true)/batch_size*100, \"%\")\n",
    "\n",
    "y_true_labels = [label_map_rev[c] for c in y_true]\n",
    "y_pred_labels = [label_map_rev[c] for c in y_pred]\n",
    "batch_size_t = len(y_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n",
    "Visualization of performance of a random test dataset batch and few random images from a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/result\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "\n",
    "cols = 8\n",
    "rows= batch_size_t/cols\n",
    "if batch_size_t%cols==0:\n",
    "    rows = int(batch_size_t/cols)\n",
    "else:\n",
    "    rows = int(batch_size_t/cols)+1\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "facecolor='w'\n",
    "edgecolor='k'\n",
    "\n",
    "titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org : \"\n",
    "pred_label_title_prefix = \"pred: \"\n",
    "\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 (Random Batch)\n",
    "Visualization of performance of a random test dataset batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "for i in range(0, batch_size_t): # how many imgs will show from the mxn grid\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[i])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[i]==y_pred_labels[i]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[i] + \"\\n\" + pred_label_title_prefix + y_pred_labels[i], color=false_prediction_label_color)\n",
    "        \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)\n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters for visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_directory = \"data/output/figures\"\n",
    "image_file_name = figure_directory+\"/sample\"\n",
    "\n",
    "dpi=100\n",
    "\n",
    "update_image = True\n",
    "\n",
    "cols = 4\n",
    "rows= 2\n",
    "\n",
    "count = rows*cols\n",
    "    \n",
    "figsize_col = cols*2.5\n",
    "figsize_row = rows*2.5\n",
    "\n",
    "hspace = 0.5\n",
    "wspace = 0.3\n",
    "\n",
    "# titlesize = 'small'\n",
    "\n",
    "true_prediction_label_color='black'\n",
    "false_prediction_label_color='red'\n",
    "\n",
    "true_label_title_prefix = \"org:  \"\n",
    "pred_label_title_prefix = \"pred: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 (Random) \n",
    "Visualization of performance of a few random images from a random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(figsize_col, figsize_row),\n",
    "                        dpi=dpi, facecolor=facecolor, edgecolor=edgecolor,\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': titlesize})\n",
    "plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "\n",
    "\n",
    "batch_size_tmp = batch_size_t\n",
    "\n",
    "m = {}\n",
    "\n",
    "for i in range(0, count): \n",
    "    num = random.randint(0, batch_size_tmp-1)\n",
    "    while num in m:\n",
    "        num = random.randint(0, batch_size_tmp-1)\n",
    "    \n",
    "    m[num]=1\n",
    "    \n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    \n",
    "    plt.imshow(y_img_batch[num])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if y_true_labels[num]==y_pred_labels[num]:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num])\n",
    "    else:\n",
    "        plt.title(true_label_title_prefix + y_true_labels[num] + \"\\n\" + pred_label_title_prefix + y_pred_labels[num], color=false_prediction_label_color)\n",
    "    \n",
    "   \n",
    "    if update_image and os.path.exists(image_file_name):\n",
    "        os.remove(image_file_name)   \n",
    "    \n",
    "    fig.savefig(image_file_name, dpi=dpi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
